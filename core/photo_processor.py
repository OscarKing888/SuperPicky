#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Core Photo Processor - æ ¸å¿ƒç…§ç‰‡å¤„ç†å™¨
æå–è‡ª GUI å’Œ CLI çš„å…±äº«ä¸šåŠ¡é€»è¾‘

èŒè´£ï¼š
- æ–‡ä»¶æ‰«æå’Œ RAW è½¬æ¢
- è°ƒç”¨ AI æ£€æµ‹
- è°ƒç”¨ RatingEngine è¯„åˆ†
- å†™å…¥ EXIF å…ƒæ•°æ®
- æ–‡ä»¶ç§»åŠ¨å’Œæ¸…ç†
"""

import os
import time
import json
import shutil
import numpy as np
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Callable, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime

# ç°æœ‰æ¨¡å—
from find_bird_util import raw_to_jpeg
from ai_model import load_yolo_model, detect_and_draw_birds
from exiftool_manager import get_exiftool_manager
from advanced_config import get_advanced_config
from core.rating_engine import RatingEngine, create_rating_engine_from_config
from core.keypoint_detector import KeypointDetector, get_keypoint_detector
from core.flight_detector import FlightDetector, get_flight_detector, FlightResult
from core.exposure_detector import ExposureDetector, get_exposure_detector, ExposureResult
from core.focus_point_detector import get_focus_detector, verify_focus_in_bbox

from constants import RATING_FOLDER_NAMES, RAW_EXTENSIONS, JPG_EXTENSIONS


@dataclass
class ProcessingSettings:
    """å¤„ç†å‚æ•°é…ç½®"""
    ai_confidence: int = 50
    sharpness_threshold: int = 400   # å¤´éƒ¨åŒºåŸŸé”åº¦è¾¾æ ‡é˜ˆå€¼ (200-600)
    nima_threshold: float = 5.2  # TOPIQ ç¾å­¦è¾¾æ ‡é˜ˆå€¼ (4.0-7.0)
    save_crop: bool = False
    normalization_mode: str = 'log_compression'  # é»˜è®¤ä½¿ç”¨log_compressionï¼Œä¸GUIä¸€è‡´
    detect_flight: bool = True  # V3.4: é£ç‰ˆæ£€æµ‹å¼€å…³
    detect_exposure: bool = False  # V3.8: æ›å…‰æ£€æµ‹å¼€å…³ï¼ˆé»˜è®¤å…³é—­ï¼‰
    exposure_threshold: float = 0.10  # V3.8: æ›å…‰é˜ˆå€¼ (0.05-0.20)
    device: str = 'auto'  # è®¡ç®—è®¾å¤‡é€‰æ‹©: 'auto', 'cuda', 'cpu', 'mps', 'all'
    stop_event: Optional[Any] = None  # åœæ­¢äº‹ä»¶ï¼ˆç”¨äºå–æ¶ˆå¤„ç†ï¼‰
    keep_temp_jpg: bool = True  # æ˜¯å¦ä¿ç•™ä¸´æ—¶è½¬æ¢çš„JPGæ–‡ä»¶
    cpu_threads: int = 0  # CPUæ¨ç†çº¿ç¨‹æ•°ï¼ˆ0=è‡ªåŠ¨ï¼Œä½¿ç”¨CPUé€»è¾‘æ ¸å¿ƒæ•°ï¼‰
    gpu_concurrent: int = 10  # GPUæ¨ç†å¹¶å‘æ•°ï¼ˆ1=ä¸²è¡Œï¼Œ>1=å¹¶å‘é˜Ÿåˆ—ï¼Œéœ€è€ƒè™‘æ˜¾å­˜ï¼‰
    use_pipeline: bool = True  # æ˜¯å¦ä½¿ç”¨æ–°çš„æµæ°´çº¿æ¡†æ¶ï¼ˆé»˜è®¤å¯ç”¨ï¼‰


@dataclass
class ProcessingCallbacks:
    """å›è°ƒå‡½æ•°ï¼ˆç”¨äºè¿›åº¦æ›´æ–°å’Œæ—¥å¿—è¾“å‡ºï¼‰"""
    log: Optional[Callable[[str, str], None]] = None
    progress: Optional[Callable[[int], None]] = None


@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœæ•°æ®"""
    stats: Dict[str, any] = field(default_factory=dict)
    file_ratings: Dict[str, int] = field(default_factory=dict)
    star_3_photos: List[Dict] = field(default_factory=list)
    total_time: float = 0.0
    avg_time: float = 0.0


class PhotoProcessor:
    """
    æ ¸å¿ƒç…§ç‰‡å¤„ç†å™¨
    
    å°è£…æ‰€æœ‰ä¸šåŠ¡é€»è¾‘ï¼ŒGUI å’Œ CLI éƒ½è°ƒç”¨è¿™ä¸ªç±»
    """
    
    def __init__(
        self,
        dir_path: str,
        settings: ProcessingSettings,
        callbacks: Optional[ProcessingCallbacks] = None
    ):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            dir_path: å¤„ç†ç›®å½•è·¯å¾„
            settings: å¤„ç†å‚æ•°
            callbacks: å›è°ƒå‡½æ•°ï¼ˆè¿›åº¦ã€æ—¥å¿—ï¼‰
        """
        self.dir_path = dir_path
        self.settings = settings
        self.callbacks = callbacks or ProcessingCallbacks()
        self.config = get_advanced_config()
        
        # åˆå§‹åŒ–è¯„åˆ†å¼•æ“
        self.rating_engine = create_rating_engine_from_config(self.config)
        # ä½¿ç”¨ UI è®¾ç½®æ›´æ–°è¾¾æ ‡é˜ˆå€¼
        self.rating_engine.update_thresholds(
            sharpness_threshold=settings.sharpness_threshold,
            nima_threshold=settings.nima_threshold
        )
        
        # DEBUG: è¾“å‡ºå‚æ•°
        self._log(f"\nğŸ” DEBUG - å¤„ç†å‚æ•°:")
        self._log(f"  ğŸ“Š AIç½®ä¿¡åº¦: {settings.ai_confidence}")
        self._log(f"  ğŸ“ é”åº¦é˜ˆå€¼: {settings.sharpness_threshold}")
        self._log(f"  ğŸ¨ NIMAé˜ˆå€¼: {settings.nima_threshold}")
        self._log(f"  ğŸ”§ å½’ä¸€åŒ–æ¨¡å¼: {settings.normalization_mode}")
        self._log(f"  ğŸ¦… é£é¸Ÿæ£€æµ‹: {'å¼€å¯' if settings.detect_flight else 'å…³é—­'}")
        self._log(f"  ğŸ“¸ æ›å…‰æ£€æµ‹: {'å¼€å¯' if settings.detect_exposure else 'å…³é—­'}")
        self._log(f"  âš™ï¸  é«˜çº§é…ç½® - min_sharpness: {self.config.min_sharpness}")
        self._log(f"  âš™ï¸  é«˜çº§é…ç½® - min_nima: {self.config.min_nima}\n")
        
        # ç»Ÿè®¡æ•°æ®ï¼ˆæ”¯æŒ 0/1/2/3 æ˜Ÿï¼‰
        self.stats = {
            'total': 0,
            'star_3': 0,
            'picked': 0,
            'star_2': 0,
            'star_1': 0,  # æ™®é€šç…§ç‰‡ï¼ˆåˆæ ¼ï¼‰
            'star_0': 0,  # æ™®é€šç…§ç‰‡ï¼ˆé—®é¢˜ï¼‰
            'no_bird': 0,
            'flying': 0,  # V3.6: é£é¸Ÿç…§ç‰‡è®¡æ•°
            'exposure_issue': 0,  # V3.8: æ›å…‰é—®é¢˜è®¡æ•°
            'start_time': 0,
            'end_time': 0,
            'total_time': 0,
            'avg_time': 0,
            # æ–°å¢ç»Ÿè®¡å­—æ®µ
            'photo_times': [],  # æ¯å¼ å›¾ç‰‡çš„å¤„ç†æ—¶é—´åˆ—è¡¨ [(filename, time_ms, detected)]
            'with_bird_times': [],  # å¸¦é¸Ÿå›¾ç‰‡çš„å¤„ç†æ—¶é—´
            'no_bird_times': [],  # ä¸å¸¦é¸Ÿå›¾ç‰‡çš„å¤„ç†æ—¶é—´
            'longest_photo': None,  # (filename, time_ms)
            'shortest_photo': None,  # (filename, time_ms)
            'avg_with_bird_time': 0.0,  # å¸¦é¸Ÿå›¾ç‰‡å¹³å‡å¤„ç†æ—¶é—´
            'avg_no_bird_time': 0.0,  # ä¸å¸¦é¸Ÿå›¾ç‰‡å¹³å‡å¤„ç†æ—¶é—´
            'cancelled': False  # æ˜¯å¦è¢«å–æ¶ˆ
        }
        
        # åœæ­¢äº‹ä»¶ï¼ˆç”¨äºå–æ¶ˆå¤„ç†ï¼‰
        self.stop_event = settings.stop_event
        
        # å†…éƒ¨çŠ¶æ€
        self.file_ratings = {}
        self.star2_reasons = {}  # è®°å½•2æ˜ŸåŸå› : 'sharpness' æˆ– 'nima'
        self.star_3_photos = []
        self.heif_temp_map = {}  # HEIF æ–‡ä»¶åˆ°ä¸´æ—¶ JPG çš„æ˜ å°„
        self.picked_files = set()  # ç²¾é€‰æ–‡ä»¶é›†åˆï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦ç²¾é€‰ï¼‰
        
        # çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰
        import threading
        self._stats_lock = threading.Lock()
        
        # æµæ°´çº¿æ¨¡å¼ä¸‹çš„è¿›åº¦è·Ÿè¸ª
        self._pipeline_total_files = 0  # æ€»æ–‡ä»¶æ•°
        self._pipeline_processed_files = 0  # å·²å¤„ç†æ–‡ä»¶æ•°
        self._pipeline_progress_lock = threading.Lock()  # è¿›åº¦é”
        
        # æµæ°´çº¿å®ä¾‹ï¼ˆç”¨äºUIç›‘æ§ï¼‰
        self._pipelines = []  # ä¿å­˜æµæ°´çº¿å®ä¾‹åˆ—è¡¨
    
    def _log(self, msg: str, level: str = "info"):
        """å†…éƒ¨æ—¥å¿—æ–¹æ³•"""
        if self.callbacks.log:
            self.callbacks.log(msg, level)
    
    def _progress(self, percent: int = -1):
        """
        å†…éƒ¨è¿›åº¦æ›´æ–°
        
        Args:
            percent: è¿›åº¦ç™¾åˆ†æ¯” (0-100)ï¼Œ-1 è¡¨ç¤ºåŸºäºå·²å¤„ç†æ–‡ä»¶æ•°è‡ªåŠ¨è®¡ç®—
        """
        if self.callbacks.progress:
            # å¦‚æœä¼ é€’ -1ï¼Œè¡¨ç¤ºæµæ°´çº¿æ¨¡å¼ä¸‹çš„è¿›åº¦æ›´æ–°ï¼ˆåŸºäºå·²å¤„ç†æ–‡ä»¶æ•°è®¡ç®—ï¼‰
            if percent == -1:
                with self._pipeline_progress_lock:
                    if self._pipeline_total_files > 0:
                        # åŸºäºå·²å¤„ç†æ–‡ä»¶æ•°è®¡ç®—è¿›åº¦
                        calculated_percent = int((self._pipeline_processed_files / self._pipeline_total_files) * 100)
                        calculated_percent = min(100, max(0, calculated_percent))  # é™åˆ¶åœ¨ 0-100
                        self.callbacks.progress(calculated_percent)
                    # å¦‚æœæ€»æ–‡ä»¶æ•°ä¸º0ï¼Œä¸æ›´æ–°è¿›åº¦ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰
            else:
                self.callbacks.progress(percent)
    
    def process(
        self,
        organize_files: bool = True,
        cleanup_temp: bool = True
    ) -> ProcessingResult:
        """
        ä¸»å¤„ç†æµç¨‹
        
        Args:
            organize_files: æ˜¯å¦ç§»åŠ¨æ–‡ä»¶åˆ°åˆ†ç±»æ–‡ä»¶å¤¹
            cleanup_temp: æ˜¯å¦æ¸…ç†ä¸´æ—¶JPGæ–‡ä»¶
            
        Returns:
            ProcessingResult åŒ…å«ç»Ÿè®¡æ•°æ®å’Œå¤„ç†ç»“æœ
        """
        start_time = time.time()
        self.stats['start_time'] = start_time
        
        # é˜¶æ®µ1: æ–‡ä»¶æ‰«æ
        raw_dict, jpg_dict, files_tbr = self._scan_files()
        
        # é˜¶æ®µ2: RAWè½¬æ¢
        raw_files_to_convert = self._identify_raws_to_convert(raw_dict, jpg_dict, files_tbr)
        if raw_files_to_convert:
            self._convert_raws(raw_files_to_convert, files_tbr)
        
        # é˜¶æ®µ2.5: HEIF/HIF å¹¶è¡Œè½¬æ¢ï¼ˆä»…éæµæ°´çº¿æ¨¡å¼ï¼‰
        # æµæ°´çº¿æ¨¡å¼ä¸‹ï¼ŒHEIFè½¬æ¢ä¼šåœ¨æµæ°´çº¿ä¸­å¤„ç†ï¼Œè½¬æ¢ä¸€å¼ ç«‹å³è¿›å…¥æ¨ç†é˜Ÿåˆ—
        use_pipeline = getattr(self.settings, 'use_pipeline', True)  # é»˜è®¤å¯ç”¨
        if not use_pipeline:
            # éæµæ°´çº¿æ¨¡å¼ï¼šæå‰è½¬æ¢æ‰€æœ‰HEIFæ–‡ä»¶
            heif_files_to_convert = self._identify_heif_to_convert(files_tbr)
            if heif_files_to_convert:
                self._convert_heif_files(heif_files_to_convert)
        
        # é˜¶æ®µ3: AIæ£€æµ‹ä¸è¯„åˆ†
        # ä½¿ç”¨æ–°çš„æµæ°´çº¿æ¡†æ¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_pipeline:
            self._process_images_with_pipeline(files_tbr, raw_dict)
        else:
            self._process_images(files_tbr, raw_dict)
        
        # é˜¶æ®µ4: ç²¾é€‰æ——æ ‡è®¡ç®—
        self._calculate_picked_flags()
        
        # é˜¶æ®µ5: æ–‡ä»¶ç»„ç»‡
        if organize_files:
            self._move_files_to_rating_folders(raw_dict)
        
        # é˜¶æ®µ6: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if cleanup_temp:
            self._cleanup_temp_files(files_tbr, raw_dict)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        self.stats['end_time'] = end_time
        self.stats['total_time'] = end_time - start_time
        self.stats['avg_time'] = (
            self.stats['total_time'] / self.stats['total']
            if self.stats['total'] > 0 else 0
        )
        
        # è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        if self.stats['photo_times']:
            # æœ€é•¿/æœ€çŸ­å¤„ç†æ—¶é—´
            longest = max(self.stats['photo_times'], key=lambda x: x[1])
            shortest = min(self.stats['photo_times'], key=lambda x: x[1])
            self.stats['longest_photo'] = (longest[0], longest[1])
            self.stats['shortest_photo'] = (shortest[0], shortest[1])
            
            # å¸¦é¸Ÿ/ä¸å¸¦é¸Ÿå¹³å‡æ—¶é—´
            if self.stats['with_bird_times']:
                self.stats['avg_with_bird_time'] = sum(self.stats['with_bird_times']) / len(self.stats['with_bird_times'])
            if self.stats['no_bird_times']:
                self.stats['avg_no_bird_time'] = sum(self.stats['no_bird_times']) / len(self.stats['no_bird_times'])
        
        return ProcessingResult(
            stats=self.stats.copy(),
            file_ratings=self.file_ratings.copy(),
            star_3_photos=self.star_3_photos.copy(),
            total_time=self.stats['total_time'],
            avg_time=self.stats['avg_time']
        )
    
    def _scan_files(self) -> Tuple[dict, dict, list]:
        """æ‰«æç›®å½•æ–‡ä»¶"""
        scan_start = time.time()
        
        raw_dict = {}
        jpg_dict = {}
        files_tbr = []
        
        for filename in os.listdir(self.dir_path):
            if filename.startswith('.'):
                continue

            
            file_prefix, file_ext = os.path.splitext(filename)
            if file_ext.lower() in RAW_EXTENSIONS:
                raw_dict[file_prefix] = file_ext
            if file_ext.lower() in JPG_EXTENSIONS:
                jpg_dict[file_prefix] = file_ext
                files_tbr.append(filename)
        
        scan_time = (time.time() - scan_start) * 1000
        self._log(f"â±ï¸  æ–‡ä»¶æ‰«æè€—æ—¶: {scan_time:.1f}ms")
        
        return raw_dict, jpg_dict, files_tbr
    
    def _identify_raws_to_convert(self, raw_dict, jpg_dict, files_tbr):
        """è¯†åˆ«éœ€è¦è½¬æ¢çš„RAWæ–‡ä»¶"""
        raw_files_to_convert = []
        
        for key, value in raw_dict.items():
            if key in jpg_dict:
                jpg_dict.pop(key)
                continue
            else:
                raw_file_path = os.path.join(self.dir_path, key + value)
                raw_files_to_convert.append((key, raw_file_path))
        
        return raw_files_to_convert
    
    def _convert_raws(self, raw_files_to_convert, files_tbr):
        """å¹¶è¡Œè½¬æ¢RAWæ–‡ä»¶"""
        raw_start = time.time()
        import multiprocessing
        max_workers = min(4, multiprocessing.cpu_count())
        
        self._log(f"ğŸ”„ å¼€å§‹å¹¶è¡Œè½¬æ¢ {len(raw_files_to_convert)} ä¸ªRAWæ–‡ä»¶({max_workers}çº¿ç¨‹)...")
        
        def convert_single(args):
            key, raw_path = args
            try:
                raw_to_jpeg(raw_path)
                return (key, True, None)
            except Exception as e:
                return (key, False, str(e))
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_raw = {
                executor.submit(convert_single, args): args 
                for args in raw_files_to_convert
            }
            converted_count = 0
            
            for future in as_completed(future_to_raw):
                key, success, error = future.result()
                if success:
                    files_tbr.append(key + ".jpg")
                    converted_count += 1
                    if converted_count % 5 == 0 or converted_count == len(raw_files_to_convert):
                        self._log(f"  âœ… å·²è½¬æ¢ {converted_count}/{len(raw_files_to_convert)} å¼ ")
                else:
                    self._log(f"  âŒ è½¬æ¢å¤±è´¥: {key} ({error})", "error")
        
        raw_time = time.time() - raw_start
        avg_time = raw_time / len(raw_files_to_convert) if len(raw_files_to_convert) > 0 else 0
        self._log(f"â±ï¸  RAWè½¬æ¢è€—æ—¶: {raw_time:.1f}ç§’ (å¹³å‡ {avg_time:.1f}ç§’/å¼ )\n")
    
    def _identify_heif_to_convert(self, files_tbr):
        """è¯†åˆ«éœ€è¦è½¬æ¢çš„ HEIF/HIF æ–‡ä»¶"""
        heif_files = []
        heif_extensions = ['.heif', '.heic', '.hif']
        
        for filename in files_tbr:
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext in heif_extensions:
                filepath = os.path.join(self.dir_path, filename)
                heif_files.append((filename, filepath))
        
        return heif_files
    
    def _convert_heif_files(self, heif_files_to_convert):
        """å¹¶è¡Œè½¬æ¢ HEIF/HIF æ–‡ä»¶ä¸ºä¸´æ—¶ JPG"""
        if not heif_files_to_convert:
            return
        
        heif_start = time.time()
        import multiprocessing
        max_workers = min(8, multiprocessing.cpu_count())  # HEIFè½¬æ¢å¯ä»¥æ›´å¤šçº¿ç¨‹
        
        self._log(f"ğŸ”„ å¼€å§‹å¹¶è¡Œè½¬æ¢ {len(heif_files_to_convert)} ä¸ª HEIF/HIF æ–‡ä»¶({max_workers}çº¿ç¨‹)...")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(self.dir_path, '.superpicky', 'temp_jpg')
        os.makedirs(temp_dir, exist_ok=True)
        
        def convert_single_heif(args):
            filename, heif_path = args
            try:
                # ç”Ÿæˆä¸´æ—¶ JPG è·¯å¾„
                file_basename = os.path.splitext(filename)[0]
                temp_jpg_path = os.path.join(temp_dir, f"{file_basename}_temp.jpg")
                
                # æ£€æŸ¥ä¸´æ—¶JPGæ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ç›´æ¥ä½¿ç”¨ï¼Œè·³è¿‡è½¬æ¢
                if os.path.exists(temp_jpg_path):
                    # éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆå¤§å°å¤§äº0ï¼‰
                    if os.path.getsize(temp_jpg_path) > 0:
                        return (filename, True, temp_jpg_path, None)
                    else:
                        # æ–‡ä»¶å­˜åœ¨ä½†å¤§å°ä¸º0ï¼Œåˆ é™¤åé‡æ–°è½¬æ¢
                        try:
                            os.remove(temp_jpg_path)
                        except:
                            pass
                
                # ä¸´æ—¶JPGä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œæ‰§è¡Œè½¬æ¢
                # æ³¨å†Œ pillow-heif
                try:
                    from pillow_heif import register_heif_opener
                    register_heif_opener()
                except ImportError:
                    pass
                
                from PIL import Image
                
                # è¯»å–å¹¶è½¬æ¢
                pil_image = Image.open(heif_path).convert('RGB')
                
                # ä¿å­˜ä¸º JPG
                pil_image.save(temp_jpg_path, 'JPEG', quality=95)
                
                return (filename, True, temp_jpg_path, None)
            except Exception as e:
                return (filename, False, None, str(e))
        
        # å­˜å‚¨è½¬æ¢æ˜ å°„ï¼šåŸå§‹æ–‡ä»¶å -> ä¸´æ—¶JPGè·¯å¾„
        self.heif_temp_map = {}
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_heif = {
                executor.submit(convert_single_heif, args): args 
                for args in heif_files_to_convert
            }
            converted_count = 0
            reused_count = 0
            
            for future in as_completed(future_to_heif):
                filename, success, temp_jpg_path, error = future.result()
                if success:
                    self.heif_temp_map[filename] = temp_jpg_path
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤ç”¨çš„æ–‡ä»¶ï¼ˆé€šè¿‡æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦æ—©äºå¤„ç†å¼€å§‹æ—¶é—´ï¼‰
                    if os.path.exists(temp_jpg_path):
                        file_mtime = os.path.getmtime(temp_jpg_path)
                        if file_mtime < heif_start:
                            reused_count += 1
                        else:
                            converted_count += 1
                    else:
                        converted_count += 1
                    
                    total_processed = converted_count + reused_count
                    if total_processed % 10 == 0 or total_processed == len(heif_files_to_convert):
                        status_msg = f"  âœ… å·²å¤„ç† {total_processed}/{len(heif_files_to_convert)} å¼ "
                        if reused_count > 0:
                            status_msg += f" (è½¬æ¢: {converted_count}, å¤ç”¨: {reused_count})"
                        self._log(status_msg)
                else:
                    self._log(f"  âŒ è½¬æ¢å¤±è´¥: {filename} ({error})", "error")
        
        heif_time = time.time() - heif_start
        if converted_count > 0:
            avg_time = heif_time / converted_count
            if reused_count > 0:
                self._log(f"â±ï¸  HEIFè½¬æ¢è€—æ—¶: {heif_time:.1f}ç§’ (è½¬æ¢ {converted_count} å¼ , å¹³å‡ {avg_time:.1f}ç§’/å¼ , å¤ç”¨ {reused_count} å¼ )\n")
            else:
                self._log(f"â±ï¸  HEIFè½¬æ¢è€—æ—¶: {heif_time:.1f}ç§’ (è½¬æ¢ {converted_count} å¼ , å¹³å‡ {avg_time:.1f}ç§’/å¼ )\n")
        else:
            self._log(f"â±ï¸  HEIFå¤„ç†è€—æ—¶: {heif_time:.1f}ç§’ (å…¨éƒ¨å¤ç”¨ç°æœ‰æ–‡ä»¶, {reused_count} å¼ )\n")
    
    def _process_images_with_pipeline(self, files_tbr, raw_dict):
        """
        ä½¿ç”¨æ–°çš„æµæ°´çº¿æ¡†æ¶å¤„ç†å›¾ç‰‡
        æ”¯æŒæµæ°´çº¿å¼HEIFè½¬æ¢ã€å¤šè®¾å¤‡å¹¶è¡Œæ¨ç†
        ä¼˜åŒ–ï¼šHEIFè½¬æ¢å®Œæˆåç«‹å³è¿›å…¥æ¨ç†é˜Ÿåˆ—ï¼ŒCPUè½¬æ¢å®Œæˆåå¯å‚ä¸æ¨ç†
        """
        self._log("ğŸš€ ä½¿ç”¨æµæ°´çº¿æ¡†æ¶å¤„ç†å›¾ç‰‡...")
        
        try:
            from core.pipeline_builder import PipelineBuilder
            from core.job_queue import JobQueue
            
            # åˆ›å»ºæ„å»ºå™¨
            builder = PipelineBuilder(
                dir_path=self.dir_path,
                settings=self.settings,
                raw_dict=raw_dict,
                log_callback=self._log,
                progress_callback=self._progress,
                stats_callback=self._handle_pipeline_stats
            )
            
            # è¯†åˆ«HEIFæ–‡ä»¶
            heif_files = self._identify_heif_to_convert(files_tbr)
            regular_files = [f for f in files_tbr if f not in [hf[0] for hf in heif_files]]
            
            # åˆ›å»ºç»Ÿä¸€çš„AIå¤„ç†é˜Ÿåˆ—ï¼ˆHEIFè½¬æ¢è¾“å‡ºå’Œå¸¸è§„æ–‡ä»¶éƒ½è¿›å…¥æ­¤é˜Ÿåˆ—ï¼‰
            device_configs = builder.device_mgr.get_all_configs()
            total_inference_workers = sum(cfg['max_workers'] for cfg in device_configs)
            queue_maxsize = max(8, total_inference_workers * 2)
            shared_ai_queue = JobQueue(maxsize=queue_maxsize)
            
            # æ„å»ºå¹¶å¯åŠ¨æµæ°´çº¿
            pipelines = []
            
            # 1. HEIFè½¬æ¢é˜¶æ®µï¼ˆå¦‚æœæœ‰HEIFæ–‡ä»¶ï¼‰
            # è½¬æ¢å®Œæˆåç«‹å³å°†ç»“æœæ”¾å…¥shared_ai_queueï¼Œå®ç°æµå¼å¤„ç†
            if heif_files:
                self._log(f"ğŸ“¦ æ„å»ºHEIFè½¬æ¢é˜¶æ®µï¼ˆ{len(heif_files)}ä¸ªæ–‡ä»¶ï¼Œè½¬æ¢å®Œæˆåç«‹å³è¿›å…¥æ¨ç†é˜Ÿåˆ—ï¼‰...")
                heif_pipeline = builder.build_heif_conversion_stage(heif_files, shared_ai_queue)
                heif_pipeline.start()
                pipelines.append(heif_pipeline)
            
            # 2. ç»Ÿä¸€çš„AIå¤„ç†æµæ°´çº¿ï¼ˆå¤„ç†HEIFè½¬æ¢è¾“å‡ºå’Œå¸¸è§„æ–‡ä»¶ï¼‰
            # æ‰€æœ‰è®¾å¤‡å…±äº«åŒä¸€ä¸ªé˜Ÿåˆ—ï¼ŒCPUåœ¨è½¬æ¢å®Œæˆåå¯ä»¥ç«‹å³å‚ä¸æ¨ç†
            if heif_files or regular_files:
                total_files = len(heif_files) + len(regular_files)
                # ä¿å­˜æ€»æ–‡ä»¶æ•°ç”¨äºè¿›åº¦è®¡ç®—
                with self._pipeline_progress_lock:
                    self._pipeline_total_files = total_files
                    self._pipeline_processed_files = 0
                self._log(f"ğŸ“¦ æ„å»ºç»Ÿä¸€AIå¤„ç†æµæ°´çº¿ï¼ˆ{total_files}ä¸ªæ–‡ä»¶ï¼ŒHEIFè½¬æ¢å®ŒæˆåCPUå¯å‚ä¸æ¨ç†ï¼‰...")
                ai_pipeline = builder.build_unified_ai_processing_pipeline(regular_files, shared_ai_queue)
                ai_pipeline.start()
                pipelines.append(ai_pipeline)
            
            # ä¿å­˜æµæ°´çº¿å®ä¾‹ä¾›UIç›‘æ§ä½¿ç”¨
            self._pipelines = pipelines
            self._shared_ai_queue = shared_ai_queue
            
            # ç­‰å¾…æ‰€æœ‰æµæ°´çº¿å®Œæˆï¼ˆæ”¯æŒå–æ¶ˆï¼‰
            self._log("â³ ç­‰å¾…æµæ°´çº¿å¤„ç†å®Œæˆ...")
            import time
            last_progress_log = time.time()
            
            for pipeline in pipelines:
                # è½®è¯¢ç­‰å¾…ï¼Œå…è®¸ä¸­æ–­æ£€æŸ¥
                while True:
                    # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
                    if self.stop_event and self.stop_event.is_set():
                        self._log("âš ï¸  æ£€æµ‹åˆ°å–æ¶ˆä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æµæ°´çº¿...", "warning")
                        break
                    
                    # æ£€æŸ¥æ‰€æœ‰é˜¶æ®µæ˜¯å¦å·²å®Œæˆ
                    all_done = True
                    for stage in pipeline.stages:
                        if stage.input_queue:
                            # æ£€æŸ¥é˜Ÿåˆ—ç»Ÿè®¡ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½å·²æ”¾å…¥ä¸”éƒ½å·²å®Œæˆ
                            queue_stats = stage.input_queue.get_stats()
                            total_put = queue_stats.get('total_put', 0)
                            total_done = queue_stats.get('total_done', 0)
                            
                            # å¦‚æœé˜Ÿåˆ—ä¸ä¸ºç©ºï¼Œæˆ–è€…è¿˜æœ‰ä»»åŠ¡åœ¨å¤„ç†ä¸­ï¼ˆput > doneï¼‰ï¼Œåˆ™æœªå®Œæˆ
                            if not stage.input_queue.empty() or total_put > total_done:
                                all_done = False
                                break
                    
                    # å®šæœŸè¾“å‡ºè¿›åº¦æ—¥å¿—ï¼ˆæ¯5ç§’ï¼‰
                    current_time = time.time()
                    if current_time - last_progress_log >= 5.0:
                        # è¾“å‡ºå½“å‰è¿›åº¦
                        for stage in pipeline.stages:
                            if stage.input_queue:
                                queue_stats = stage.input_queue.get_stats()
                                stage_stats = stage.get_stats()
                                processed = stage_stats.get('processed', 0)
                                failed = stage_stats.get('failed', 0)
                                self._log(f"  [{stage.name}] å·²å¤„ç†: {processed}, å¤±è´¥: {failed}, "
                                        f"é˜Ÿåˆ—: {queue_stats.get('total_put', 0)}/{queue_stats.get('total_done', 0)}")
                        last_progress_log = current_time
                    
                    if all_done:
                        break
                    
                    time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…ï¼Œé¿å…CPUå ç”¨è¿‡é«˜
                
                # å¦‚æœå·²å–æ¶ˆï¼Œè·³å‡ºå¾ªç¯
                if self.stop_event and self.stop_event.is_set():
                    break
            
            # ç­‰å¾…æ‰€æœ‰é˜Ÿåˆ—å®Œæˆï¼ˆç¡®ä¿æ‰€æœ‰task_doneéƒ½è¢«è°ƒç”¨ï¼‰
            self._log("â³ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...")
            for pipeline in pipelines:
                for stage in pipeline.stages:
                    if stage.input_queue:
                        try:
                            # ç­‰å¾…é˜Ÿåˆ—joinå®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
                            import queue
                            start_wait = time.time()
                            while not stage.input_queue.empty() or stage.input_queue.qsize() > 0:
                                if time.time() - start_wait > 30:
                                    self._log(f"âš ï¸  ç­‰å¾… {stage.name} é˜Ÿåˆ—è¶…æ—¶", "warning")
                                    break
                                time.sleep(0.1)
                            # å°è¯•joinï¼Œä½†è®¾ç½®è¶…æ—¶
                            stage.input_queue.join()
                        except Exception as e:
                            self._log(f"âš ï¸  ç­‰å¾… {stage.name} é˜Ÿåˆ—æ—¶å‡ºé”™: {e}", "warning")
            
            # åŒæ­¥HEIFè½¬æ¢æ˜ å°„ï¼ˆç”¨äºä¿ç•™ä¸´æ—¶JPGåŠŸèƒ½ï¼‰
            # ä»HEIFè½¬æ¢é˜¶æ®µè·å–heif_temp_map
            if heif_files:
                for stage in heif_pipeline.stages:
                    if hasattr(stage, 'heif_temp_map'):
                        # åŒæ­¥æ˜ å°„åˆ°PhotoProcessorï¼Œä¾›åç»­æ¸…ç†æˆ–ä¿ç•™ä½¿ç”¨
                        self.heif_temp_map.update(stage.heif_temp_map)
                        break
            
            # åœæ­¢æ‰€æœ‰æµæ°´çº¿ï¼ˆæ— è®ºæ˜¯å¦å®Œæˆï¼‰
            for pipeline in pipelines:
                pipeline.stop()
            
            # æ¸…ç©ºæµæ°´çº¿å¼•ç”¨
            self._pipelines = []
            self._shared_ai_queue = None
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            self._log("\nğŸ“Š æµæ°´çº¿ç»Ÿè®¡:")
            for pipeline in pipelines:
                stats = pipeline.get_stats()
                for stage_name, stage_stats in stats.items():
                    self._log(f"  {stage_name}: å¤„ç† {stage_stats.get('processed', 0)} ä¸ªä»»åŠ¡, "
                            f"å¤±è´¥ {stage_stats.get('failed', 0)} ä¸ª, "
                            f"å¹³å‡è€—æ—¶ {stage_stats.get('avg_time', 0):.2f}ç§’")
            
            self._log("âœ… æµæ°´çº¿å¤„ç†å®Œæˆ")
            
        except Exception as e:
            self._log(f"âŒ æµæ°´çº¿å¤„ç†å¤±è´¥: {e}", "error")
            import traceback
            self._log(traceback.format_exc(), "error")
            # é™çº§åˆ°åŸæœ‰æ–¹æ³•
            self._log("âš ï¸  é™çº§åˆ°åŸæœ‰å¤„ç†æ–¹æ³•", "warning")
            self._process_images(files_tbr, raw_dict)
    
    def _handle_pipeline_stats(self, result: Dict[str, Any]):
        """å¤„ç†æµæ°´çº¿ç»Ÿè®¡å›è°ƒ"""
        # æ›´æ–°å·²å¤„ç†æ–‡ä»¶æ•°å¹¶è®¡ç®—è¿›åº¦
        with self._pipeline_progress_lock:
            self._pipeline_processed_files += 1
            # è§¦å‘è¿›åº¦æ›´æ–°ï¼ˆä¼ é€’ -1 è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—ï¼‰
            if self._pipeline_processed_files % 5 == 0 or self._pipeline_processed_files == self._pipeline_total_files:
                self._progress(-1)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        rating_value = result.get('rating', 0)
        is_flying = result.get('is_flying', False)
        has_exposure_issue = result.get('is_overexposed', False) or result.get('is_underexposed', False)
        
        self._update_stats(rating_value, is_flying, has_exposure_issue)
        
        # è®°å½•å¤„ç†æ—¶é—´
        processing_time = result.get('processing_time', 0) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        filename = result.get('filename', '')
        detected = result.get('detected', False)
        
        self.stats['photo_times'].append((filename, processing_time, detected))
        if detected:
            self.stats['with_bird_times'].append(processing_time)
        else:
            self.stats['no_bird_times'].append(processing_time)
        
        # æ›´æ–°æ–‡ä»¶è¯„åˆ†
        file_prefix = result.get('file_prefix')
        if file_prefix:
            self.file_ratings[file_prefix] = rating_value
            
            # æ”¶é›†3æ˜Ÿç…§ç‰‡
            if rating_value == 3:
                topiq = result.get('topiq')
                head_sharpness = result.get('head_sharpness', 0)
                if topiq is not None:
                    filepath = result.get('filepath')
                    if filepath:
                        self.star_3_photos.append({
                            'file': filepath,
                            'nima': topiq,
                            'sharpness': head_sharpness
                        })
            
            # è®°å½•2æ˜ŸåŸå› 
            if rating_value == 2:
                head_sharpness = result.get('head_sharpness', 0)
                topiq = result.get('topiq')
                sharpness_ok = head_sharpness >= self.settings.sharpness_threshold
                topiq_ok = topiq is not None and topiq >= self.settings.nima_threshold
                if sharpness_ok and not topiq_ok:
                    self.star2_reasons[file_prefix] = 'sharpness'
                elif topiq_ok and not sharpness_ok:
                    self.star2_reasons[file_prefix] = 'nima'
                else:
                    self.star2_reasons[file_prefix] = 'both'
        
        # æ›´æ–°CSVï¼ˆåœ¨EXIFå†™å…¥é˜¶æ®µå·²ç»å¤„ç†ï¼Œè¿™é‡Œå¯ä»¥è·³è¿‡ï¼‰
    
    def _process_images(self, files_tbr, raw_dict):
        """å¤„ç†æ‰€æœ‰å›¾ç‰‡ - AIæ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹ä¸è¯„åˆ†"""
        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if self.stop_event and self.stop_event.is_set():
            self.stats['cancelled'] = True
            self._log("âš ï¸  å¤„ç†å·²å–æ¶ˆ", "warning")
            return
        
        # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨æŒ‡å®šè®¾å¤‡ï¼‰
        model_start = time.time()
        self._log("ğŸ¤– åŠ è½½AIæ¨¡å‹...")
        device = self.settings.device if hasattr(self.settings, 'device') else 'auto'
        self._log(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
        model = load_yolo_model(device=device)
        model_time = (time.time() - model_start) * 1000
        self._log(f"â±ï¸  æ¨¡å‹åŠ è½½è€—æ—¶: {model_time:.0f}ms")
        
        # åŠ è½½å…³é”®ç‚¹æ£€æµ‹æ¨¡å‹
        self._log("ğŸ‘ï¸  åŠ è½½å…³é”®ç‚¹æ¨¡å‹...")
        keypoint_detector = get_keypoint_detector()
        try:
            keypoint_detector.load_model()
            self._log("âœ… å…³é”®ç‚¹æ¨¡å‹åŠ è½½æˆåŠŸ")
            use_keypoints = True
        except FileNotFoundError:
            self._log("âš ï¸  å…³é”®ç‚¹æ¨¡å‹æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ä¼ ç»Ÿé”åº¦è®¡ç®—", "warning")
            use_keypoints = False
        
        # V3.4: åŠ è½½é£ç‰ˆæ£€æµ‹æ¨¡å‹
        use_flight = False
        flight_detector = None
        if self.settings.detect_flight:
            self._log("ğŸ¦… åŠ è½½é£ç‰ˆæ£€æµ‹æ¨¡å‹...")
            flight_detector = get_flight_detector()
            try:
                flight_detector.load_model()
                self._log("âœ… é£ç‰ˆæ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
                use_flight = True
            except FileNotFoundError:
                self._log("âš ï¸  é£ç‰ˆæ£€æµ‹æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè·³è¿‡é£ç‰ˆæ£€æµ‹", "warning")
                use_flight = False
        
        total_files = len(files_tbr)
        self._log(f"ğŸ“ å…± {total_files} ä¸ªæ–‡ä»¶å¾…å¤„ç†\n")
        
        exiftool_mgr = get_exiftool_manager()
        
        # UIè®¾ç½®è½¬ä¸ºåˆ—è¡¨æ ¼å¼
        ui_settings = [
            self.settings.ai_confidence,
            self.settings.sharpness_threshold,
            self.settings.nima_threshold,
            self.settings.save_crop,
            self.settings.normalization_mode
        ]
        
        ai_total_start = time.time()
        
        # ç¡®å®šå®é™…ä½¿ç”¨çš„è®¾å¤‡
        actual_device = get_best_device(device) if hasattr(self, 'get_best_device') else device
        try:
            from utils import get_best_device
            actual_device = get_best_device(device)
        except:
            actual_device = device
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
        use_parallel = False
        is_cpu = actual_device == 'cpu'
        is_gpu = actual_device in ['cuda', 'mps']
        
        # CPU: ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œ
        if is_cpu:
            import multiprocessing
            cpu_threads = self.settings.cpu_threads if hasattr(self.settings, 'cpu_threads') else 0
            if cpu_threads == 0:
                cpu_threads = multiprocessing.cpu_count()
            use_parallel = cpu_threads > 1
            if use_parallel:
                self._log(f"ğŸ”„ ä½¿ç”¨ CPU çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆ{cpu_threads} çº¿ç¨‹ï¼‰")
        
        # GPU: ä½¿ç”¨é˜Ÿåˆ—æ§åˆ¶å¹¶å‘ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
        elif is_gpu:
            gpu_concurrent = self.settings.gpu_concurrent if hasattr(self.settings, 'gpu_concurrent') else 1
            use_parallel = gpu_concurrent > 1
            if use_parallel:
                self._log(f"ğŸ”„ ä½¿ç”¨ GPU é˜Ÿåˆ—å¹¶å‘å¤„ç†ï¼ˆå¹¶å‘æ•°: {gpu_concurrent}ï¼‰")
        
        if use_parallel:
            # å¹¶è¡Œå¤„ç†æ¨¡å¼
            self._process_images_parallel(files_tbr, raw_dict, model, ui_settings, 
                                         use_keypoints, keypoint_detector, use_flight, 
                                         flight_detector, exiftool_mgr, actual_device, 
                                         is_cpu, is_gpu)
        else:
            # ä¸²è¡Œå¤„ç†æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            self._process_images_sequential(files_tbr, raw_dict, model, ui_settings, 
                                          use_keypoints, keypoint_detector, use_flight, 
                                          flight_detector, exiftool_mgr)
        
        ai_total_time = time.time() - ai_total_start
        avg_ai_time = ai_total_time / len(files_tbr) if len(files_tbr) > 0 else 0
        self._log(f"\nâ±ï¸  AIæ£€æµ‹æ€»è€—æ—¶: {ai_total_time:.1f}ç§’ (å¹³å‡ {avg_ai_time:.1f}ç§’/å¼ )")
    
    def _process_images_sequential(self, files_tbr, raw_dict, model, ui_settings,
                                   use_keypoints, keypoint_detector, use_flight,
                                   flight_detector, exiftool_mgr):
        """ä¸²è¡Œå¤„ç†å›¾ç‰‡ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        total_files = len(files_tbr)
        
        for i, filename in enumerate(files_tbr, 1):
            # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
            if self.stop_event and self.stop_event.is_set():
                self.stats['cancelled'] = True
                self._log(f"\nâš ï¸  å¤„ç†å·²å–æ¶ˆï¼ˆå·²å¤„ç† {i-1}/{total_files} å¼ ï¼‰", "warning")
                break
            
            # è®°å½•æ¯å¼ ç…§ç‰‡çš„å¼€å§‹æ—¶é—´
            photo_start_time = time.time()
            
            filepath = os.path.join(self.dir_path, filename)
            file_prefix, _ = os.path.splitext(filename)
            
            # æ›´æ–°è¿›åº¦
            should_update = (i % 5 == 0 or i == total_files or i == 1)
            if should_update:
                progress = int((i / total_files) * 100)
                self._progress(progress)
            
            # ä¼˜åŒ–æµç¨‹ï¼šYOLO â†’ å…³é”®ç‚¹æ£€æµ‹(åœ¨cropä¸Š) â†’ æ¡ä»¶NIMA
            # Phase 1: å…ˆåšYOLOæ£€æµ‹ï¼ˆè·³è¿‡NIMAï¼‰ï¼Œè·å–é¸Ÿçš„ä½ç½®å’Œbbox
            try:
                result = detect_and_draw_birds(
                    filepath, model, None, self.dir_path, ui_settings, None, skip_nima=True
                )
                if result is None:
                    self._log(f"  âš ï¸  æ— æ³•å¤„ç†(AIæ¨ç†å¤±è´¥)", "error")
                    continue
            except Exception as e:
                self._log(f"  âŒ å¤„ç†å¼‚å¸¸: {e}", "error")
                continue
            
            # è§£æ„ AI ç»“æœ (åŒ…å«bbox, å›¾åƒå°ºå¯¸, åˆ†å‰²æ©ç ) - V3.2ç§»é™¤BRISQUE
            detected, _, confidence, sharpness, _, bird_bbox, img_dims, bird_mask = result
            
            # Phase 2: å…³é”®ç‚¹æ£€æµ‹ï¼ˆåœ¨è£å‰ªåŒºåŸŸä¸Šæ‰§è¡Œï¼Œæ›´å‡†ç¡®ï¼‰
            all_keypoints_hidden = False
            both_eyes_hidden = False  # ä¿ç•™ç”¨äºæ—¥å¿—/è°ƒè¯•
            best_eye_visibility = 0.0  # V3.8: çœ¼ç›æœ€é«˜ç½®ä¿¡åº¦ï¼Œç”¨äºå°é¡¶é€»è¾‘
            head_sharpness = 0.0
            has_visible_eye = False
            has_visible_beak = False
            left_eye_vis = 0.0
            right_eye_vis = 0.0
            beak_vis = 0.0
            
            # V3.9: å¤´éƒ¨åŒºåŸŸä¿¡æ¯ï¼ˆç”¨äºå¯¹ç„¦éªŒè¯ï¼‰
            head_center_orig = None
            head_radius_val = None
            
            # V3.2ä¼˜åŒ–: åªè¯»å–åŸå›¾ä¸€æ¬¡ï¼Œåœ¨å…³é”®ç‚¹æ£€æµ‹å’ŒNIMAè®¡ç®—ä¸­å¤ç”¨
            orig_img = None  # åŸå›¾ç¼“å­˜
            bird_crop_bgr = None  # è£å‰ªåŒºåŸŸç¼“å­˜ï¼ˆBGRï¼‰
            bird_crop_mask = None # è£å‰ªåŒºåŸŸæ©ç ç¼“å­˜
            bird_mask_orig = None  # V3.9: åŸå›¾å°ºå¯¸çš„åˆ†å‰²æ©ç ï¼ˆç”¨äºå¯¹ç„¦éªŒè¯ï¼‰
            
            if use_keypoints and detected and bird_bbox is not None and img_dims is not None:
                try:
                    import cv2
                    from utils import read_image
                    orig_img = read_image(filepath)  # åªè¯»å–ä¸€æ¬¡!ï¼ˆæ”¯æŒ HEIF/HEICï¼‰
                    if orig_img is not None:
                        h_orig, w_orig = orig_img.shape[:2]
                        # è·å–YOLOå¤„ç†æ—¶çš„å›¾åƒå°ºå¯¸
                        w_resized, h_resized = img_dims
                        
                        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼šåŸå›¾ / ç¼©æ”¾å›¾
                        scale_x = w_orig / w_resized
                        scale_y = h_orig / h_resized
                        
                        # å°†bboxä»ç¼©æ”¾å°ºå¯¸è½¬æ¢åˆ°åŸå›¾å°ºå¯¸
                        x, y, w, h = bird_bbox
                        x_orig = int(x * scale_x)
                        y_orig = int(y * scale_y)
                        w_orig_box = int(w * scale_x)
                        h_orig_box = int(h * scale_y)
                        
                        # ç¡®ä¿è¾¹ç•Œæœ‰æ•ˆ
                        x_orig = max(0, min(x_orig, w_orig - 1))
                        y_orig = max(0, min(y_orig, h_orig - 1))
                        w_orig_box = min(w_orig_box, w_orig - x_orig)
                        h_orig_box = min(h_orig_box, h_orig - y_orig)
                        
                        # è£å‰ªé¸Ÿçš„åŒºåŸŸï¼ˆä¿å­˜BGRç‰ˆæœ¬ä¾›NIMAä½¿ç”¨ï¼‰
                        bird_crop_bgr = orig_img[y_orig:y_orig+h_orig_box, x_orig:x_orig+w_orig_box]
                        
                        # åŒæ ·è£å‰ª mask (å¦‚æœå­˜åœ¨)
                        if bird_mask is not None:
                            # ç¼©æ”¾ mask åˆ°åŸå›¾å°ºå¯¸ (Maskæ˜¯æ•´å›¾çš„)
                            # bird_mask æ˜¯ (h_resized, w_resized)ï¼Œéœ€è¦æ”¾å¤§åˆ° (h_orig, w_orig)
                            if bird_mask.shape[:2] != (h_orig, w_orig):
                                # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ä¿æŒäºŒå€¼ç‰¹æ€§
                                bird_mask_orig = cv2.resize(bird_mask, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)
                            else:
                                bird_mask_orig = bird_mask
                                
                            bird_crop_mask = bird_mask_orig[y_orig:y_orig+h_orig_box, x_orig:x_orig+w_orig_box]
                        
                        if bird_crop_bgr.size > 0:
                            crop_rgb = cv2.cvtColor(bird_crop_bgr, cv2.COLOR_BGR2RGB)
                            # åœ¨è£å‰ªåŒºåŸŸä¸Šè¿›è¡Œå…³é”®ç‚¹æ£€æµ‹ï¼Œä¼ å…¥åˆ†å‰²æ©ç 
                            kp_result = keypoint_detector.detect(
                                crop_rgb, 
                                box=(x_orig, y_orig, w_orig_box, h_orig_box),
                                seg_mask=bird_crop_mask  # ä¼ å…¥åˆ†å‰²æ©ç 
                            )
                            if kp_result is not None:
                                both_eyes_hidden = kp_result.both_eyes_hidden  # ä¿ç•™å…¼å®¹
                                all_keypoints_hidden = kp_result.all_keypoints_hidden  # æ–°å±æ€§
                                best_eye_visibility = kp_result.best_eye_visibility  # V3.8
                                has_visible_eye = kp_result.visible_eye is not None
                                has_visible_beak = kp_result.beak_vis >= 0.3  # V3.8: é™ä½åˆ° 0.3
                                left_eye_vis = kp_result.left_eye_vis
                                right_eye_vis = kp_result.right_eye_vis
                                beak_vis = kp_result.beak_vis
                                head_sharpness = kp_result.head_sharpness
                                
                                # V3.9: è®¡ç®—å¤´éƒ¨åŒºåŸŸä¸­å¿ƒå’ŒåŠå¾„ï¼ˆç”¨äºå¯¹ç„¦éªŒè¯ï¼‰
                                ch, cw = bird_crop_bgr.shape[:2]
                                # é€‰æ‹©æ›´å¯è§çš„çœ¼ç›ä½œä¸ºå¤´éƒ¨ä¸­å¿ƒ
                                if left_eye_vis >= right_eye_vis and left_eye_vis >= 0.3:
                                    eye_px = (int(kp_result.left_eye[0] * cw), int(kp_result.left_eye[1] * ch))
                                elif right_eye_vis >= 0.3:
                                    eye_px = (int(kp_result.right_eye[0] * cw), int(kp_result.right_eye[1] * ch))
                                else:
                                    eye_px = None
                                
                                if eye_px is not None:
                                    # è½¬æ¢åˆ°åŸå›¾åæ ‡
                                    head_center_orig = (eye_px[0] + x_orig, eye_px[1] + y_orig)
                                    # è®¡ç®—åŠå¾„
                                    beak_px = (int(kp_result.beak[0] * cw), int(kp_result.beak[1] * ch))
                                    if beak_vis >= 0.3:
                                        import math
                                        dist = math.sqrt((eye_px[0] - beak_px[0])**2 + (eye_px[1] - beak_px[1])**2)
                                        head_radius_val = int(dist * 1.2)
                                    else:
                                        head_radius_val = int(max(cw, ch) * 0.15)
                                    head_radius_val = max(20, min(head_radius_val, min(cw, ch) // 2))
                except Exception as e:
                    self._log(f"  âš ï¸ å…³é”®ç‚¹æ£€æµ‹å¼‚å¸¸: {e}", "warning")
                    # import traceback
                    # self._log(traceback.format_exc(), "error")
                    pass
            
            # Phase 3: æ ¹æ®å…³é”®ç‚¹å¯è§æ€§å†³å®šæ˜¯å¦è®¡ç®—TOPIQ
            # V4.0: çœ¼ç›å¯è§åº¦ < 30% æ—¶ä¹Ÿè·³è¿‡ TOPIQï¼ˆèŠ‚çœæ—¶é—´ï¼‰
            topiq = None
            if detected and not all_keypoints_hidden and best_eye_visibility >= 0.3:
                # åŒçœ¼å¯è§ï¼Œéœ€è¦è®¡ç®—NIMAä»¥è¿›è¡Œæ˜Ÿçº§åˆ¤å®š
                try:
                    from iqa_scorer import get_iqa_scorer
                    from utils import get_best_device
                    import time as time_module
                    
                    step_start = time_module.time()
                    # ä½¿ç”¨è®¾ç½®ä¸­æŒ‡å®šçš„è®¾å¤‡
                    device = get_best_device(self.settings.device if hasattr(self.settings, 'device') else 'auto')
                    scorer = get_iqa_scorer(device=device)
                    
                    # V3.7: ä½¿ç”¨å…¨å›¾è€Œéè£å‰ªå›¾è¿›è¡ŒTOPIQç¾å­¦è¯„åˆ†
                    # å…¨å›¾è¯„åˆ† + å¤´éƒ¨é”åº¦é˜ˆå€¼ æ˜¯æ›´å¥½çš„ç»„åˆï¼š
                    # - å…¨å›¾è¯„åˆ†è¯„ä¼°æ•´ä½“ç”»é¢æ„å›¾å’Œç¾æ„Ÿ
                    # - å¤´éƒ¨é”åº¦é˜ˆå€¼ç¡®ä¿é¸Ÿæœ¬èº«è¶³å¤Ÿæ¸…æ™°
                    topiq = scorer.calculate_nima(filepath)
                    
                    topiq_time = (time_module.time() - step_start) * 1000
                except Exception as e:
                    pass  # V3.3: ç®€åŒ–æ—¥å¿—ï¼Œé™é»˜ TOPIQ è®¡ç®—å¤±è´¥
            # V3.8: ç§»é™¤è·³è¿‡æ—¥å¿—ï¼Œæ”¹ç”¨ all_keypoints_hidden åè·³è¿‡çš„æƒ…å†µä¼šå°‘å¾ˆå¤š
            
            # Phase 4: V3.4 é£ç‰ˆæ£€æµ‹ï¼ˆåœ¨é¸Ÿçš„è£å‰ªåŒºåŸŸä¸Šæ‰§è¡Œï¼‰
            is_flying = False
            flight_confidence = 0.0
            if use_flight and detected and bird_crop_bgr is not None and bird_crop_bgr.size > 0:
                try:
                    flight_result = flight_detector.detect(bird_crop_bgr)
                    is_flying = flight_result.is_flying
                    flight_confidence = flight_result.confidence
                    # DEBUG: è¾“å‡ºé£ç‰ˆæ£€æµ‹ç»“æœ
                    # self._log(f"  ğŸ¦… é£ç‰ˆæ£€æµ‹: is_flying={is_flying}, conf={flight_confidence:.2f}")
                except Exception as e:
                    self._log(f"  âš ï¸ é£ç‰ˆæ£€æµ‹å¼‚å¸¸: {e}", "warning")
            
            # Phase 5: V3.8 æ›å…‰æ£€æµ‹ï¼ˆåœ¨é¸Ÿçš„è£å‰ªåŒºåŸŸä¸Šæ‰§è¡Œï¼‰
            is_overexposed = False
            is_underexposed = False
            if self.settings.detect_exposure and detected and bird_crop_bgr is not None and bird_crop_bgr.size > 0:
                try:
                    exposure_detector = get_exposure_detector()
                    exposure_result = exposure_detector.detect(
                        bird_crop_bgr, 
                        threshold=self.settings.exposure_threshold
                    )
                    is_overexposed = exposure_result.is_overexposed
                    is_underexposed = exposure_result.is_underexposed
                except Exception as e:
                    pass  # æ›å…‰æ£€æµ‹å¤±è´¥ä¸å½±å“å¤„ç†
            
            # V3.8: é£ç‰ˆåŠ æˆï¼ˆä»…å½“ confidence >= 0.5 ä¸” is_flying æ—¶ï¼‰
            # é”åº¦+100ï¼Œç¾å­¦+0.5ï¼ŒåŠ æˆåçš„å€¼ç”¨äºè¯„åˆ†
            rating_sharpness = head_sharpness
            rating_topiq = topiq
            if is_flying and confidence >= 0.5:
                rating_sharpness = head_sharpness + 100
                if topiq is not None:
                    rating_topiq = topiq + 0.5
            
            # V4.0 ä¼˜åŒ–: å…ˆè®¡ç®—åˆæ­¥è¯„åˆ†ï¼ˆä¸è€ƒè™‘å¯¹ç„¦ï¼‰ï¼Œåªå¯¹ 1 æ˜Ÿä»¥ä¸Šåšå¯¹ç„¦æ£€æµ‹
            # è¿™æ · 0 æ˜Ÿå’Œ -1 æ˜Ÿç…§ç‰‡ä¸éœ€è¦è°ƒç”¨ exiftoolï¼ŒèŠ‚çœå¤§é‡æ—¶é—´
            preliminary_result = self.rating_engine.calculate(
                detected=detected,
                confidence=confidence,
                sharpness=head_sharpness,   # V4.0: åŸå§‹é”åº¦ï¼ˆé£é¸ŸåŠ æˆåœ¨å¼•æ“å†…ï¼‰
                topiq=topiq,                # V4.0: åŸå§‹ç¾å­¦ï¼ˆé£é¸ŸåŠ æˆåœ¨å¼•æ“å†…ï¼‰
                all_keypoints_hidden=all_keypoints_hidden,
                best_eye_visibility=best_eye_visibility,
                is_overexposed=is_overexposed,
                is_underexposed=is_underexposed,
                focus_sharpness_weight=1.0,  # åˆæ­¥è¯„åˆ†ä¸è€ƒè™‘å¯¹ç„¦
                focus_topiq_weight=1.0,
                is_flying=False,             # åˆæ­¥è¯„åˆ†ä¸è€ƒè™‘é£é¸ŸåŠ æˆ
            )
            
            # Phase 6: V4.0 å¯¹ç„¦ç‚¹éªŒè¯ï¼ˆä»…å¯¹ 1 æ˜Ÿä»¥ä¸Šç…§ç‰‡ï¼‰
            # 4 å±‚æ£€æµ‹è¿”å›ä¸¤ä¸ªæƒé‡: é”åº¦æƒé‡ + ç¾å­¦æƒé‡
            focus_sharpness_weight = 1.0  # é»˜è®¤æ— å½±å“
            focus_topiq_weight = 1.0      # é»˜è®¤æ— å½±å“
            focus_x, focus_y = None, None
            
            # åªå¯¹ 1 æ˜Ÿä»¥ä¸Šç…§ç‰‡åšå¯¹ç„¦æ£€æµ‹ï¼ˆ0 æ˜Ÿå’Œ -1 æ˜Ÿè·³è¿‡ï¼ŒèŠ‚çœæ—¶é—´ï¼‰
            if preliminary_result.rating >= 1:
                if detected and bird_bbox is not None and img_dims is not None:
                    if file_prefix in raw_dict:
                        raw_ext = raw_dict[file_prefix]
                        raw_path = os.path.join(self.dir_path, file_prefix + raw_ext)
                        # Nikon, Sony, Canon, Olympus, Fujifilm, Panasonic å…¨æ”¯æŒ
                        if raw_ext.lower() in ['.nef', '.nrw', '.arw', '.cr3', '.cr2', '.orf', '.raf', '.rw2']:
                            try:
                                focus_detector = get_focus_detector()
                                focus_result = focus_detector.detect(raw_path)
                                if focus_result is not None:
                                    # V3.9 ä¿®å¤ï¼šä½¿ç”¨åŸå›¾å°ºå¯¸è€Œé resize åçš„ img_dims
                                    # head_center_orig å’Œ bird_mask_orig éƒ½æ˜¯åŸå›¾åæ ‡ç³»
                                    orig_dims = (w_orig, h_orig) if 'w_orig' in dir() and 'h_orig' in dir() else img_dims
                                    # V4.0: è¿”å›å…ƒç»„ (é”åº¦æƒé‡, ç¾å­¦æƒé‡)
                                    focus_sharpness_weight, focus_topiq_weight = verify_focus_in_bbox(
                                        focus_result, 
                                        bird_bbox, 
                                        orig_dims,  # ä½¿ç”¨åŸå›¾å°ºå¯¸ï¼
                                        seg_mask=bird_mask_orig,
                                        head_center=head_center_orig,
                                        head_radius=head_radius_val,
                                    )
                                    focus_x, focus_y = focus_result.x, focus_result.y
                            except Exception as e:
                                pass  # å¯¹ç„¦æ£€æµ‹å¤±è´¥ä¸å½±å“å¤„ç†
            
            # V4.0: æœ€ç»ˆè¯„åˆ†è®¡ç®—ï¼ˆä¼ å…¥å¯¹ç„¦æƒé‡å’Œé£é¸ŸçŠ¶æ€ï¼‰
            # æ³¨æ„: ç°åœ¨æ€»æ˜¯é‡æ–°è®¡ç®—ï¼Œå› ä¸ºéœ€è¦ä¼ å…¥ is_flying å‚æ•°
            rating_result = self.rating_engine.calculate(
                detected=detected,
                confidence=confidence,
                sharpness=head_sharpness,  # V4.0: ä½¿ç”¨åŸå§‹é”åº¦ï¼Œæƒé‡åœ¨å¼•æ“å†…åº”ç”¨
                topiq=topiq,              # V4.0: ä½¿ç”¨åŸå§‹ç¾å­¦ï¼Œæƒé‡åœ¨å¼•æ“å†…åº”ç”¨
                all_keypoints_hidden=all_keypoints_hidden,
                best_eye_visibility=best_eye_visibility,
                is_overexposed=is_overexposed,
                is_underexposed=is_underexposed,
                focus_sharpness_weight=focus_sharpness_weight,  # V4.0: é”åº¦æƒé‡
                focus_topiq_weight=focus_topiq_weight,          # V4.0: ç¾å­¦æƒé‡
                is_flying=is_flying,                            # V4.0: é£é¸Ÿä¹˜æ³•åŠ æˆ
            )
            
            rating_value = rating_result.rating
            pick = rating_result.pick
            reason = rating_result.reason
            
            # V4.0: æ ¹æ® focus_sharpness_weight è®¡ç®—å¯¹ç„¦çŠ¶æ€æ–‡æœ¬
            # åªæœ‰æ£€æµ‹åˆ°é¸Ÿæ‰è®¾ç½®å¯¹ç„¦çŠ¶æ€ï¼Œé¿å…æ— é¸Ÿç…§ç‰‡ä¹Ÿå†™å…¥
            focus_status = None
            focus_status_en = None  # è‹±æ–‡ç‰ˆæœ¬ç”¨äºè°ƒè¯•å›¾ï¼ˆé¿å…ä¸­æ–‡å­—ä½“é—®é¢˜ï¼‰
            if detected:  # åªæœ‰æ£€æµ‹åˆ°é¸Ÿæ‰è®¡ç®—å¯¹ç„¦çŠ¶æ€
                if focus_sharpness_weight > 1.0:
                    focus_status = "ç²¾å‡†"
                    focus_status_en = "BEST"
                elif focus_sharpness_weight >= 1.0:
                    focus_status = "é¸Ÿèº«"
                    focus_status_en = "GOOD"
                elif focus_sharpness_weight >= 0.7:
                    focus_status = "åç§»"
                    focus_status_en = "BAD"
                elif focus_sharpness_weight < 0.7:
                    focus_status = "è„±ç„¦"
                    focus_status_en = "WORST"
            
            # V3.9: ç”Ÿæˆè°ƒè¯•å¯è§†åŒ–å›¾ï¼ˆä»…å¯¹æœ‰é¸Ÿçš„ç…§ç‰‡ï¼‰
            if detected and bird_crop_bgr is not None:
                # è®¡ç®—è£å‰ªåŒºåŸŸå†…çš„åæ ‡
                head_center_crop = None
                if head_center_orig is not None:
                    # è½¬æ¢åˆ°è£å‰ªåŒºåŸŸåæ ‡
                    head_center_crop = (head_center_orig[0] - x_orig, head_center_orig[1] - y_orig)
                
                focus_point_crop = None
                if focus_x is not None and focus_y is not None:
                    # å¯¹ç„¦ç‚¹ä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºè£å‰ªåŒºåŸŸåæ ‡
                    # ä½¿ç”¨åŸå›¾å°ºå¯¸ (w_orig, h_orig) è€Œä¸æ˜¯ resize åçš„ img_dims
                    if 'w_orig' in dir() and 'h_orig' in dir():
                        fx_px = int(focus_x * w_orig) - x_orig
                        fy_px = int(focus_y * h_orig) - y_orig
                        focus_point_crop = (fx_px, fy_px)
                
                try:
                    self._save_debug_crop(
                        filename,
                        bird_crop_bgr,
                        bird_crop_mask if 'bird_crop_mask' in dir() else None,
                        head_center_crop,
                        head_radius_val,
                        focus_point_crop,
                        focus_status_en  # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾
                    )
                except Exception as e:
                    pass  # è°ƒè¯•å›¾ç”Ÿæˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            
            # è®¡ç®—çœŸæ­£æ€»è€—æ—¶å¹¶è¾“å‡ºç®€åŒ–æ—¥å¿—
            photo_time_ms = (time.time() - photo_start_time) * 1000
            has_exposure_issue = is_overexposed or is_underexposed
            self._log_photo_result_simple(i, total_files, filename, rating_value, reason, photo_time_ms, is_flying, has_exposure_issue, focus_status)
            
            # è®°å½•ç»Ÿè®¡
            self._update_stats(rating_value, is_flying, has_exposure_issue)
            
            # è®°å½•å¤„ç†æ—¶é—´ç»Ÿè®¡
            self.stats['photo_times'].append((filename, photo_time_ms, detected))
            if detected:
                self.stats['with_bird_times'].append(photo_time_ms)
            else:
                self.stats['no_bird_times'].append(photo_time_ms)
            
            # V3.4: ç¡®å®šè¦å¤„ç†çš„ç›®æ ‡æ–‡ä»¶ï¼ˆRAW ä¼˜å…ˆï¼Œæ²¡æœ‰åˆ™ç”¨ JPEG/HEIFï¼‰
            # æ³¨æ„ï¼šå¯¹äº HEIF/HEIC/HIF æ–‡ä»¶ï¼Œè™½ç„¶ AI æ¨ç†æ—¶ä½¿ç”¨äº†ä¸´æ—¶ JPGï¼Œ
            # ä½† EXIF å…ƒæ•°æ®ä¼šå†™å…¥åŸå§‹æ–‡ä»¶ï¼ˆfilepath å§‹ç»ˆæŒ‡å‘åŸå§‹æ–‡ä»¶ï¼‰
            target_file_path = None
            target_extension = None
            
            if file_prefix in raw_dict:
                # æœ‰å¯¹åº”çš„ RAW æ–‡ä»¶
                raw_extension = raw_dict[file_prefix]
                target_file_path = os.path.join(self.dir_path, file_prefix + raw_extension)
                target_extension = raw_extension
                
                # å†™å…¥ EXIFï¼ˆä»…é™ RAW æ–‡ä»¶ï¼‰
                if os.path.exists(target_file_path):
                    # V4.0: æ ‡ç­¾é€»è¾‘ - é£é¸Ÿç»¿è‰²ä¼˜å…ˆï¼Œå¤´éƒ¨å¯¹ç„¦çº¢è‰²
                    label = None
                    if is_flying:
                        label = 'Green'
                    elif focus_sharpness_weight > 1.0:  # å¤´éƒ¨å¯¹ç„¦ (1.1)
                        label = 'Red'
                    
                    # V4.0: æ„å»ºè¯¦ç»†è¯„åˆ†è¯´æ˜
                    caption_parts = []
                    caption_parts.append(f"[SuperPicky V4.0 è¯„åˆ†æŠ¥å‘Š]")
                    caption_parts.append(f"æœ€ç»ˆè¯„åˆ†: {rating_value}æ˜Ÿ | {reason}")
                    caption_parts.append("")
                    
                    # åŸå§‹æ•°æ®
                    caption_parts.append("[åŸå§‹æ£€æµ‹æ•°æ®]")
                    caption_parts.append(f"AIç½®ä¿¡åº¦: {confidence:.0%}")
                    caption_parts.append(f"å¤´éƒ¨é”åº¦: {head_sharpness:.2f}" if head_sharpness else "å¤´éƒ¨é”åº¦: æ— æ³•è®¡ç®—")
                    caption_parts.append(f"TOPIQç¾å­¦: {topiq:.2f}" if topiq else "TOPIQç¾å­¦: æœªè®¡ç®—")
                    caption_parts.append(f"çœ¼ç›å¯è§åº¦: {best_eye_visibility:.0%}")
                    caption_parts.append("")
                    
                    # ä¿®æ­£å› å­
                    caption_parts.append("[ä¿®æ­£å› å­]")
                    caption_parts.append(f"å¯¹ç„¦é”åº¦æƒé‡: {focus_sharpness_weight:.2f}")
                    caption_parts.append(f"å¯¹ç„¦ç¾å­¦æƒé‡: {focus_topiq_weight:.2f}")
                    caption_parts.append(f"æ˜¯å¦é£é¸Ÿ: {'æ˜¯ (é”åº¦Ã—1.2, ç¾å­¦Ã—1.1)' if is_flying else 'å¦'}")
                    caption_parts.append("")
                    
                    # è°ƒæ•´åæ•°å€¼
                    caption_parts.append("[è°ƒæ•´åæ•°å€¼]")
                    adj_sharpness = head_sharpness * focus_sharpness_weight if head_sharpness else 0
                    if is_flying and head_sharpness:
                        adj_sharpness = adj_sharpness * 1.2
                    caption_parts.append(f"è°ƒæ•´åé”åº¦: {adj_sharpness:.2f} (é˜ˆå€¼400)")
                    
                    if topiq:
                        adj_topiq = topiq * focus_topiq_weight
                        if is_flying:
                            adj_topiq = adj_topiq * 1.1
                        caption_parts.append(f"è°ƒæ•´åç¾å­¦: {adj_topiq:.2f} (é˜ˆå€¼5.0)")
                    caption_parts.append("")
                    
                    # æ¸è¿›å¯è§åº¦
                    visibility_weight = max(0.5, min(1.0, best_eye_visibility * 2))
                    caption_parts.append(f"[å¯è§åº¦é™æƒ]")
                    caption_parts.append(f"å¯è§åº¦æƒé‡: {visibility_weight:.2f}")
                    caption_parts.append(f"å…¬å¼: max(0.5, min(1.0, {best_eye_visibility:.2f}Ã—2))")
                    
                    caption = " | ".join(caption_parts)
                    
                    single_batch = [{
                        'file': target_file_path,
                        'rating': rating_value if rating_value >= 0 else 0,
                        'pick': pick,
                        'sharpness': head_sharpness,
                        'nima_score': topiq,  # V3.8: å®é™…æ˜¯ TOPIQ åˆ†æ•°
                        'label': label,
                        'focus_status': focus_status,  # V3.9: å¯¹ç„¦çŠ¶æ€å†™å…¥ Country å­—æ®µ
                        'caption': caption,  # V4.0: è¯¦ç»†è¯„åˆ†è¯´æ˜
                    }]
                    exiftool_mgr.batch_set_metadata(single_batch)
            else:
                # V3.4: çº¯ JPEG/HEIF æ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº” RAWï¼‰
                # æ³¨æ„ï¼šfilepath å§‹ç»ˆæ˜¯åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ .hifï¼‰ï¼Œå³ä½¿ AI æ¨ç†æ—¶ä½¿ç”¨äº†ä¸´æ—¶ JPG
                target_file_path = filepath  # ä½¿ç”¨åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆHIF/HEIF/HEIC/JPGï¼‰
                target_extension = os.path.splitext(filename)[1]
            
            # V3.4: ä»¥ä¸‹æ“ä½œå¯¹ RAW å’Œçº¯ JPEG éƒ½æ‰§è¡Œ
            if target_file_path and os.path.exists(target_file_path):
                # æ›´æ–° CSV ä¸­çš„å…³é”®ç‚¹æ•°æ®ï¼ˆV3.9: æ·»åŠ å¯¹ç„¦çŠ¶æ€å’Œåæ ‡ï¼‰
                self._update_csv_keypoint_data(
                    file_prefix, 
                    rating_sharpness,  # ä½¿ç”¨åŠ æˆåçš„é”åº¦
                    has_visible_eye, 
                    has_visible_beak,
                    left_eye_vis,
                    right_eye_vis,
                    beak_vis,
                    rating_topiq,  # V3.8: æ”¹ä¸º rating_topiq
                    rating_value,
                    is_flying,
                    flight_confidence,
                    focus_status,  # V3.9: å¯¹ç„¦çŠ¶æ€
                    focus_x,  # V3.9: å¯¹ç„¦ç‚¹Xåæ ‡
                    focus_y   # V3.9: å¯¹ç„¦ç‚¹Yåæ ‡
                )
                
                # æ”¶é›†3æ˜Ÿç…§ç‰‡ï¼ˆV3.8: ä½¿ç”¨åŠ æˆåçš„å€¼ï¼‰
                if rating_value == 3 and rating_topiq is not None:
                    self.star_3_photos.append({
                        'file': target_file_path,
                        'nima': rating_topiq,  # V3.8: å®é™…æ˜¯ TOPIQï¼Œä¿ç•™å­—æ®µåå…¼å®¹
                        'sharpness': rating_sharpness  # åŠ æˆåçš„é”åº¦
                    })
                
                # è®°å½•è¯„åˆ†ï¼ˆç”¨äºæ–‡ä»¶ç§»åŠ¨ï¼‰
                self.file_ratings[file_prefix] = rating_value
                
                # è®°å½•2æ˜ŸåŸå› ï¼ˆç”¨äºåˆ†ç›®å½•ï¼‰ï¼ˆV3.8: ä½¿ç”¨åŠ æˆåçš„å€¼ï¼‰
                if rating_value == 2:
                    sharpness_ok = rating_sharpness >= self.settings.sharpness_threshold
                    topiq_ok = rating_topiq is not None and rating_topiq >= self.settings.nima_threshold
                    if sharpness_ok and not topiq_ok:
                        self.star2_reasons[file_prefix] = 'sharpness'
                    elif topiq_ok and not sharpness_ok:
                        self.star2_reasons[file_prefix] = 'nima'  # ä¿ç•™åŸå­—æ®µåå…¼å®¹
                    else:
                        self.star2_reasons[file_prefix] = 'both'
    
    def _process_images_parallel(self, files_tbr, raw_dict, model, ui_settings,
                                 use_keypoints, keypoint_detector, use_flight,
                                 flight_detector, exiftool_mgr, actual_device,
                                 is_cpu, is_gpu):
        """å¹¶è¡Œå¤„ç†å›¾ç‰‡ï¼ˆCPUçº¿ç¨‹æ± æˆ–GPUé˜Ÿåˆ—ï¼‰"""
        total_files = len(files_tbr)
        
        if is_cpu:
            # CPU: ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œ
            import multiprocessing
            cpu_threads = self.settings.cpu_threads if hasattr(self.settings, 'cpu_threads') else 0
            if cpu_threads == 0:
                cpu_threads = multiprocessing.cpu_count()
            
            # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
            tasks = [(i, filename) for i, filename in enumerate(files_tbr, 1)]
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†
            with ThreadPoolExecutor(max_workers=cpu_threads) as executor:
                futures = {
                    executor.submit(
                        self._process_single_image,
                        i, filename, total_files, raw_dict, model, ui_settings,
                        use_keypoints, keypoint_detector, use_flight,
                        flight_detector, exiftool_mgr
                    ): (i, filename)
                    for i, filename in tasks
                }
                
                completed = 0
                for future in as_completed(futures):
                    if self.stop_event and self.stop_event.is_set():
                        break
                    try:
                        future.result()  # è·å–ç»“æœï¼ˆå¯èƒ½æŠ›å‡ºå¼‚å¸¸ï¼‰
                        completed += 1
                        if completed % 5 == 0 or completed == total_files:
                            progress = int((completed / total_files) * 100)
                            self._progress(progress)
                    except Exception as e:
                        i, filename = futures[future]
                        self._log(f"  âŒ å¤„ç†å¤±è´¥ {filename}: {e}", "error")
        
        elif is_gpu:
            # GPU: ä½¿ç”¨é˜Ÿåˆ—æ§åˆ¶å¹¶å‘ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
            gpu_concurrent = self.settings.gpu_concurrent if hasattr(self.settings, 'gpu_concurrent') else 1
            import queue
            import threading
            
            task_queue = queue.Queue()
            for i, filename in enumerate(files_tbr, 1):
                task_queue.put((i, filename))
            
            # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
            semaphore = threading.Semaphore(gpu_concurrent)
            results_lock = threading.Lock()
            completed_count = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨çº¿ç¨‹é—´å…±äº«
            
            def worker():
                while True:
                    if self.stop_event and self.stop_event.is_set():
                        break
                    try:
                        i, filename = task_queue.get_nowait()
                    except queue.Empty:
                        break
                    
                    with semaphore:  # æ§åˆ¶å¹¶å‘æ•°
                        try:
                            self._process_single_image(
                                i, filename, total_files, raw_dict, model, ui_settings,
                                use_keypoints, keypoint_detector, use_flight,
                                flight_detector, exiftool_mgr
                            )
                            with results_lock:
                                completed_count[0] += 1
                                if completed_count[0] % 5 == 0 or completed_count[0] == total_files:
                                    progress = int((completed_count[0] / total_files) * 100)
                                    self._progress(progress)
                        except Exception as e:
                            self._log(f"  âŒ å¤„ç†å¤±è´¥ {filename}: {e}", "error")
                    task_queue.task_done()
            
            # å¯åŠ¨å·¥ä½œçº¿ç¨‹ï¼ˆæ¯ä¸ªå¹¶å‘ä»»åŠ¡ä¸€ä¸ªçº¿ç¨‹ï¼‰
            threads = []
            for _ in range(gpu_concurrent):
                t = threading.Thread(target=worker)
                t.start()
                threads.append(t)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            task_queue.join()
            for t in threads:
                t.join()
    
    def _process_single_image(self, i, filename, total_files, raw_dict, model, ui_settings,
                             use_keypoints, keypoint_detector, use_flight,
                             flight_detector, exiftool_mgr):
        """å¤„ç†å•å¼ å›¾ç‰‡ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if self.stop_event and self.stop_event.is_set():
            return
        
        # è®°å½•æ¯å¼ ç…§ç‰‡çš„å¼€å§‹æ—¶é—´
        photo_start_time = time.time()
        
        filepath = os.path.join(self.dir_path, filename)
        file_prefix, _ = os.path.splitext(filename)
        
        # ä¼˜åŒ–æµç¨‹ï¼šYOLO â†’ å…³é”®ç‚¹æ£€æµ‹(åœ¨cropä¸Š) â†’ æ¡ä»¶NIMA
        # Phase 1: å…ˆåšYOLOæ£€æµ‹ï¼ˆè·³è¿‡NIMAï¼‰ï¼Œè·å–é¸Ÿçš„ä½ç½®å’Œbbox
        try:
            result = detect_and_draw_birds(
                filepath, model, None, self.dir_path, ui_settings, None, skip_nima=True
            )
            if result is None:
                return
        except Exception as e:
            return
        
        # è§£æ„ AI ç»“æœ
        detected, _, confidence, sharpness, _, bird_bbox, img_dims, bird_mask = result
        
        # Phase 2: å…³é”®ç‚¹æ£€æµ‹ï¼ˆåœ¨è£å‰ªåŒºåŸŸä¸Šæ‰§è¡Œï¼Œæ›´å‡†ç¡®ï¼‰
        all_keypoints_hidden = False
        best_eye_visibility = 0.0
        head_sharpness = 0.0
        has_visible_eye = False
        has_visible_beak = False
        left_eye_vis = 0.0
        right_eye_vis = 0.0
        beak_vis = 0.0
        head_center_orig = None
        head_radius_val = None
        orig_img = None
        bird_crop_bgr = None
        bird_crop_mask = None
        bird_mask_orig = None
        
        if use_keypoints and detected and bird_bbox is not None and img_dims is not None:
            try:
                import cv2
                from utils import read_image
                orig_img = read_image(filepath)
                if orig_img is not None:
                    h_orig, w_orig = orig_img.shape[:2]
                    w_resized, h_resized = img_dims
                    scale_x = w_orig / w_resized
                    scale_y = h_orig / h_resized
                    x, y, w, h = bird_bbox
                    x_orig = max(0, min(int(x * scale_x), w_orig - 1))
                    y_orig = max(0, min(int(y * scale_y), h_orig - 1))
                    w_orig_box = min(int(w * scale_x), w_orig - x_orig)
                    h_orig_box = min(int(h * scale_y), h_orig - y_orig)
                    bird_crop_bgr = orig_img[y_orig:y_orig+h_orig_box, x_orig:x_orig+w_orig_box]
                    
                    if bird_mask is not None:
                        if bird_mask.shape[:2] != (h_orig, w_orig):
                            bird_mask_orig = cv2.resize(bird_mask, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)
                        else:
                            bird_mask_orig = bird_mask
                        bird_crop_mask = bird_mask_orig[y_orig:y_orig+h_orig_box, x_orig:x_orig+w_orig_box]
                    
                    if bird_crop_bgr.size > 0:
                        crop_rgb = cv2.cvtColor(bird_crop_bgr, cv2.COLOR_BGR2RGB)
                        kp_result = keypoint_detector.detect(
                            crop_rgb, 
                            box=(x_orig, y_orig, w_orig_box, h_orig_box),
                            seg_mask=bird_crop_mask
                        )
                        if kp_result is not None:
                            all_keypoints_hidden = kp_result.all_keypoints_hidden
                            best_eye_visibility = kp_result.best_eye_visibility
                            has_visible_eye = kp_result.visible_eye is not None
                            has_visible_beak = kp_result.beak_vis >= 0.3
                            left_eye_vis = kp_result.left_eye_vis
                            right_eye_vis = kp_result.right_eye_vis
                            beak_vis = kp_result.beak_vis
                            head_sharpness = kp_result.head_sharpness
                            
                            ch, cw = bird_crop_bgr.shape[:2]
                            if left_eye_vis >= right_eye_vis and left_eye_vis >= 0.3:
                                eye_px = (int(kp_result.left_eye[0] * cw), int(kp_result.left_eye[1] * ch))
                            elif right_eye_vis >= 0.3:
                                eye_px = (int(kp_result.right_eye[0] * cw), int(kp_result.right_eye[1] * ch))
                            else:
                                eye_px = None
                            
                            if eye_px is not None:
                                head_center_orig = (eye_px[0] + x_orig, eye_px[1] + y_orig)
                                beak_px = (int(kp_result.beak[0] * cw), int(kp_result.beak[1] * ch))
                                if beak_vis >= 0.3:
                                    import math
                                    dist = math.sqrt((eye_px[0] - beak_px[0])**2 + (eye_px[1] - beak_px[1])**2)
                                    head_radius_val = int(dist * 1.2)
                                else:
                                    head_radius_val = int(max(cw, ch) * 0.15)
                                head_radius_val = max(20, min(head_radius_val, min(cw, ch) // 2))
            except Exception:
                pass
        
        # Phase 3: TOPIQè®¡ç®—
        topiq = None
        if detected and not all_keypoints_hidden and best_eye_visibility >= 0.3:
            try:
                from iqa_scorer import get_iqa_scorer
                from utils import get_best_device
                device = get_best_device(self.settings.device if hasattr(self.settings, 'device') else 'auto')
                scorer = get_iqa_scorer(device=device)
                topiq = scorer.calculate_nima(filepath)
            except Exception:
                pass
        
        # Phase 4: é£ç‰ˆæ£€æµ‹
        is_flying = False
        flight_confidence = 0.0
        if use_flight and detected and bird_crop_bgr is not None and bird_crop_bgr.size > 0:
            try:
                flight_result = flight_detector.detect(bird_crop_bgr)
                is_flying = flight_result.is_flying
                flight_confidence = flight_result.confidence
            except Exception:
                pass
        
        # Phase 5: æ›å…‰æ£€æµ‹
        is_overexposed = False
        is_underexposed = False
        if self.settings.detect_exposure and detected and bird_crop_bgr is not None and bird_crop_bgr.size > 0:
            try:
                exposure_detector = get_exposure_detector()
                exposure_result = exposure_detector.detect(
                    bird_crop_bgr, 
                    threshold=self.settings.exposure_threshold
                )
                is_overexposed = exposure_result.is_overexposed
                is_underexposed = exposure_result.is_underexposed
            except Exception:
                pass
        
        # é£ç‰ˆåŠ æˆ
        rating_sharpness = head_sharpness
        rating_topiq = topiq
        if is_flying and confidence >= 0.5:
            rating_sharpness = head_sharpness + 100
            if topiq is not None:
                rating_topiq = topiq + 0.5
        
        # åˆæ­¥è¯„åˆ†
        preliminary_result = self.rating_engine.calculate(
            detected=detected,
            confidence=confidence,
            sharpness=head_sharpness,
            topiq=topiq,
            all_keypoints_hidden=all_keypoints_hidden,
            best_eye_visibility=best_eye_visibility,
            is_overexposed=is_overexposed,
            is_underexposed=is_underexposed,
            focus_sharpness_weight=1.0,
            focus_topiq_weight=1.0,
            is_flying=False,
        )
        
        # å¯¹ç„¦ç‚¹éªŒè¯ï¼ˆä»…å¯¹1æ˜Ÿä»¥ä¸Šï¼‰
        focus_sharpness_weight = 1.0
        focus_topiq_weight = 1.0
        focus_x, focus_y = None, None
        
        if preliminary_result.rating >= 1:
            if detected and bird_bbox is not None and img_dims is not None:
                if file_prefix in raw_dict:
                    raw_ext = raw_dict[file_prefix]
                    raw_path = os.path.join(self.dir_path, file_prefix + raw_ext)
                    if raw_ext.lower() in ['.nef', '.nrw', '.arw', '.cr3', '.cr2', '.orf', '.raf', '.rw2']:
                        try:
                            focus_detector = get_focus_detector()
                            focus_result = focus_detector.detect(raw_path)
                            if focus_result is not None:
                                orig_dims = (w_orig, h_orig) if 'w_orig' in locals() and 'h_orig' in locals() else img_dims
                                focus_sharpness_weight, focus_topiq_weight = verify_focus_in_bbox(
                                    focus_result, 
                                    bird_bbox, 
                                    orig_dims,
                                    seg_mask=bird_mask_orig,
                                    head_center=head_center_orig,
                                    head_radius=head_radius_val,
                                )
                                focus_x, focus_y = focus_result.x, focus_result.y
                        except Exception:
                            pass
        
        # æœ€ç»ˆè¯„åˆ†
        rating_result = self.rating_engine.calculate(
            detected=detected,
            confidence=confidence,
            sharpness=head_sharpness,
            topiq=topiq,
            all_keypoints_hidden=all_keypoints_hidden,
            best_eye_visibility=best_eye_visibility,
            is_overexposed=is_overexposed,
            is_underexposed=is_underexposed,
            focus_sharpness_weight=focus_sharpness_weight,
            focus_topiq_weight=focus_topiq_weight,
            is_flying=is_flying,
        )
        
        rating_value = rating_result.rating
        pick = rating_result.pick
        reason = rating_result.reason
        
        # å¯¹ç„¦çŠ¶æ€
        focus_status = None
        focus_status_en = None
        if detected:
            if focus_sharpness_weight > 1.0:
                focus_status = "ç²¾å‡†"
                focus_status_en = "BEST"
            elif focus_sharpness_weight >= 1.0:
                focus_status = "é¸Ÿèº«"
                focus_status_en = "GOOD"
            elif focus_sharpness_weight >= 0.7:
                focus_status = "åç§»"
                focus_status_en = "BAD"
            elif focus_sharpness_weight < 0.7:
                focus_status = "è„±ç„¦"
                focus_status_en = "WORST"
        
        # è®¡ç®—è€—æ—¶
        photo_time_ms = (time.time() - photo_start_time) * 1000
        has_exposure_issue = is_overexposed or is_underexposed
        
        # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»Ÿè®¡ï¼ˆéœ€è¦åˆå§‹åŒ–é”ï¼‰
        if not hasattr(self, '_stats_lock'):
            import threading
            self._stats_lock = threading.Lock()
        
        with self._stats_lock:
            self._log_photo_result_simple(i, total_files, filename, rating_value, reason, photo_time_ms, is_flying, has_exposure_issue, focus_status)
            self._update_stats(rating_value, is_flying, has_exposure_issue)
            self.stats['photo_times'].append((filename, photo_time_ms, detected))
            if detected:
                self.stats['with_bird_times'].append(photo_time_ms)
            else:
                self.stats['no_bird_times'].append(photo_time_ms)
        
        # ç¡®å®šç›®æ ‡æ–‡ä»¶
        target_file_path = None
        if file_prefix in raw_dict:
            raw_ext = raw_dict[file_prefix]
            target_file_path = os.path.join(self.dir_path, file_prefix + raw_ext)
            if os.path.exists(target_file_path):
                label = None
                if is_flying:
                    label = 'Green'
                elif focus_sharpness_weight > 1.0:
                    label = 'Red'
                
                caption_parts = [
                    f"[SuperPicky V4.0 è¯„åˆ†æŠ¥å‘Š]",
                    f"æœ€ç»ˆè¯„åˆ†: {rating_value}æ˜Ÿ | {reason}",
                    "",
                    "[åŸå§‹æ£€æµ‹æ•°æ®]",
                    f"AIç½®ä¿¡åº¦: {confidence:.0%}",
                    f"å¤´éƒ¨é”åº¦: {head_sharpness:.2f}" if head_sharpness else "å¤´éƒ¨é”åº¦: æ— æ³•è®¡ç®—",
                    f"TOPIQç¾å­¦: {topiq:.2f}" if topiq else "TOPIQç¾å­¦: æœªè®¡ç®—",
                    f"çœ¼ç›å¯è§åº¦: {best_eye_visibility:.0%}",
                    "",
                    "[ä¿®æ­£å› å­]",
                    f"å¯¹ç„¦é”åº¦æƒé‡: {focus_sharpness_weight:.2f}",
                    f"å¯¹ç„¦ç¾å­¦æƒé‡: {focus_topiq_weight:.2f}",
                    f"æ˜¯å¦é£é¸Ÿ: {'æ˜¯ (é”åº¦Ã—1.2, ç¾å­¦Ã—1.1)' if is_flying else 'å¦'}",
                ]
                caption = " | ".join(caption_parts)
                
                single_batch = [{
                    'file': target_file_path,
                    'rating': rating_value if rating_value >= 0 else 0,
                    'pick': pick,
                    'sharpness': head_sharpness,
                    'nima_score': topiq,
                    'label': label,
                    'focus_status': focus_status,
                    'caption': caption,
                }]
                exiftool_mgr.batch_set_metadata(single_batch)
        else:
            target_file_path = filepath
        
        # æ›´æ–°CSVå’Œè®°å½•è¯„åˆ†ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        if target_file_path and os.path.exists(target_file_path):
            with self._stats_lock:
                self._update_csv_keypoint_data(
                    file_prefix, 
                    rating_sharpness,
                    has_visible_eye, 
                    has_visible_beak,
                    left_eye_vis,
                    right_eye_vis,
                    beak_vis,
                    rating_topiq,
                    rating_value,
                    is_flying,
                    flight_confidence,
                    focus_status,
                    focus_x,
                    focus_y
                )
                
                if rating_value == 3 and rating_topiq is not None:
                    self.star_3_photos.append({
                        'file': target_file_path,
                        'nima': rating_topiq,
                        'sharpness': rating_sharpness
                    })
                
                self.file_ratings[file_prefix] = rating_value
                
                if rating_value == 2:
                    sharpness_ok = rating_sharpness >= self.settings.sharpness_threshold
                    topiq_ok = rating_topiq is not None and rating_topiq >= self.settings.nima_threshold
                    if sharpness_ok and not topiq_ok:
                        self.star2_reasons[file_prefix] = 'sharpness'
                    elif topiq_ok and not sharpness_ok:
                        self.star2_reasons[file_prefix] = 'nima'
                    else:
                        self.star2_reasons[file_prefix] = 'both'
    
    # æ³¨æ„: _calculate_rating æ–¹æ³•å·²ç§»è‡³ core/rating_engine.py
    # ç°åœ¨ä½¿ç”¨ self.rating_engine.calculate() æ›¿ä»£
    
    def _log_photo_result(
        self, 
        rating: int, 
        reason: str, 
        conf: float, 
        sharp: float, 
        nima: Optional[float]
    ):
        """è®°å½•ç…§ç‰‡å¤„ç†ç»“æœï¼ˆè¯¦ç»†ç‰ˆï¼Œä¿ç•™ç”¨äºè°ƒè¯•ï¼‰"""
        iqa_text = ""
        if nima is not None:
            iqa_text += f", ç¾å­¦:{nima:.2f}"
        
        if rating == 3:
            self._log(f"  â­â­â­ ä¼˜é€‰ç…§ç‰‡ (AI:{conf:.2f}, é”åº¦:{sharp:.1f}{iqa_text})", "success")
        elif rating == 2:
            self._log(f"  â­â­ è‰¯å¥½ç…§ç‰‡ (AI:{conf:.2f}, é”åº¦:{sharp:.1f}{iqa_text})", "info")
        elif rating == 1:
            self._log(f"  â­ æ™®é€šç…§ç‰‡ (AI:{conf:.2f}, é”åº¦:{sharp:.1f}{iqa_text})", "warning")
        elif rating == 0:
            self._log(f"  æ™®é€šç…§ç‰‡ - {reason}", "warning")
        else:  # -1
            self._log(f"  âŒ æ— é¸Ÿ - {reason}", "error")
    
    def _log_photo_result_simple(
        self,
        index: int,
        total: int,
        filename: str,
        rating: int,
        reason: str,
        time_ms: float,
        is_flying: bool = False,  # V3.4: é£é¸Ÿæ ‡è¯†
        has_exposure_issue: bool = False,  # V3.8: æ›å…‰é—®é¢˜æ ‡è¯†
        focus_status: str = None  # V3.9: å¯¹ç„¦çŠ¶æ€
    ):
        """è®°å½•ç…§ç‰‡å¤„ç†ç»“æœï¼ˆç®€åŒ–ç‰ˆï¼Œå•è¡Œè¾“å‡ºï¼‰"""
        # æ˜Ÿçº§æ ‡è¯†
        star_map = {3: "3æ˜Ÿ", 2: "2æ˜Ÿ", 1: "1æ˜Ÿ", 0: "0æ˜Ÿ", -1: "-1æ˜Ÿ"}
        star_text = star_map.get(rating, "?æ˜Ÿ")
        
        # V3.4: é£é¸Ÿæ ‡è¯†
        flight_tag = "ã€é£é¸Ÿã€‘" if is_flying else ""
        
        # V3.8: æ›å…‰é—®é¢˜æ ‡è¯†
        exposure_tag = "ã€æ›å…‰ã€‘" if has_exposure_issue else ""
        
        # V3.9: å¯¹ç„¦çŠ¶æ€æ ‡è¯†
        focus_tag = ""
        if focus_status and focus_status != "é¸Ÿèº«":
            focus_tag = f"ã€{focus_status}ã€‘"
        
        # ç®€åŒ–åŸå› æ˜¾ç¤ºï¼ˆV3.9: å¢åŠ åˆ°35å­—ç¬¦é¿å…æˆªæ–­ï¼‰
        reason_short = reason if len(reason) < 35 else reason[:32] + "..."
        
        # æ—¶é—´æ ¼å¼åŒ–
        if time_ms >= 1000:
            time_text = f"{time_ms/1000:.1f}s"
        else:
            time_text = f"{time_ms:.0f}ms"
        
        # è¾“å‡ºç®€åŒ–æ ¼å¼
        self._log(f"[{index:03d}/{total}] {filename} | {star_text} ({reason_short}) {flight_tag}{exposure_tag}{focus_tag}| {time_text}")
    
    def _save_debug_crop(
        self,
        filename: str,
        bird_crop_bgr: np.ndarray,
        bird_crop_mask: np.ndarray = None,
        head_center_crop: tuple = None,
        head_radius: int = None,
        focus_point_crop: tuple = None,
        focus_status: str = None
    ):
        """
        V3.9: ä¿å­˜è°ƒè¯•å¯è§†åŒ–å›¾ç‰‡åˆ° .superpicky/debug_crops/ ç›®å½•
        
        æ ‡æ³¨å†…å®¹ï¼š
        - ğŸŸ¢ ç»¿è‰²åŠé€æ˜: SEG mask é¸Ÿèº«åŒºåŸŸ
        - ğŸ”µ è“è‰²åœ†åœˆ: å¤´éƒ¨æ£€æµ‹åŒºåŸŸ
        - ğŸ”´ çº¢è‰²åå­—: å¯¹ç„¦ç‚¹ä½ç½®
        """
        import cv2
        
        # åˆ›å»ºè°ƒè¯•ç›®å½•
        debug_dir = os.path.join(self.dir_path, ".superpicky", "debug_crops")
        os.makedirs(debug_dir, exist_ok=True)
        
        # å¤åˆ¶åŸå›¾
        debug_img = bird_crop_bgr.copy()
        h, w = debug_img.shape[:2]
        
        # 1. ç»˜åˆ¶ SEG maskï¼ˆç»¿è‰²åŠé€æ˜è¦†ç›–ï¼‰
        if bird_crop_mask is not None and bird_crop_mask.shape[:2] == (h, w):
            green_overlay = np.zeros_like(debug_img)
            green_overlay[:] = (0, 255, 0)  # BGR ç»¿è‰²
            mask_bool = bird_crop_mask > 0
            # åŠé€æ˜å åŠ 
            debug_img[mask_bool] = cv2.addWeighted(
                debug_img[mask_bool], 0.7,
                green_overlay[mask_bool], 0.3, 0
            )
        
        # 2. ç»˜åˆ¶å¤´éƒ¨åœ†åœˆï¼ˆè“è‰²ï¼‰
        if head_center_crop is not None and head_radius is not None:
            cx, cy = head_center_crop
            cv2.circle(debug_img, (cx, cy), head_radius, (255, 0, 0), 2)  # è“è‰²åœ†åœˆ
            cv2.circle(debug_img, (cx, cy), 3, (255, 0, 0), -1)  # åœ†å¿ƒ
        
        # 3. ç»˜åˆ¶å¯¹ç„¦ç‚¹ï¼ˆçº¢è‰²åå­—ï¼‰
        if focus_point_crop is not None:
            fx, fy = focus_point_crop
            cross_size = 15
            cv2.line(debug_img, (fx - cross_size, fy), (fx + cross_size, fy), (0, 0, 255), 2)
            cv2.line(debug_img, (fx, fy - cross_size), (fx, fy + cross_size), (0, 0, 255), 2)
        
        # 4. æ·»åŠ çŠ¶æ€æ–‡å­—
        if focus_status:
            cv2.putText(debug_img, focus_status, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ä¿å­˜è°ƒè¯•å›¾
        file_prefix = os.path.splitext(filename)[0]
        debug_path = os.path.join(debug_dir, f"{file_prefix}_debug.jpg")
        cv2.imwrite(debug_path, debug_img, [cv2.IMWRITE_JPEG_QUALITY, 85])
    
    def _update_stats(self, rating: int, is_flying: bool = False, has_exposure_issue: bool = False):
        """æ›´æ–°ç»Ÿè®¡æ•°æ®"""
        self.stats['total'] += 1
        if rating == 3:
            self.stats['star_3'] += 1
        elif rating == 2:
            self.stats['star_2'] += 1
        elif rating == 1:
            self.stats['star_1'] += 1  # æ™®é€šç…§ç‰‡ï¼ˆåˆæ ¼ï¼‰
        elif rating == 0:
            self.stats['star_0'] += 1  # æ™®é€šç…§ç‰‡ï¼ˆé—®é¢˜ï¼‰
        else:  # -1
            self.stats['no_bird'] += 1
        
        # V3.6: ç»Ÿè®¡é£é¸Ÿç…§ç‰‡
        if is_flying:
            self.stats['flying'] += 1
        
        # V3.8: ç»Ÿè®¡æ›å…‰é—®é¢˜ç…§ç‰‡
        if has_exposure_issue:
            self.stats['exposure_issue'] += 1
    
    def _update_csv_keypoint_data(
        self, 
        filename: str, 
        head_sharpness: float,
        has_visible_eye: bool,
        has_visible_beak: bool,
        left_eye_vis: float,
        right_eye_vis: float,
        beak_vis: float,
        nima: float,
        rating: int,
        is_flying: bool = False,
        flight_confidence: float = 0.0,
        focus_status: str = None,  # V3.9: å¯¹ç„¦çŠ¶æ€
        focus_x: float = None,  # V3.9: å¯¹ç„¦ç‚¹Xåæ ‡
        focus_y: float = None   # V3.9: å¯¹ç„¦ç‚¹Yåæ ‡
    ):
        """æ›´æ–°CSVä¸­çš„å…³é”®ç‚¹æ•°æ®å’Œè¯„åˆ†ï¼ˆV3.9: æ·»åŠ å¯¹ç„¦çŠ¶æ€å’Œåæ ‡ï¼‰"""
        import csv
        
        csv_path = os.path.join(self.dir_path, ".superpicky", "report.csv")
        if not os.path.exists(csv_path):
            return
        
        try:
            # è¯»å–ç°æœ‰CSV
            rows = []
            with open(csv_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                fieldnames = list(reader.fieldnames) if reader.fieldnames else []
                
                # V3.9: å¦‚æœæ²¡æœ‰å¯¹ç„¦ç›¸å…³å­—æ®µåˆ™æ·»åŠ 
                if 'focus_status' not in fieldnames:
                    rating_idx = fieldnames.index('rating') if 'rating' in fieldnames else len(fieldnames)
                    fieldnames.insert(rating_idx + 1, 'focus_status')
                if 'focus_x' not in fieldnames:
                    focus_status_idx = fieldnames.index('focus_status') if 'focus_status' in fieldnames else len(fieldnames)
                    fieldnames.insert(focus_status_idx + 1, 'focus_x')
                if 'focus_y' not in fieldnames:
                    focus_x_idx = fieldnames.index('focus_x') if 'focus_x' in fieldnames else len(fieldnames)
                    fieldnames.insert(focus_x_idx + 1, 'focus_y')
                
                for row in reader:
                    if row.get('filename') == filename:
                        # V3.4: ä½¿ç”¨è‹±æ–‡å­—æ®µåæ›´æ–°æ•°æ®
                        row['head_sharp'] = f"{head_sharpness:.0f}" if head_sharpness > 0 else "-"
                        row['left_eye'] = f"{left_eye_vis:.2f}"
                        row['right_eye'] = f"{right_eye_vis:.2f}"
                        row['beak'] = f"{beak_vis:.2f}"
                        row['nima_score'] = f"{nima:.2f}" if nima is not None else "-"
                        # V3.4: é£ç‰ˆæ£€æµ‹å­—æ®µ
                        row['is_flying'] = "yes" if is_flying else "no"
                        row['flight_conf'] = f"{flight_confidence:.2f}"
                        row['rating'] = str(rating)
                        # V3.9: å¯¹ç„¦çŠ¶æ€å’Œåæ ‡å­—æ®µ
                        row['focus_status'] = focus_status if focus_status else "-"
                        row['focus_x'] = f"{focus_x:.3f}" if focus_x is not None else "-"
                        row['focus_y'] = f"{focus_y:.3f}" if focus_y is not None else "-"
                    rows.append(row)
            
            # å†™å›CSV
            if fieldnames and rows:
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(rows)
        except Exception as e:
            self._log(f"  âš ï¸  æ›´æ–°CSVå¤±è´¥: {e}", "warning")
    
    def _calculate_picked_flags(self):
        """è®¡ç®—ç²¾é€‰æ——æ ‡ - 3æ˜Ÿç…§ç‰‡ä¸­ç¾å­¦+é”åº¦åŒæ’åäº¤é›†"""
        if len(self.star_3_photos) == 0:
            self._log("\nâ„¹ï¸  æ— 3æ˜Ÿç…§ç‰‡ï¼Œè·³è¿‡ç²¾é€‰æ——æ ‡è®¡ç®—")
            return
        
        self._log(f"\nğŸ¯ è®¡ç®—ç²¾é€‰æ——æ ‡ (å…±{len(self.star_3_photos)}å¼ 3æ˜Ÿç…§ç‰‡)...")
        top_percent = self.config.picked_top_percentage / 100.0
        top_count = max(1, int(len(self.star_3_photos) * top_percent))
        
        # ç¾å­¦æ’åº
        sorted_by_nima = sorted(self.star_3_photos, key=lambda x: x['nima'], reverse=True)
        nima_top_files = set([photo['file'] for photo in sorted_by_nima[:top_count]])
        
        # é”åº¦æ’åº
        sorted_by_sharpness = sorted(self.star_3_photos, key=lambda x: x['sharpness'], reverse=True)
        sharpness_top_files = set([photo['file'] for photo in sorted_by_sharpness[:top_count]])
        
        # äº¤é›†
        picked_files = nima_top_files & sharpness_top_files
        
        if len(picked_files) > 0:
            self._log(f"  ğŸ“Œ ç¾å­¦Top{self.config.picked_top_percentage}%: {len(nima_top_files)}å¼ ")
            self._log(f"  ğŸ“Œ é”åº¦Top{self.config.picked_top_percentage}%: {len(sharpness_top_files)}å¼ ")
            self._log(f"  â­ åŒæ’åäº¤é›†: {len(picked_files)}å¼  â†’ è®¾ä¸ºç²¾é€‰")
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºç²¾é€‰æ–‡ä»¶è·¯å¾„
            for file_path in picked_files:
                exists = os.path.exists(file_path)
                self._log(f"    ğŸ” ç²¾é€‰: {os.path.basename(file_path)} (å­˜åœ¨: {exists})")
            
            # æ‰¹é‡å†™å…¥
            picked_batch = [{
                'file': file_path,
                'rating': 3,
                'pick': 1
            } for file_path in picked_files]
            
            exiftool_mgr = get_exiftool_manager()
            picked_stats = exiftool_mgr.batch_set_metadata(picked_batch)
            
            if picked_stats['failed'] == 0:
                self._log(f"  âœ… ç²¾é€‰æ——æ ‡å†™å…¥æˆåŠŸ")
            else:
                self._log(f"  âš ï¸  {picked_stats['failed']} å¼ ç²¾é€‰æ——æ ‡å†™å…¥å¤±è´¥", "warning")
            
            self.stats['picked'] = len(picked_files) - picked_stats.get('failed', 0)
            # ä¿å­˜ç²¾é€‰æ–‡ä»¶é›†åˆï¼Œä¾›åç»­ä½¿ç”¨
            self.picked_files = picked_files
        else:
            self._log(f"  â„¹ï¸  åŒæ’åäº¤é›†ä¸ºç©ºï¼Œæœªè®¾ç½®ç²¾é€‰æ——æ ‡")
            self.stats['picked'] = 0
            self.picked_files = set()
    
    def _move_files_to_rating_folders(self, raw_dict):
        """ç§»åŠ¨æ–‡ä»¶åˆ°åˆ†ç±»æ–‡ä»¶å¤¹ï¼ˆV3.4: æ”¯æŒçº¯ JPEGï¼‰"""
        # ç­›é€‰éœ€è¦ç§»åŠ¨çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬æ‰€æœ‰æ˜Ÿçº§ï¼Œç¡®ä¿åŸç›®å½•ä¸ºç©ºï¼‰
        files_to_move = []
        for prefix, rating in self.file_ratings.items():
            if rating in [-1, 0, 1, 2, 3]:
                # V3.4: ä¼˜å…ˆä½¿ç”¨ RAWï¼Œæ²¡æœ‰åˆ™ä½¿ç”¨ JPEG
                if prefix in raw_dict:
                    # æœ‰å¯¹åº”çš„ RAW æ–‡ä»¶
                    raw_ext = raw_dict[prefix]
                    file_path = os.path.join(self.dir_path, prefix + raw_ext)
                    if os.path.exists(file_path):
                        folder = RATING_FOLDER_NAMES.get(rating, "0æ˜Ÿ_æ”¾å¼ƒ")
                        files_to_move.append({
                            'filename': prefix + raw_ext,
                            'rating': rating,
                            'folder': folder
                        })
                else:
                    # V3.4: çº¯ JPEG/HEIF æ–‡ä»¶ï¼ˆåŒ…æ‹¬ HEIF/HEICï¼‰
                    for jpg_ext in ['.jpg', '.jpeg', '.heif', '.heic', '.hif', '.JPG', '.JPEG', '.HEIF', '.heic', '.hif']:
                        jpg_path = os.path.join(self.dir_path, prefix + jpg_ext)
                        if os.path.exists(jpg_path):
                            folder = RATING_FOLDER_NAMES.get(rating, "0æ˜Ÿ_æ”¾å¼ƒ")
                            files_to_move.append({
                                'filename': prefix + jpg_ext,
                                'rating': rating,
                                'folder': folder
                            })
                            break  # æ‰¾åˆ°å°±è·³å‡º
        
        if not files_to_move:
            self._log("\nğŸ“‚ æ— éœ€ç§»åŠ¨æ–‡ä»¶")
            return
        
        self._log(f"\nğŸ“‚ ç§»åŠ¨ {len(files_to_move)} å¼ ç…§ç‰‡åˆ°åˆ†ç±»æ–‡ä»¶å¤¹...")
        
        # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆä½¿ç”¨å®é™…çš„ç›®å½•åï¼‰
        folders_in_use = set(f['folder'] for f in files_to_move)
        for folder_name in folders_in_use:
            folder_path = os.path.join(self.dir_path, folder_name)
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
                self._log(f"  ğŸ“ åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name}/")
        
        # ç§»åŠ¨æ–‡ä»¶
        moved_count = 0
        for file_info in files_to_move:
            src_path = os.path.join(self.dir_path, file_info['filename'])
            dst_folder = os.path.join(self.dir_path, file_info['folder'])
            dst_path = os.path.join(dst_folder, file_info['filename'])
            
            try:
                if os.path.exists(dst_path):
                    continue
                shutil.move(src_path, dst_path)
                moved_count += 1
            except Exception as e:
                self._log(f"  âš ï¸  ç§»åŠ¨å¤±è´¥: {file_info['filename']} - {e}", "warning")
        
        # ç”Ÿæˆmanifest
        manifest = {
            "version": "1.0",
            "created": datetime.now().isoformat(),
            "app_version": "Refactored-Core",
            "original_dir": self.dir_path,
            "folder_structure": RATING_FOLDER_NAMES,
            "files": files_to_move,
            "stats": {"total_moved": moved_count}
        }
        
        manifest_path = os.path.join(self.dir_path, ".superpicky_manifest.json")
        try:
            with open(manifest_path, 'w', encoding='utf-8') as f:
                json.dump(manifest, f, ensure_ascii=False, indent=2)
            self._log(f"  âœ… å·²ç§»åŠ¨ {moved_count} å¼ ç…§ç‰‡")
            self._log(f"  ğŸ“‹ Manifest: .superpicky_manifest.json")
        except Exception as e:
            self._log(f"  âš ï¸  ä¿å­˜manifestå¤±è´¥: {e}", "warning")
    
    def _cleanup_temp_files(self, files_tbr, raw_dict):
        """æ¸…ç†ä¸´æ—¶JPGæ–‡ä»¶æˆ–ä¿ç•™å¹¶å†™å…¥EXIF"""
        if self.settings.keep_temp_jpg:
            self._log("\nğŸ’¾ ä¿ç•™ä¸´æ—¶è½¬æ¢çš„JPGæ–‡ä»¶...")
            self._process_keep_temp_jpg(files_tbr)
        else:
            self._log("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            deleted_count = 0
            
            # åˆ é™¤ RAW è½¬æ¢çš„ä¸´æ—¶ JPG
            for filename in files_tbr:
                file_prefix, file_ext = os.path.splitext(filename)
                if file_prefix in raw_dict and file_ext.lower() in ['.jpg', '.jpeg']:
                    jpg_path = os.path.join(self.dir_path, filename)
                    try:
                        if os.path.exists(jpg_path):
                            os.remove(jpg_path)
                            deleted_count += 1
                    except Exception as e:
                        self._log(f"  âš ï¸  åˆ é™¤å¤±è´¥ {filename}: {e}", "warning")
            
            # åˆ é™¤ HEIF è½¬æ¢çš„ä¸´æ—¶ JPG
            temp_dir = os.path.join(self.dir_path, '.superpicky', 'temp_jpg')
            if os.path.exists(temp_dir):
                # å¦‚æœheif_temp_mapä¸ºç©ºï¼ˆæµæ°´çº¿æ¡†æ¶å¯èƒ½æœªåŒæ­¥ï¼‰ï¼Œæ‰«æä¸´æ—¶ç›®å½•
                if not self.heif_temp_map:
                    for temp_file in os.listdir(temp_dir):
                        if temp_file.endswith('_temp.jpg'):
                            temp_jpg_path = os.path.join(temp_dir, temp_file)
                            try:
                                if os.path.exists(temp_jpg_path):
                                    os.remove(temp_jpg_path)
                                    deleted_count += 1
                            except Exception as e:
                                self._log(f"  âš ï¸  åˆ é™¤å¤±è´¥ {temp_file}: {e}", "warning")
                else:
                    # ä½¿ç”¨æ˜ å°„åˆ é™¤
                    for temp_jpg_path in self.heif_temp_map.values():
                        try:
                            if os.path.exists(temp_jpg_path):
                                os.remove(temp_jpg_path)
                                deleted_count += 1
                        except Exception as e:
                            self._log(f"  âš ï¸  åˆ é™¤å¤±è´¥ {os.path.basename(temp_jpg_path)}: {e}", "warning")
            
            if deleted_count > 0:
                self._log(f"  âœ… å·²åˆ é™¤ {deleted_count} ä¸ªä¸´æ—¶JPGæ–‡ä»¶")
            else:
                self._log(f"  â„¹ï¸  æ— ä¸´æ—¶æ–‡ä»¶éœ€æ¸…ç†")
    
    def _process_keep_temp_jpg(self, files_tbr):
        """å¤„ç†ä¿ç•™çš„ä¸´æ—¶JPGæ–‡ä»¶ï¼šå†™å…¥EXIFå¹¶ç§»åŠ¨åˆ°å¯¹åº”æ˜Ÿçº§ç›®å½•"""
        from exiftool_manager import get_exiftool_manager
        exiftool_mgr = get_exiftool_manager()
        
        processed_count = 0
        
        # å¤„ç† HEIF è½¬æ¢çš„ä¸´æ—¶ JPG
        # å¦‚æœheif_temp_mapä¸ºç©ºï¼ˆæµæ°´çº¿æ¡†æ¶å¯èƒ½æœªåŒæ­¥ï¼‰ï¼Œå°è¯•ä»ä¸´æ—¶ç›®å½•æ‰«æ
        if not self.heif_temp_map:
            temp_dir = os.path.join(self.dir_path, '.superpicky', 'temp_jpg')
            if os.path.exists(temp_dir):
                # æ‰«æä¸´æ—¶ç›®å½•ï¼Œé‡å»ºæ˜ å°„
                for temp_file in os.listdir(temp_dir):
                    if temp_file.endswith('_temp.jpg'):
                        # ä»æ–‡ä»¶åæå–åŸå§‹æ–‡ä»¶åï¼ˆå»æ‰_temp.jpgåç¼€ï¼‰
                        file_basename = temp_file[:-10]  # å»æ‰'_temp.jpg'
                        # å°è¯•åŒ¹é…åŸå§‹HEIFæ–‡ä»¶å
                        for filename in files_tbr:
                            file_prefix, ext = os.path.splitext(filename)
                            if file_prefix == file_basename and ext.lower() in ['.heif', '.heic', '.hif']:
                                temp_jpg_path = os.path.join(temp_dir, temp_file)
                                self.heif_temp_map[filename] = temp_jpg_path
                                break
        
        for original_filename, temp_jpg_path in self.heif_temp_map.items():
            if not os.path.exists(temp_jpg_path):
                continue
            
            # è·å–åŸå§‹æ–‡ä»¶çš„è¯„åˆ†ï¼ˆä»file_ratingsä¸­è·å–ï¼Œä¸æ˜¯ä»EXIFè¯»å–ï¼‰
            file_prefix = os.path.splitext(original_filename)[0]
            rating = self.file_ratings.get(file_prefix, -1)
            
            if rating < 0:
                # æ— è¯„åˆ†ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(temp_jpg_path)
                except:
                    pass
                continue
            
            try:
                # æ„å»º JPG æ–‡ä»¶åï¼ˆå»æ‰ _temp åç¼€ï¼‰
                jpg_filename = file_prefix + ".jpg"
                final_jpg_path = os.path.join(self.dir_path, jpg_filename)
                
                # å¦‚æœå·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„åç§°
                if os.path.exists(final_jpg_path):
                    import datetime
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    jpg_filename = f"{file_prefix}_{timestamp}.jpg"
                    final_jpg_path = os.path.join(self.dir_path, jpg_filename)
                
                # ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°æœ€ç»ˆä½ç½®
                import shutil
                shutil.move(temp_jpg_path, final_jpg_path)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç²¾é€‰ç…§ç‰‡
                # é€šè¿‡æ£€æŸ¥åŸå§‹æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨ picked_files ä¸­
                original_file_path = os.path.join(self.dir_path, original_filename)
                is_picked = original_file_path in self.picked_files
                
                # å°è¯•ä»åŸå§‹HEIFæ–‡ä»¶è¯»å–EXIFæ•°æ®ï¼ˆå¦‚æœå·²å†™å…¥ï¼‰
                # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                sharpness = None
                nima_score = None
                focus_status = None
                caption = f"[SuperPicky] ä» {os.path.splitext(original_filename)[1]} è½¬æ¢"
                
                try:
                    # å°è¯•ä»åŸå§‹æ–‡ä»¶è¯»å–EXIFï¼ˆå¦‚æœå·²å†™å…¥ï¼‰
                    from exiftool_manager import ExifToolManager
                    if os.path.exists(original_file_path):
                        # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯å°è¯•è¯»å–ï¼Œå¦‚æœå¤±è´¥å°±ä½¿ç”¨é»˜è®¤å€¼
                        # å®é™…EXIFæ•°æ®åº”è¯¥åœ¨åŸå§‹HEIFæ–‡ä»¶ä¸­
                        pass
                except:
                    pass
                
                # å†™å…¥ EXIF å…ƒæ•°æ®åˆ°JPGæ–‡ä»¶
                batch_data = [{
                    'file': final_jpg_path,
                    'rating': rating if rating >= 0 else 0,
                    'pick': 1 if is_picked else 0,
                    'sharpness': sharpness,  # å¯èƒ½ä¸ºNone
                    'nima_score': nima_score,  # å¯èƒ½ä¸ºNone
                    'label': None,
                    'focus_status': focus_status,  # å¯èƒ½ä¸ºNone
                    'caption': caption
                }]
                
                exiftool_mgr.batch_set_metadata(batch_data)
                
                # ç§»åŠ¨åˆ°å¯¹åº”æ˜Ÿçº§ç›®å½•ï¼ˆæŒ‰æ˜Ÿçº§å½’æ¡£ï¼‰
                folder = RATING_FOLDER_NAMES.get(rating, "0æ˜Ÿ_æ”¾å¼ƒ")
                folder_path = os.path.join(self.dir_path, folder)
                os.makedirs(folder_path, exist_ok=True)
                
                dst_path = os.path.join(folder_path, jpg_filename)
                if not os.path.exists(dst_path):
                    shutil.move(final_jpg_path, dst_path)
                    processed_count += 1
                    # è®°å½•å½’æ¡£ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼‰
                    # self._log(f"  ğŸ“ å·²å½’æ¡£åˆ° {folder}/: {jpg_filename}")
                else:
                    # ç›®æ ‡å·²å­˜åœ¨ï¼Œåˆ é™¤æºæ–‡ä»¶
                    os.remove(final_jpg_path)
                    self._log(f"  âš ï¸  ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {folder}/{jpg_filename}", "warning")
                
            except Exception as e:
                self._log(f"  âš ï¸  å¤„ç†ä¸´æ—¶JPGå¤±è´¥ {original_filename}: {e}", "warning")
        
        if processed_count > 0:
            self._log(f"  âœ… å·²ä¿ç•™å¹¶å½’æ¡£ {processed_count} ä¸ªä¸´æ—¶JPGæ–‡ä»¶åˆ°å¯¹åº”æ˜Ÿçº§ç›®å½•")
        else:
            self._log(f"  â„¹ï¸  æ— ä¸´æ—¶JPGæ–‡ä»¶éœ€ä¿ç•™")
    
    def get_pipeline_status(self):
        """
        è·å–æµæ°´çº¿çŠ¶æ€ï¼ˆä¾›UIç›‘æ§ä½¿ç”¨ï¼‰
        
        Returns:
            dict: åŒ…å«è½¬æ¢ã€é˜Ÿåˆ—ã€æ¨ç†ä¸‰ä¸ªç®¡çº¿çš„çŠ¶æ€
        """
        if not hasattr(self, '_pipelines') or not self._pipelines:
            return {
                'conversion': {'workers': 0, 'active_jobs': []},
                'queue': {'size': 0, 'max_size': 100},
                'inference_gpu': {'workers': 0, 'active_jobs': []},
                'inference_cpu': {'workers': 0, 'active_jobs': []}
            }
        
        status = {
            'conversion': {'workers': 0, 'active_jobs': []},
            'queue': {'size': 0, 'max_size': 100},
            'inference_gpu': {'workers': 0, 'active_jobs': []},
            'inference_cpu': {'workers': 0, 'active_jobs': []}
        }
        
        # éå†æ‰€æœ‰æµæ°´çº¿ï¼Œæ”¶é›†çŠ¶æ€
        for pipeline in self._pipelines:
            for stage in pipeline.stages:
                stage_name = stage.name.lower()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è½¬æ¢é˜¶æ®µ
                if 'heif' in stage_name or 'è½¬æ¢' in stage_name:
                    workers = stage.max_workers
                    # ä¼°ç®—æ´»è·ƒä»»åŠ¡æ•°ï¼ˆåŸºäºé˜Ÿåˆ—ç»Ÿè®¡ï¼‰
                    if stage.input_queue:
                        queue_stats = stage.input_queue.get_stats()
                        active_count = min(workers, max(0, queue_stats.get('total_put', 0) - queue_stats.get('total_done', 0)))
                        active_jobs = [i < active_count for i in range(workers)]
                    else:
                        active_jobs = [False] * workers
                    status['conversion']['workers'] = max(status['conversion']['workers'], workers)
                    status['conversion']['active_jobs'] = active_jobs
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨ç†é˜¶æ®µï¼ŒåŒºåˆ†GPUå’ŒCPU
                elif 'aiå¤„ç†' in stage_name or 'æ¨ç†' in stage_name or 'inference' in stage_name:
                    workers = stage.max_workers
                    device = stage.device.lower()
                    # ä¼°ç®—æ´»è·ƒä»»åŠ¡æ•°
                    if stage.input_queue:
                        queue_stats = stage.input_queue.get_stats()
                        active_count = min(workers, max(0, queue_stats.get('total_put', 0) - queue_stats.get('total_done', 0)))
                        active_jobs = [i < active_count for i in range(workers)]
                    else:
                        active_jobs = [False] * workers
                    
                    # æ ¹æ®è®¾å¤‡ç±»å‹åˆ†ç±»
                    if 'cuda' in device or 'gpu' in device or 'mps' in device:
                        status['inference_gpu']['workers'] = max(status['inference_gpu']['workers'], workers)
                        status['inference_gpu']['active_jobs'] = active_jobs
                    else:  # CPU
                        status['inference_cpu']['workers'] = max(status['inference_cpu']['workers'], workers)
                        status['inference_cpu']['active_jobs'] = active_jobs
        
        # è·å–å…±äº«é˜Ÿåˆ—å¤§å°
        if hasattr(self, '_shared_ai_queue') and self._shared_ai_queue:
            status['queue']['size'] = self._shared_ai_queue.qsize()
            # ä¼°ç®—æœ€å¤§é˜Ÿåˆ—å¤§å°
            queue_stats = self._shared_ai_queue.get_stats()
            status['queue']['max_size'] = max(100, queue_stats.get('total_put', 0))
        
        return status
