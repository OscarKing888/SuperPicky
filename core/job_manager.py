# -*- coding: utf-8 -*-

import os
import queue
import time
import threading
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, as_completed, Future
from typing import Optional, Callable, Any, Dict, List, Tuple

import torch

from constants import RAW_EXTENSIONS, JPG_EXTENSIONS
from core.job_base import JobFileInfo
from core.job_base_cpu_convert_heif import JobBaseCPU_ConvertHEIF
from core.job_base_cpu_rate import JobBaseCPU_Rate
from core.job_base_gpu_rate import JobBaseGPU_Rate
from core.job_base_cpu_write_exif import JobBaseCPU_WriteEXIF
from core.rating_info import RatingInfo
from core.photo_processor import PhotoProcessor

from core.job_manager_worker_cpu import CPUJobWorker
from core.job_manager_worker_gpu import GPUJobWorker


class JobManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - ç®¡ç†å¹¶æ‰§è¡Œå„ç§ç±»å‹çš„ä»»åŠ¡ï¼ˆè´Ÿè´£çº¿ç¨‹æ± è°ƒåº¦ï¼‰"""
    
    def __init__(
        self,
        dir_path: str,
        photo_processor: PhotoProcessor,
        cpu_worker_count: Optional[int] = None,
        gpu_worker_count: Optional[int] = None,
        log_callback: Optional[Callable[[str, str], None]] = None
    ):
        """
        åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨
        
        Args:
            dir_path: å¤„ç†ç›®å½•è·¯å¾„
            photo_processor: PhotoProcessorå®ä¾‹
            cpu_worker_count: CPUå·¥ä½œçº¿ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
            gpu_worker_count: GPUå·¥ä½œçº¿ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        self.dir_path = dir_path
        self.photo_processor = photo_processor
        self.log_callback = log_callback
        
        # è®¡ç®—workeræ•°é‡
        cpu_count = cpu_worker_count or min(4, multiprocessing.cpu_count())
        
        # åˆ›å»ºCPU workersåˆ—è¡¨ï¼ˆæ¯ä¸ªworkerä¸€ä¸ªå®ä¾‹ï¼Œç”¨äºè´Ÿè½½å‡è¡¡ï¼‰
        self.cpu_workers: List[CPUJobWorker] = [
            CPUJobWorker(log_callback=log_callback, device="cpu")
            for _ in range(cpu_count)
        ]
        self.cpu_worker_index = 0  # è½®è¯¢ç´¢å¼•
        
        # åˆ›å»ºCPUçº¿ç¨‹æ± ï¼ˆç”±JobManagerç®¡ç†ï¼‰
        self.cpu_executor = ThreadPoolExecutor(max_workers=cpu_count)
        
        # æ£€æµ‹GPUè®¾å¤‡
        gpu_device_str = None
        if torch.backends.mps.is_available():
            gpu_device_str = "mps"
        elif torch.cuda.is_available():
            gpu_device_str = "cuda"
        
        # åˆ›å»ºGPU workerå’Œçº¿ç¨‹æ± ï¼ˆå¦‚æœGPUå¯ç”¨ï¼‰
        if gpu_device_str is not None:
            gpu_count = gpu_worker_count or self._calculate_gpu_workers(gpu_device_str)
            self.gpu_workers: List[GPUJobWorker] = [
                GPUJobWorker(log_callback=log_callback, device=gpu_device_str)
                for _ in range(gpu_count)
            ]
            self.gpu_worker_index = 0  # è½®è¯¢ç´¢å¼•
            self.gpu_executor = ThreadPoolExecutor(max_workers=gpu_count)
        else:
            self.gpu_workers = []
            self.gpu_executor = None
        
        # è¯„æ˜Ÿä¿¡æ¯é˜Ÿåˆ—ï¼ˆæ­¥éª¤4ï¼šè¯„æ˜Ÿå®Œæˆåä¿å­˜åˆ°è¿™é‡Œï¼‰
        self.rating_info_queue: queue.Queue[RatingInfo] = queue.Queue()
        self.rating_info_lock = threading.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'convert_success': 0,
            'convert_failed': 0,
            'rate_success': 0,
            'rate_failed': 0,
            'exif_success': 0,
            'exif_failed': 0,
        }
        self.stats_lock = threading.Lock()
        
        # è·Ÿè¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼ˆç”¨äºåˆ¤æ–­workeræ˜¯å¦ç©ºé—²ï¼‰
        self.active_futures: List[Future] = []
        self.futures_lock = threading.Lock()

    def _get_idle_cpu_worker(self) -> CPUJobWorker:
        """è·å–ç©ºé—²çš„CPU workerï¼ˆè½®è¯¢æ–¹å¼ï¼‰"""
        worker = self.cpu_workers[self.cpu_worker_index]
        self.cpu_worker_index = (self.cpu_worker_index + 1) % len(self.cpu_workers)
        return worker
    
    def _get_idle_gpu_worker(self) -> Optional[GPUJobWorker]:
        """è·å–ç©ºé—²çš„GPU workerï¼ˆè½®è¯¢æ–¹å¼ï¼‰"""
        if not self.gpu_workers:
            return None
        worker = self.gpu_workers[self.gpu_worker_index]
        self.gpu_worker_index = (self.gpu_worker_index + 1) % len(self.gpu_workers)
        return worker
    
    def _get_idle_worker_for_rate(self) -> Tuple[Any, ThreadPoolExecutor]:
        """ä¸ºè¯„åˆ†ä»»åŠ¡é€‰æ‹©workerå’Œexecutorï¼ˆè‡ªåŠ¨é€‰æ‹©CPUæˆ–GPUï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.gpu_workers and self.gpu_executor:
            return self._get_idle_gpu_worker(), self.gpu_executor
        return self._get_idle_cpu_worker(), self.cpu_executor

    def _calculate_gpu_workers(self, device_str: str) -> int:
        """æ ¹æ®å¯ç”¨æ˜¾å­˜è®¡ç®—GPUå¹¶å‘æ•°"""
        try:
            if device_str == "cuda" and torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                free_memory_bytes, _ = torch.cuda.mem_get_info(0)
                free_memory_gb = free_memory_bytes / (1024 ** 3)
                gpu_workers = int(free_memory_gb / 2 - 2)
                return max(1, gpu_workers)
        except Exception:
            pass
        return 1

    def _log(self, msg: str, level: str = "info"):
        """å†…éƒ¨æ—¥å¿—æ–¹æ³•"""
        if self.log_callback:
            self.log_callback(msg, level)
    
    def _scan_files(self) -> Tuple[Dict[str, str], List[JobFileInfo]]:
        """
        æ­¥éª¤1ï¼šæ‰«æå¤„ç†ç›®å½•æ–‡ä»¶ç”Ÿæˆåˆ—è¡¨
        
        Returns:
            (raw_dict, job_file_info_list)
        """
        scan_start = time.time()
        raw_dict = {}
        job_file_info_list: List[JobFileInfo] = []
        
        for filename in os.listdir(self.dir_path):
            if filename.startswith('.'):
                continue
            
            file_prefix, file_ext = os.path.splitext(filename)
            ext_lower = file_ext.lower()
            
            # è®°å½•RAWæ–‡ä»¶
            if ext_lower in RAW_EXTENSIONS:
                raw_dict[file_prefix] = file_ext
                continue
            
            # å¤„ç†JPGå’ŒHEIFæ–‡ä»¶
            if ext_lower in JPG_EXTENSIONS or ext_lower in JobFileInfo.HEIF_EXTENSIONS:
                filepath = os.path.join(self.dir_path, filename)
                job_file_info = JobFileInfo(filepath)
                job_file_info_list.append(job_file_info)
        
        scan_time = (time.time() - scan_start) * 1000
        self._log(f"â±ï¸  æ–‡ä»¶æ‰«æè€—æ—¶: {scan_time:.1f}ms (å…± {len(job_file_info_list)} ä¸ªæ–‡ä»¶)")
        
        return raw_dict, job_file_info_list
    
    def _on_rate_complete(self, result: Dict[str, Any]):
        """
        æ­¥éª¤4ï¼šè¯„æ˜Ÿä»»åŠ¡å®Œæˆå›è°ƒï¼Œä¿å­˜è¯„æ˜Ÿä¿¡æ¯åˆ°é˜Ÿåˆ—
        """
        if not result:
            return
        
        job_file_info = result.get('job_file_info')
        if not job_file_info:
            return
        
        # æ„å»ºEXIFæ•°æ®
        exif_data = {
            'rating': result.get('rating', 0),
            'pick': result.get('pick', 0),
            'reason': result.get('reason', ''),
            'confidence': result.get('confidence', 0.0),
            'head_sharpness': result.get('head_sharpness', 0.0),
            'topiq': result.get('topiq'),
            'adj_sharpness': result.get('adj_sharpness'),
            'adj_topiq': result.get('adj_topiq'),
            'is_flying': result.get('is_flying', False),
            'focus_status': result.get('focus_status'),
            'focus_sharpness_weight': result.get('focus_sharpness_weight', 1.0),
            'focus_topiq_weight': result.get('focus_topiq_weight', 1.0),
            'best_eye_visibility': result.get('best_eye_visibility', 0.0),
        }
        
        rating_info = RatingInfo(
            job_file_info=job_file_info,
            rating=result.get('rating', 0),
            pick=result.get('pick', 0),
            reason=result.get('reason', ''),
            exif_data=exif_data,
        )
        
        with self.rating_info_lock:
            self.rating_info_queue.put(rating_info)

    def run(self):
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹ï¼š
        1. æ‰«ææ–‡ä»¶ç”ŸæˆJobFileInfoåˆ—è¡¨
        2. æ ¹æ®use_tmp_fileåˆ›å»ºè½¬æ¢ä»»åŠ¡æˆ–è¯„åˆ†ä»»åŠ¡
        3. è¯„æ˜Ÿå®Œæˆåä¿å­˜åˆ°é˜Ÿåˆ—
        4. æ‰€æœ‰rateå®Œæˆåæ‰§è¡ŒEXIFå†™å…¥
        5. è¾“å‡ºç»Ÿè®¡å¹¶é‡Šæ”¾workers
        """
        start_time = time.time()
        
        # æ­¥éª¤1ï¼šæ‰«ææ–‡ä»¶
        raw_dict, job_file_info_list = self._scan_files()
        
        if not job_file_info_list:
            self._log("æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†")
            return {
                'stats': self.stats.copy(),
                'total_time': time.time() - start_time,
            }
        
        # æ­¥éª¤2å’Œ3ï¼šå¤„ç†è½¬æ¢å’Œè¯„åˆ†ä»»åŠ¡
        convert_futures: Dict[Future, JobFileInfo] = {}
        rate_futures: Dict[Future, JobFileInfo] = {}
        
        # ä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(self.dir_path, '.superpicky', 'temp_jpg')
        os.makedirs(temp_dir, exist_ok=True)
        
        for job_file_info in job_file_info_list:
            if job_file_info.needs_tmp_file():
                # æ­¥éª¤2ï¼šéœ€è¦è½¬æ¢HEIFï¼Œåˆ›å»ºè½¬æ¢ä»»åŠ¡
                convert_job = JobBaseCPU_ConvertHEIF(
                    job_file_info=job_file_info,
                    output_dir=temp_dir,
                )
                worker = self._get_idle_cpu_worker()
                future = self.cpu_executor.submit(worker.run_job, convert_job)
                convert_futures[future] = job_file_info
            else:
                # æ­¥éª¤3ï¼šç›´æ¥è¯„åˆ†ï¼Œä»ç©ºé—²workerä¸­é€‰æ‹©ï¼ˆè‡ªåŠ¨CPU/GPUï¼‰
                worker, executor = self._get_idle_worker_for_rate()
                rate_job = worker.create_rate_job(
                    job_file_info=job_file_info,
                    photo_processor=self.photo_processor,
                    raw_dict=raw_dict,
                )
                future = executor.submit(worker.run_job, rate_job)
                rate_futures[future] = job_file_info
        
        # ç­‰å¾…è½¬æ¢ä»»åŠ¡å®Œæˆï¼Œå®Œæˆååˆ›å»ºè¯„åˆ†ä»»åŠ¡
        self._log(f"ğŸ”„ å¼€å§‹è½¬æ¢ {len(convert_futures)} ä¸ªHEIFæ–‡ä»¶...")
        for future in as_completed(convert_futures):
            job_file_info = convert_futures[future]
            try:
                result = future.result()
                if result and result.get('success'):
                    # è½¬æ¢æˆåŠŸï¼Œæ›´æ–°job_file_infoçš„tmp_file_path
                    job_file_info.tmp_file_path = result.get('temp_jpg_path')
                    # åˆ›å»ºè¯„åˆ†ä»»åŠ¡
                    worker, executor = self._get_idle_worker_for_rate()
                    rate_job = worker.create_rate_job(
                        job_file_info=job_file_info,
                        photo_processor=self.photo_processor,
                        raw_dict=raw_dict,
                    )
                    rate_future = executor.submit(worker.run_job, rate_job)
                    rate_futures[rate_future] = job_file_info
                    
                    with self.stats_lock:
                        self.stats['convert_success'] += 1
                else:
                    with self.stats_lock:
                        self.stats['convert_failed'] += 1
            except Exception as e:
                self._log(f"è½¬æ¢ä»»åŠ¡å¼‚å¸¸: {job_file_info.file_prefix} - {e}", "error")
                with self.stats_lock:
                    self.stats['convert_failed'] += 1
        
        self._log(f"âœ… HEIFè½¬æ¢å®Œæˆ: æˆåŠŸ {self.stats['convert_success']}, å¤±è´¥ {self.stats['convert_failed']}")
        
        # ç­‰å¾…æ‰€æœ‰è¯„åˆ†ä»»åŠ¡å®Œæˆ
        self._log(f"ğŸ¤– å¼€å§‹è¯„åˆ† {len(rate_futures)} ä¸ªæ–‡ä»¶...")
        for future in as_completed(rate_futures):
            job_file_info = rate_futures[future]
            try:
                result = future.result()
                if result:
                    # æ­¥éª¤4ï¼šè¯„æ˜Ÿå®Œæˆï¼Œä¿å­˜åˆ°é˜Ÿåˆ—
                    self._on_rate_complete(result)
                    with self.stats_lock:
                        if result.get('rating', -1) >= 0:
                            self.stats['rate_success'] += 1
                        else:
                            self.stats['rate_failed'] += 1
            except Exception as e:
                self._log(f"è¯„åˆ†ä»»åŠ¡å¼‚å¸¸: {job_file_info.file_prefix} - {e}", "error")
                with self.stats_lock:
                    self.stats['rate_failed'] += 1
        
        self._log(f"âœ… è¯„åˆ†å®Œæˆ: æˆåŠŸ {self.stats['rate_success']}, å¤±è´¥ {self.stats['rate_failed']}")
        
        # æ­¥éª¤5ï¼šæ‰€æœ‰rateå®Œæˆåï¼Œæ‰§è¡ŒEXIFå†™å…¥
        self._log(f"ğŸ“ å¼€å§‹å†™å…¥EXIF {self.rating_info_queue.qsize()} ä¸ªæ–‡ä»¶...")
        exif_futures: List[Future] = []
        
        while not self.rating_info_queue.empty():
            try:
                rating_info = self.rating_info_queue.get_nowait()
            except queue.Empty:
                break
            
            # åˆ›å»ºEXIFå†™å…¥ä»»åŠ¡
            exif_job = JobBaseCPU_WriteEXIF(
                job_file_info=rating_info.job_file_info,
                exif_data=rating_info.exif_data,
                raw_dict=raw_dict,
                dir_path=self.dir_path,
            )
            
            worker = self._get_idle_cpu_worker()
            future = self.cpu_executor.submit(worker.run_job, exif_job)
            exif_futures.append(future)
        
        # ç­‰å¾…æ‰€æœ‰EXIFå†™å…¥å®Œæˆ
        for future in as_completed(exif_futures):
            try:
                result = future.result()
                with self.stats_lock:
                    if result and result.get('success'):
                        self.stats['exif_success'] += 1
                    else:
                        self.stats['exif_failed'] += 1
            except Exception as e:
                self._log(f"EXIFå†™å…¥ä»»åŠ¡å¼‚å¸¸: {e}", "error")
                with self.stats_lock:
                    self.stats['exif_failed'] += 1
        
        self._log(f"âœ… EXIFå†™å…¥å®Œæˆ: æˆåŠŸ {self.stats['exif_success']}, å¤±è´¥ {self.stats['exif_failed']}")
        
        # æ­¥éª¤6ï¼šè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        total_time = time.time() - start_time
        self._log(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
        self._log(f"ğŸ“Š ç»Ÿè®¡: è½¬æ¢({self.stats['convert_success']}/{self.stats['convert_failed']}), "
                  f"è¯„åˆ†({self.stats['rate_success']}/{self.stats['rate_failed']}), "
                  f"EXIF({self.stats['exif_success']}/{self.stats['exif_failed']})")
        
        # é‡Šæ”¾workers
        self.shutdown(wait=True)
        
        return {
            'stats': self.stats.copy(),
            'total_time': total_time,
        }

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats_lock:
            return self.stats.copy()

    def shutdown(self, wait: bool = True):
        """å…³é—­çº¿ç¨‹æ± ï¼ˆå¯é€‰è°ƒç”¨ï¼‰"""
        try:
            self.cpu_executor.shutdown(wait=wait)
        except Exception:
            pass
        try:
            if self.gpu_executor is not None:
                self.gpu_executor.shutdown(wait=wait)
        except Exception:
            pass