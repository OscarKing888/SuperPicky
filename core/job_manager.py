# -*- coding: utf-8 -*-

import os
import queue
import time
import threading
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, as_completed, Future
from typing import Optional, Callable, Any, Dict, List, Tuple, Set

import torch

from constants import RAW_EXTENSIONS, JPG_EXTENSIONS
from core.job_base import JobFileInfo
from core.job_base_cpu_convert_heif import JobBaseCPU_ConvertHEIF
from core.job_base_cpu_rate import JobBaseCPU_Rate
from core.job_base_gpu_rate import JobBaseGPU_Rate
from core.job_base_cpu_write_exif import JobBaseCPU_WriteEXIF
from core.rating_info import RatingInfo, RatingInfoQueue
from core.photo_processor import PhotoProcessor

from core.job_manager_worker_cpu import CPUJobWorker
from core.job_manager_worker_gpu import GPUJobWorker
from advanced_config import get_advanced_config


class JobManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - ç®¡ç†å¹¶æ‰§è¡Œå„ç§ç±»å‹çš„ä»»åŠ¡ï¼ˆè´Ÿè´£çº¿ç¨‹æ± è°ƒåº¦ï¼‰"""
    
    def __init__(
        self,
        dir_path: str,
        photo_processor: PhotoProcessor,
        cpu_worker_count: Optional[int] = None,
        gpu_worker_count: Optional[int] = None,
        log_callback: Optional[Callable[[str, str], None]] = None
    ):
        """
        åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨
        
        Args:
            dir_path: å¤„ç†ç›®å½•è·¯å¾„
            photo_processor: PhotoProcessorå®ä¾‹
            cpu_worker_count: CPUå·¥ä½œçº¿ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
            gpu_worker_count: GPUå·¥ä½œçº¿ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        self.dir_path = dir_path
        self.photo_processor = photo_processor
        self.log_callback = log_callback
        
        # è®¡ç®—workeræ•°é‡
        cpu_total_limit = None
        cpu_rate_count_config = 0
        cpu_io_count = None
        self.cpu_rate_assist_enabled = False
        self.cpu_rate_backlog_threshold = 8
        self.gpu_single_thread_mode = False
        self.gpu_batch_size_config = 0
        self.gpu_batch_min_size = 1
        self.gpu_batch_max_size = 8
        self.gpu_batch_mem_per_item_gb = 1.0
        self.gpu_batch_mem_overhead_gb = 2.0
        self.gpu_batch_max_wait_ms = 0

        try:
            config = get_advanced_config()
            if cpu_worker_count is None:
                # è‡ªåŠ¨è®¡ç®—ï¼šä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§é™åˆ¶
                cpu_total_limit = min(config.max_cpu_worker_count, multiprocessing.cpu_count())
                # åº”ç”¨è°ƒæ•´å€¼
                cpu_total_limit += config.cpu_worker_count_adjust
                cpu_total_limit = min(cpu_total_limit, config.max_cpu_worker_count)
                cpu_total_limit = max(1, cpu_total_limit)  # ç¡®ä¿è‡³å°‘ä¸º1
            else:
                cpu_total_limit = max(1, cpu_worker_count)

            cpu_io_count = getattr(config, "cpu_io_worker_count", 0)
            cpu_rate_count_config = getattr(config, "cpu_rate_worker_count", 0)
            self.cpu_rate_backlog_threshold = max(0, int(getattr(config, "cpu_rate_backlog_threshold", 8)))
            self.cpu_rate_assist_enabled = bool(getattr(config, "cpu_rate_assist_enabled", True))
            self.gpu_single_thread_mode = bool(getattr(config, "gpu_single_thread_mode", False))
            self.gpu_batch_size_config = max(0, int(getattr(config, "gpu_batch_size", 0)))
            self.gpu_batch_min_size = max(1, int(getattr(config, "gpu_batch_min_size", 1)))
            self.gpu_batch_max_size = max(
                self.gpu_batch_min_size,
                int(getattr(config, "gpu_batch_max_size", 8)),
            )
            self.gpu_batch_mem_per_item_gb = float(getattr(config, "gpu_batch_mem_per_item_gb", 1.0))
            self.gpu_batch_mem_overhead_gb = float(getattr(config, "gpu_batch_mem_overhead_gb", 2.0))
            self.gpu_batch_max_wait_ms = max(0, int(getattr(config, "gpu_batch_max_wait_ms", 0)))
        except Exception as e:
            # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            self._log(f"âš ï¸  åŠ è½½é«˜çº§é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}", "warning")
            if cpu_worker_count is None:
                cpu_total_limit = min(64, multiprocessing.cpu_count())
            else:
                cpu_total_limit = max(1, cpu_worker_count)
            cpu_io_count = min(2, cpu_total_limit)
            cpu_rate_count_config = 0
            self.cpu_rate_backlog_threshold = 8
            self.cpu_rate_assist_enabled = False
            self.gpu_single_thread_mode = False
            self.gpu_batch_size_config = 0
            self.gpu_batch_min_size = 1
            self.gpu_batch_max_size = 8
            self.gpu_batch_mem_per_item_gb = 1.0
            self.gpu_batch_mem_overhead_gb = 2.0
            self.gpu_batch_max_wait_ms = 0

        if cpu_io_count is None or cpu_io_count <= 0:
            cpu_io_count = min(2, cpu_total_limit)
        cpu_io_count = max(1, min(cpu_io_count, cpu_total_limit))

        # æ£€æµ‹GPUè®¾å¤‡
        gpu_device_str = None
        if torch.backends.mps.is_available():
            gpu_device_str = "mps"
        elif torch.cuda.is_available():
            gpu_device_str = "cuda"
        gpu_available = gpu_device_str is not None
        self.gpu_device_str = gpu_device_str
        self.gpu_available = gpu_available

        if cpu_rate_count_config is None:
            cpu_rate_count_config = 0

        if cpu_rate_count_config > 0:
            cpu_rate_count = cpu_rate_count_config
        else:
            if gpu_available:
                cpu_rate_count = max(0, min(4, cpu_total_limit - cpu_io_count))
            else:
                cpu_rate_count = max(1, cpu_total_limit - cpu_io_count)

        if gpu_available and not self.cpu_rate_assist_enabled:
            cpu_rate_count = 0

        if cpu_rate_count + cpu_io_count > cpu_total_limit:
            cpu_rate_count = max(0, cpu_total_limit - cpu_io_count)

        if not gpu_available and cpu_rate_count < 1:
            cpu_rate_count = 1
            if cpu_rate_count + cpu_io_count > cpu_total_limit:
                cpu_io_count = max(1, cpu_total_limit - cpu_rate_count)

        self.cpu_rate_worker_count = cpu_rate_count
        self.cpu_io_worker_count = cpu_io_count

        # åˆ›å»ºCPU workersåˆ—è¡¨ï¼ˆæ¯ä¸ªworkerä¸€ä¸ªå®ä¾‹ï¼Œç”¨äºè´Ÿè½½å‡è¡¡ï¼‰
        self.cpu_rate_workers: List[CPUJobWorker] = [
            CPUJobWorker(log_callback=log_callback, device="cpu")
            for _ in range(cpu_rate_count)
        ]
        self.cpu_io_workers: List[CPUJobWorker] = [
            CPUJobWorker(log_callback=log_callback, device="cpu")
            for _ in range(cpu_io_count)
        ]
        self.cpu_rate_worker_index = 0  # è½®è¯¢ç´¢å¼•
        self.cpu_io_worker_index = 0  # è½®è¯¢ç´¢å¼•
        self.worker_index_lock = threading.Lock()  # ä¿æŠ¤workerç´¢å¼•çš„é”
        self.busy_gpu_workers: Set[int] = set()
        
        # åˆ›å»ºCPUçº¿ç¨‹æ± ï¼ˆç”±JobManagerç®¡ç†ï¼‰
        self.cpu_rate_executor = ThreadPoolExecutor(max_workers=cpu_rate_count) if cpu_rate_count > 0 else None
        self.cpu_io_executor = ThreadPoolExecutor(max_workers=cpu_io_count)
        
        # åˆ›å»ºGPU workerå’Œçº¿ç¨‹æ± ï¼ˆå¦‚æœGPUå¯ç”¨ï¼‰
        if gpu_device_str is not None:
            if self.gpu_single_thread_mode:
                gpu_count = 1
            else:
                gpu_count = gpu_worker_count or self._calculate_gpu_workers(gpu_device_str)
            self.gpu_workers: List[GPUJobWorker] = [
                GPUJobWorker(log_callback=log_callback, device=gpu_device_str)
                for _ in range(gpu_count)
            ]
            self.gpu_worker_index = 0  # è½®è¯¢ç´¢å¼•
            max_gpu_workers = 1 if self.gpu_single_thread_mode else gpu_count
            self.gpu_executor = ThreadPoolExecutor(max_workers=max_gpu_workers)
        else:
            self.gpu_workers = []
            self.gpu_executor = None
        
        self._log(
            f"ğŸ’» CPUè¯„åˆ†Workeræ•°é‡: {len(self.cpu_rate_workers)} | "
            f"ğŸ’¾ CPU IO Workeræ•°é‡: {len(self.cpu_io_workers)} | "
            f"ğŸ–¥ï¸ GPU Workeræ•°é‡: {len(self.gpu_workers)}"
        )
        self._debug_log(
            f"[è°ƒåº¦] CPUè¯„åˆ†è¾…åŠ©: {self.cpu_rate_assist_enabled}, "
            f"CPUè¯„åˆ†çº¿ç¨‹: {self.cpu_rate_worker_count}, "
            f"CPU IOçº¿ç¨‹: {self.cpu_io_worker_count}, "
            f"è¯„åˆ†é˜Ÿåˆ—é˜ˆå€¼: {self.cpu_rate_backlog_threshold}"
        )
        if gpu_available:
            self._debug_log(
                f"[è°ƒåº¦] GPUæ‰¹é‡: size={self._resolve_gpu_batch_size()}, "
                f"min={self.gpu_batch_min_size}, max={self.gpu_batch_max_size}, "
                f"per_item_gb={self.gpu_batch_mem_per_item_gb:.2f}, "
                f"overhead_gb={self.gpu_batch_mem_overhead_gb:.2f}, "
                f"wait_ms={self.gpu_batch_max_wait_ms}, "
                f"fixed={self.gpu_batch_size_config}"
            )

        # è¯„æ˜Ÿä¿¡æ¯é˜Ÿåˆ—ï¼ˆæ­¥éª¤4ï¼šè¯„æ˜Ÿå®Œæˆåä¿å­˜åˆ°è¿™é‡Œï¼‰
        self.rating_info_queue: RatingInfoQueue = RatingInfoQueue()
        
        # è¯„åˆ†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¾…è¯„åˆ†çš„JobFileInfoï¼‰
        self.rate_job_queue: queue.Queue[JobFileInfo] = queue.Queue()

        self.rating_results_lock = threading.Lock()
        self.file_ratings: Dict[str, int] = {}
        self.star_3_photos: List[Dict[str, Any]] = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'convert_success': 0,
            'convert_failed': 0,
            'rate_success': 0,
            'rate_failed': 0,
            'exif_success': 0,
            'exif_failed': 0,
            'total': 0,
            'star_3': 0,
            'picked': 0,
            'star_2': 0,
            'star_1': 0,
            'star_0': 0,
            'no_bird': 0,
            'flying': 0,
            'exposure_issue': 0,
            'start_time': 0,
            'end_time': 0,
            'total_time': 0,
            'avg_time': 0,
        }
        self.stats_lock = threading.Lock()
        
        # è·Ÿè¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼ˆç”¨äºåˆ¤æ–­workeræ˜¯å¦ç©ºé—²ï¼‰
        self.active_rate_futures: Dict[Future, Tuple[List[JobFileInfo], str, Optional[int]]] = {}
        self.active_convert_futures: Dict[Future, JobFileInfo] = {}
        self.active_exif_futures: List[Future] = []
        self.max_exif_in_flight = max(1, len(self.cpu_io_workers))
        self.futures_lock = threading.Lock()
        
        # çº¿ç¨‹æ§åˆ¶æ ‡å¿—
        self.scan_complete = threading.Event()
        self.rate_complete = threading.Event()
        self.exif_complete = threading.Event()

    def _get_idle_cpu_rate_worker(self) -> Optional[CPUJobWorker]:
        """è·å–ç©ºé—²çš„CPUè¯„åˆ†workerï¼ˆè½®è¯¢æ–¹å¼ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not self.cpu_rate_workers:
            return None
        with self.worker_index_lock:
            worker = self.cpu_rate_workers[self.cpu_rate_worker_index]
            self.cpu_rate_worker_index = (self.cpu_rate_worker_index + 1) % len(self.cpu_rate_workers)
            return worker

    def _get_idle_cpu_io_worker(self) -> Optional[CPUJobWorker]:
        """è·å–ç©ºé—²çš„CPU IO workerï¼ˆè½®è¯¢æ–¹å¼ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not self.cpu_io_workers:
            return None
        with self.worker_index_lock:
            worker = self.cpu_io_workers[self.cpu_io_worker_index]
            self.cpu_io_worker_index = (self.cpu_io_worker_index + 1) % len(self.cpu_io_workers)
            return worker
    
    def _get_idle_gpu_worker(self) -> Optional[Tuple[int, GPUJobWorker]]:
        """è·å–ç©ºé—²çš„GPU workerï¼ˆè½®è¯¢æ–¹å¼ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not self.gpu_workers:
            return None
        with self.worker_index_lock:
            for _ in range(len(self.gpu_workers)):
                worker_index = self.gpu_worker_index
                self.gpu_worker_index = (self.gpu_worker_index + 1) % len(self.gpu_workers)
                if worker_index not in self.busy_gpu_workers:
                    self.busy_gpu_workers.add(worker_index)
                    return worker_index, self.gpu_workers[worker_index]
        return None

    def _release_gpu_worker(self, worker_index: int) -> None:
        """é‡Šæ”¾GPU workerå ç”¨æ ‡è®°"""
        with self.worker_index_lock:
            self.busy_gpu_workers.discard(worker_index)

    def _has_idle_gpu_worker(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²çš„GPU worker"""
        if not self.gpu_workers:
            return False
        with self.worker_index_lock:
            return len(self.busy_gpu_workers) < len(self.gpu_workers)

    def _calculate_gpu_workers(self, device_str: str) -> int:
        """æ ¹æ®å¯ç”¨æ˜¾å­˜è®¡ç®—GPUå¹¶å‘æ•°"""
        try:
            if device_str == "cuda" and torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                free_memory_bytes, _ = torch.cuda.mem_get_info(0)
                free_memory_gb = free_memory_bytes / (1024 ** 3)
                gpu_workers = int(free_memory_gb / 1.5 - 2)
                # åº”ç”¨é…ç½®ä¸­çš„è°ƒæ•´å€¼
                try:
                    config = get_advanced_config()
                    gpu_workers += config.gpu_worker_count_adjust
                    gpu_workers = min(gpu_workers, config.max_gpu_worker_count)
                except Exception as e:
                    self._log(f"âš ï¸  åŠ è½½GPU Workeré…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è°ƒæ•´å€¼: {e}", "warning")
                return max(1, gpu_workers)
        except Exception:
            pass
        return 1

    def _log(self, msg: str, level: str = "info"):
        """å†…éƒ¨æ—¥å¿—æ–¹æ³•"""
        if self.log_callback:
            self.log_callback(msg, level)
    
    def _debug_log(self, msg: str, level: str = "info"):
        """è°ƒè¯•æ—¥å¿—æ–¹æ³•ï¼ˆå¯é€šè¿‡é…ç½®å¼€å…³ï¼‰"""
        try:
            config = get_advanced_config()
            if config.debug_log:
                self._log(f"[DEBUG] {msg}", level)
        except Exception:
            # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œé»˜è®¤è¾“å‡ºè°ƒè¯•æ—¥å¿—
            self._log(f"[DEBUG] {msg}", level)
    
    def _scan_files(self) -> Tuple[Dict[str, str], List[JobFileInfo]]:
        """
        æ­¥éª¤1ï¼šæ‰«æå¤„ç†ç›®å½•æ–‡ä»¶ç”Ÿæˆåˆ—è¡¨
        
        Returns:
            (raw_dict, job_file_info_list)
        """
        scan_start = time.time()
        raw_dict = {}
        job_file_info_list: List[JobFileInfo] = []
        
        for filename in os.listdir(self.dir_path):
            if filename.startswith('.'):
                continue
            
            file_prefix, file_ext = os.path.splitext(filename)
            ext_lower = file_ext.lower()
            
            # è®°å½•RAWæ–‡ä»¶
            if ext_lower in RAW_EXTENSIONS:
                raw_dict[file_prefix] = file_ext
                continue
            
            # å¤„ç†JPGå’ŒHEIFæ–‡ä»¶
            if ext_lower in JPG_EXTENSIONS or ext_lower in JobFileInfo.HEIF_EXTENSIONS:
                filepath = os.path.join(self.dir_path, filename)
                job_file_info = JobFileInfo(filepath)
                job_file_info_list.append(job_file_info)
        
        scan_time = (time.time() - scan_start) * 1000
        self._log(f"â±ï¸  æ–‡ä»¶æ‰«æè€—æ—¶: {scan_time:.1f}ms (å…± {len(job_file_info_list)} ä¸ªæ–‡ä»¶)")
        
        return raw_dict, job_file_info_list

    def _reset_stats(self) -> None:
        with self.stats_lock:
            for key in self.stats:
                self.stats[key] = 0

    def _reset_rating_results(self) -> None:
        with self.rating_results_lock:
            self.file_ratings.clear()
            self.star_3_photos.clear()

    def _clear_rating_queue(self) -> int:
        cleared = 0
        while not self.rating_info_queue.empty():
            try:
                self.rating_info_queue.get_nowait()
                cleared += 1
            except queue.Empty:
                break
        return cleared

    def _update_rating_stats(
        self,
        rating: int,
        pick: int,
        is_flying: bool,
        has_exposure_issue: bool,
    ) -> None:
        with self.stats_lock:
            self.stats['total'] += 1
            if rating == 3:
                self.stats['star_3'] += 1
            elif rating == 2:
                self.stats['star_2'] += 1
            elif rating == 1:
                self.stats['star_1'] += 1
            elif rating == 0:
                self.stats['star_0'] += 1
            else:
                self.stats['no_bird'] += 1

            if pick == 1:
                self.stats['picked'] += 1
            if is_flying:
                self.stats['flying'] += 1
            if has_exposure_issue:
                self.stats['exposure_issue'] += 1

    def _describe_job_infos(self, job_infos: List[JobFileInfo]) -> str:
        if not job_infos:
            return "unknown"
        if len(job_infos) == 1:
            return job_infos[0].file_prefix
        return f"{job_infos[0].file_prefix} +{len(job_infos) - 1}"

    def _handle_single_rate_result(self, result: Dict[str, Any]) -> None:
        if result:
            self._on_rate_complete(result)
            with self.stats_lock:
                if result.get('rating', -1) >= 0:
                    self.stats['rate_success'] += 1
                else:
                    self.stats['rate_failed'] += 1

    def _handle_rate_results(self, result: Any) -> None:
        if isinstance(result, list):
            for item in result:
                self._handle_single_rate_result(item)
        else:
            self._handle_single_rate_result(result)

    def _get_gpu_free_mem_gb(self) -> Optional[float]:
        if self.gpu_device_str != "cuda":
            return None
        try:
            torch.cuda.synchronize()
            free_bytes, total_bytes = torch.cuda.mem_get_info()
            return free_bytes / (1024 ** 3)
        except Exception:
            return None

    def _resolve_gpu_batch_size(self) -> int:
        if not self.gpu_available:
            return 1
        if self.gpu_batch_size_config > 0:
            return max(self.gpu_batch_min_size, min(self.gpu_batch_size_config, self.gpu_batch_max_size))

        free_gb = self._get_gpu_free_mem_gb()
        if free_gb is None:
            return 1
        per_item = max(0.1, float(self.gpu_batch_mem_per_item_gb))
        overhead = max(0.0, float(self.gpu_batch_mem_overhead_gb))
        available = max(0.0, free_gb - overhead)
        if per_item <= 0:
            return 1
        batch_size = int(available / per_item)
        batch_size = max(self.gpu_batch_min_size, min(batch_size, self.gpu_batch_max_size))
        return max(1, batch_size)

    def _on_rate_complete(self, result: Dict[str, Any]):
        """
        æ­¥éª¤4ï¼šè¯„æ˜Ÿä»»åŠ¡å®Œæˆå›è°ƒï¼Œä¿å­˜è¯„æ˜Ÿä¿¡æ¯åˆ°é˜Ÿåˆ—
        """
        if not result:
            return
        
        job_file_info = result.get('job_file_info')
        if not job_file_info:
            return
        
        rating_value = result.get('rating', 0)
        if rating_value is None:
            rating_value = 0
        pick_value = result.get('pick', 0)
        if pick_value is None:
            pick_value = 0
        is_flying = bool(result.get('is_flying', False))
        has_exposure_issue = bool(result.get('is_overexposed', False)) or bool(
            result.get('is_underexposed', False)
        )
        adj_sharpness = result.get('adj_sharpness')
        adj_topiq = result.get('adj_topiq')

        # æ„å»ºEXIFæ•°æ®
        exif_data = {
            'rating': rating_value,
            'pick': pick_value,
            'reason': result.get('reason', ''),
            'confidence': result.get('confidence', 0.0),
            'head_sharpness': result.get('head_sharpness', 0.0),
            'topiq': result.get('topiq'),
            'adj_sharpness': adj_sharpness,
            'adj_topiq': adj_topiq,
            'is_flying': is_flying,
            'focus_status': result.get('focus_status'),
            'focus_sharpness_weight': result.get('focus_sharpness_weight', 1.0),
            'focus_topiq_weight': result.get('focus_topiq_weight', 1.0),
            'best_eye_visibility': result.get('best_eye_visibility', 0.0),
        }
        
        rating_info = RatingInfo(
            job_file_info=job_file_info,
            rating=rating_value,
            pick=pick_value,
            reason=result.get('reason', ''),
            exif_data=exif_data,
        )

        self._update_rating_stats(
            rating=rating_value,
            pick=pick_value,
            is_flying=is_flying,
            has_exposure_issue=has_exposure_issue,
        )
        with self.rating_results_lock:
            self.file_ratings[job_file_info.file_prefix] = rating_value
            if rating_value == 3 and adj_topiq is not None:
                self.star_3_photos.append(
                    {
                        'file': job_file_info.src_file_path,
                        'nima': adj_topiq,
                        'sharpness': adj_sharpness if adj_sharpness is not None else 0,
                    }
                )
        
        self.rating_info_queue.put(rating_info)

    def _file_scan_thread(self, job_file_info_list: List[JobFileInfo], temp_dir: str):
        """
        æ–‡ä»¶æ‰«æçº¿ç¨‹ï¼š
        1. å¦‚æœæ˜¯HEIFæ–‡ä»¶ï¼Œåˆ›å»ºè½¬æ¢ä»»åŠ¡ï¼Œè½¬æ¢å®Œæˆåå°†JobFileInfoæ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
        2. å¦åˆ™ç›´æ¥å°†JobFileInfoæ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
        """
        self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] å¼€å§‹ï¼Œå…± {len(job_file_info_list)} ä¸ªæ–‡ä»¶")
        try:
            if not job_file_info_list:
                self._log("æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†")
                self.scan_complete.set()
                self._debug_log("[æ–‡ä»¶æ‰«æçº¿ç¨‹] æ— æ–‡ä»¶ï¼Œç»“æŸ")
                return
            
            # å¤„ç†æ–‡ä»¶ï¼Œåˆ›å»ºè½¬æ¢ä»»åŠ¡æˆ–ç›´æ¥æ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
            convert_count = 0
            direct_count = 0
            for job_file_info in job_file_info_list:
                if job_file_info.needs_tmp_file():
                    # éœ€è¦è½¬æ¢HEIFï¼Œåˆ›å»ºè½¬æ¢ä»»åŠ¡
                    self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] åˆ›å»ºHEIFè½¬æ¢ä»»åŠ¡: {job_file_info.file_prefix}")
                    convert_job = JobBaseCPU_ConvertHEIF(
                        job_file_info=job_file_info,
                        output_dir=temp_dir,
                    )
                    worker = self._get_idle_cpu_io_worker()
                    if worker is None:
                        worker = CPUJobWorker(log_callback=self.log_callback, device="cpu")
                    future = self.cpu_io_executor.submit(worker._run_job, convert_job)
                    
                    with self.futures_lock:
                        self.active_convert_futures[future] = job_file_info
                    convert_count += 1
                else:
                    # ç›´æ¥æ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
                    self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] ç›´æ¥æ”¾å…¥è¯„åˆ†é˜Ÿåˆ—: {job_file_info.file_prefix}")
                    self.rate_job_queue.put(job_file_info)
                    direct_count += 1
            self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] å¤„ç†å®Œæˆ: {convert_count} ä¸ªè½¬æ¢ä»»åŠ¡, {direct_count} ä¸ªç›´æ¥è¯„åˆ†")
            
            # ç­‰å¾…æ‰€æœ‰è½¬æ¢ä»»åŠ¡å®Œæˆï¼Œå®Œæˆåå°†JobFileInfoæ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
            if convert_count > 0:
                self._log(f"ğŸ”„ å¼€å§‹è½¬æ¢ {convert_count} ä¸ªHEIFæ–‡ä»¶...")
                while True:
                    # åœ¨é”å†…æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    with self.futures_lock:
                        if not self.active_convert_futures:
                            break
                        completed_futures = []
                        for future in list(self.active_convert_futures.keys()):
                            if future.done():
                                completed_futures.append(future)
                    
                    for future in completed_futures:
                        with self.futures_lock:
                            job_file_info = self.active_convert_futures.pop(future)
                        try:
                            result = future.result()
                            if result and result.get('success'):
                                # è½¬æ¢æˆåŠŸï¼Œæ›´æ–°job_file_infoçš„tmp_file_path
                                job_file_info.tmp_file_path = result.get('temp_jpg_path')
                                # æ”¾å…¥è¯„åˆ†é˜Ÿåˆ—
                                self.rate_job_queue.put(job_file_info)
                                
                                with self.stats_lock:
                                    self.stats['convert_success'] += 1
                            else:
                                with self.stats_lock:
                                    self.stats['convert_failed'] += 1
                        except Exception as e:
                            self._log(f"è½¬æ¢ä»»åŠ¡å¼‚å¸¸: {job_file_info.file_prefix} - {e}", "error")
                            with self.stats_lock:
                                self.stats['convert_failed'] += 1
                    
                    if not completed_futures:
                        time.sleep(0.01)  # é¿å…CPUç©ºè½¬
                
                self._log(f"âœ… HEIFè½¬æ¢å®Œæˆ: æˆåŠŸ {self.stats['convert_success']}, å¤±è´¥ {self.stats['convert_failed']}")
            
            self.scan_complete.set()
            self._debug_log("[æ–‡ä»¶æ‰«æçº¿ç¨‹] æ­£å¸¸ç»“æŸ")
        except Exception as e:
            import traceback
            self._log(f"æ–‡ä»¶æ‰«æçº¿ç¨‹å¼‚å¸¸: {e}", "error")
            self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            self._debug_log(f"[æ–‡ä»¶æ‰«æçº¿ç¨‹] å †æ ˆ:\n{traceback.format_exc()}")
            self.scan_complete.set()
    
    def _rate_worker_thread(self, raw_dict: Dict[str, str]):
        """
        è¯„åˆ†å·¥ä½œçº¿ç¨‹ï¼š
        ä»è¯„åˆ†é˜Ÿåˆ—ä¸­å–ä»»åŠ¡ï¼Œå½“æœ‰ç©ºé—²çš„è®¡ç®—èµ„æºæ—¶ï¼Œå¯åŠ¨æ–°çš„è¯„åˆ†Job
        """
        self._debug_log("[è¯„åˆ†å·¥ä½œçº¿ç¨‹] å¼€å§‹")
        try:
            self._log(f"ğŸ¤– å¼€å§‹è¯„åˆ†å·¥ä½œçº¿ç¨‹...")
            gpu_available = bool(self.gpu_workers and self.gpu_executor)
            cpu_rate_enabled = bool(
                self.cpu_rate_workers
                and self.cpu_rate_executor
                and (self.cpu_rate_assist_enabled or not gpu_available)
            )
            loop_count = 0
            while True:
                loop_count += 1
                if loop_count % 1000 == 0:
                    self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] å¾ªç¯ {loop_count} æ¬¡")
                # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆæŒç»­æ£€æŸ¥ï¼Œä¸é˜»å¡ï¼‰
                completed_futures = []
                with self.futures_lock:
                    for future in list(self.active_rate_futures.keys()):
                        if future.done():
                            completed_futures.append(future)
                
                for future in completed_futures:
                    with self.futures_lock:
                        job_file_infos_done, device_kind, worker_index = self.active_rate_futures.pop(future)
                    if device_kind == "gpu" and worker_index is not None:
                        self._release_gpu_worker(worker_index)
                    try:
                        result = future.result()
                        self._handle_rate_results(result)
                    except Exception as e:
                        self._log(f"è¯„åˆ†ä»»åŠ¡å¼‚å¸¸: {self._describe_job_infos(job_file_infos_done)} - {e}", "error")
                        with self.stats_lock:
                            self.stats['rate_failed'] += len(job_file_infos_done)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ä»»åŠ¡ä¸”æœ‰ç©ºé—²èµ„æº
                active_cpu = 0
                active_gpu = 0
                with self.futures_lock:
                    for job_infos, device_kind, _ in self.active_rate_futures.values():
                        if device_kind == "gpu":
                            active_gpu += 1
                        elif device_kind == "cpu":
                            active_cpu += len(job_infos)
                    total_workers = (len(self.gpu_workers) if gpu_available else 0)
                    if cpu_rate_enabled:
                        total_workers += self.cpu_rate_worker_count
                    active_count = active_cpu + active_gpu
                    has_idle_resource = active_count < total_workers
                
                if has_idle_resource:
                    try:
                        # éé˜»å¡è·å–ä»»åŠ¡
                        backlog = 0
                        try:
                            backlog = self.rate_job_queue.qsize()
                        except Exception:
                            backlog = 0

                        gpu_idle = gpu_available and self._has_idle_gpu_worker()
                        cpu_idle = cpu_rate_enabled and active_cpu < self.cpu_rate_worker_count
                        cpu_allowed = False
                        if cpu_idle:
                            if not gpu_available:
                                cpu_allowed = True
                            elif self.cpu_rate_assist_enabled and backlog >= self.cpu_rate_backlog_threshold:
                                cpu_allowed = True

                        if gpu_idle:
                            target_device = "gpu"
                        elif cpu_allowed:
                            target_device = "cpu"
                        else:
                            time.sleep(0.01)
                            continue

                        job_file_info = self.rate_job_queue.get_nowait()
                        job_file_infos = [job_file_info]
                        if target_device == "gpu":
                            batch_size = self._resolve_gpu_batch_size()
                            if batch_size > 1:
                                deadline = time.time() + (self.gpu_batch_max_wait_ms / 1000.0)
                                while len(job_file_infos) < batch_size:
                                    try:
                                        job_file_infos.append(self.rate_job_queue.get_nowait())
                                    except queue.Empty:
                                        if self.gpu_batch_max_wait_ms <= 0 or time.time() >= deadline:
                                            break
                                        time.sleep(0.005)
                            if len(job_file_infos) > 1:
                                self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] GPUæ‰¹é‡: {len(job_file_infos)}")

                        self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] è·å–ä»»åŠ¡: {job_file_infos[0].file_prefix}")
                        
                        # æœ‰ç©ºé—²èµ„æºï¼Œåˆ›å»ºè¯„åˆ†ä»»åŠ¡
                        worker = None
                        executor = None
                        worker_index = None
                        device_kind = target_device

                        if target_device == "gpu":
                            gpu_worker_info = self._get_idle_gpu_worker()
                            if gpu_worker_info is None:
                                for info in reversed(job_file_infos):
                                    self.rate_job_queue.put(info)
                                time.sleep(0.01)
                                continue
                            worker_index, worker = gpu_worker_info
                            executor = self.gpu_executor
                        else:
                            worker = self._get_idle_cpu_rate_worker()
                            executor = self.cpu_rate_executor
                        
                        if worker is None or executor is None:
                            time.sleep(0.01)
                            continue

                        self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] ä½¿ç”¨worker: {type(worker).__name__}, executor: {type(executor).__name__}")
                        if target_device == "gpu":
                            rate_jobs = [
                                worker.create_rate_job(
                                    job_file_info=info,
                                    photo_processor=self.photo_processor,
                                    raw_dict=raw_dict,
                                )
                                for info in job_file_infos
                            ]
                        else:
                            rate_jobs = [
                                worker.create_rate_job(
                                    job_file_info=job_file_infos[0],
                                    photo_processor=self.photo_processor,
                                    raw_dict=raw_dict,
                                )
                            ]
                        
                        try:
                            if target_device == "gpu":
                                future = executor.submit(worker._run_batch, rate_jobs)
                            else:
                                future = executor.submit(worker._run_job, rate_jobs[0])
                        except Exception as e:
                            if device_kind == "gpu" and worker_index is not None:
                                self._release_gpu_worker(worker_index)
                            self._log(f"è¯„åˆ†ä»»åŠ¡æäº¤å¤±è´¥: {self._describe_job_infos(job_file_infos)} - {e}", "error")
                            continue
                        self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] ä»»åŠ¡å·²æäº¤: {self._describe_job_infos(job_file_infos)}")
                        
                        with self.futures_lock:
                            self.active_rate_futures[future] = (job_file_infos, device_kind, worker_index)
                            active_count = len(self.active_rate_futures)
                            self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] æ´»è·ƒä»»åŠ¡æ•°: {active_count}")
                            if active_count > 50:
                                self._log(f"âš ï¸  è­¦å‘Š: æ´»è·ƒä»»åŠ¡æ•°è¿‡å¤š ({active_count})ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½é—®é¢˜", "warning")
                    except queue.Empty:
                        # é˜Ÿåˆ—ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºï¼ˆéœ€è¦åœ¨é”å†…æ£€æŸ¥active_rate_futuresï¼‰
                        if self.scan_complete.is_set() and self.rate_job_queue.empty():
                            with self.futures_lock:
                                # å¦‚æœæ‰«æå®Œæˆä¸”é˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                                if not self.active_rate_futures:
                                    self._debug_log("[è¯„åˆ†å·¥ä½œçº¿ç¨‹] é˜Ÿåˆ—ä¸ºç©ºä¸”æ— æ´»è·ƒä»»åŠ¡ï¼Œå‡†å¤‡é€€å‡º")
                                    break
                        time.sleep(0.01)  # é¿å…CPUç©ºè½¬
                else:
                    # æ²¡æœ‰ç©ºé—²èµ„æºï¼Œç­‰å¾…ä¸€ä¸‹
                    time.sleep(0.01)
            
            # ç­‰å¾…æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®Œæˆ
            while True:
                # åœ¨é”å†…æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                with self.futures_lock:
                    if not self.active_rate_futures:
                        break
                    completed_futures = []
                    for future in list(self.active_rate_futures.keys()):
                        if future.done():
                            completed_futures.append(future)
                
                for future in completed_futures:
                    with self.futures_lock:
                        job_file_infos_done, device_kind, worker_index = self.active_rate_futures.pop(future)
                    if device_kind == "gpu" and worker_index is not None:
                        self._release_gpu_worker(worker_index)
                    try:
                        result = future.result()
                        self._handle_rate_results(result)
                    except Exception as e:
                        self._log(f"è¯„åˆ†ä»»åŠ¡å¼‚å¸¸: {self._describe_job_infos(job_file_infos_done)} - {e}", "error")
                        with self.stats_lock:
                            self.stats['rate_failed'] += len(job_file_infos_done)
                
                if not completed_futures:
                    time.sleep(0.01)
            
            self._log(f"âœ… è¯„åˆ†å®Œæˆ: æˆåŠŸ {self.stats['rate_success']}, å¤±è´¥ {self.stats['rate_failed']}")
            self.rate_complete.set()
            self._debug_log("[è¯„åˆ†å·¥ä½œçº¿ç¨‹] æ­£å¸¸ç»“æŸ")
            self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] æœ€ç»ˆç»Ÿè®¡ - æˆåŠŸ: {self.stats['rate_success']}, å¤±è´¥: {self.stats['rate_failed']}")
        except Exception as e:
            import traceback
            self._log(f"è¯„åˆ†å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}", "error")
            self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            self._debug_log(f"[è¯„åˆ†å·¥ä½œçº¿ç¨‹] å †æ ˆ:\n{traceback.format_exc()}")
            self.rate_complete.set()
    
    def _exif_write_thread(self, raw_dict: Dict[str, str]):
        """
        EXIFå†™å…¥çº¿ç¨‹ï¼š
        ä»rating_info_queueä¸­å–ä»»åŠ¡ï¼Œåˆ›å»ºEXIFå†™å…¥ä»»åŠ¡å¹¶æ‰§è¡Œ
        """
        self._debug_log("[EXIFå†™å…¥çº¿ç¨‹] å¼€å§‹")
        try:
            self._log(f"ğŸ“ å¼€å§‹EXIFå†™å…¥çº¿ç¨‹...")
            loop_count = 0
            while True:
                loop_count += 1
                if loop_count % 1000 == 0:
                    self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] å¾ªç¯ {loop_count} æ¬¡")
                # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆæŒç»­æ£€æŸ¥ï¼Œä¸é˜»å¡ï¼‰
                completed_futures = []
                with self.futures_lock:
                    for future in list(self.active_exif_futures):
                        if future.done():
                            completed_futures.append(future)
                
                for future in completed_futures:
                    with self.futures_lock:
                        self.active_exif_futures.remove(future)
                    try:
                        result = future.result()
                        with self.stats_lock:
                            if result:
                                # æ£€æŸ¥ç»“æœï¼Œå³ä½¿éƒ¨åˆ†å¤±è´¥ä¹Ÿç®—éƒ¨åˆ†æˆåŠŸ
                                if result.get('success'):
                                    self.stats['exif_success'] += 1
                                elif result.get('error'):
                                    # æœ‰é”™è¯¯ä¿¡æ¯ï¼Œä½†å¯èƒ½éƒ¨åˆ†æˆåŠŸ
                                    error_msg = result.get('error', '')
                                    if 'éƒ¨åˆ†' in error_msg or 'éƒ¨åˆ†EXIFå†™å…¥å¤±è´¥' in error_msg:
                                        # éƒ¨åˆ†æˆåŠŸï¼Œä»ç„¶è®¡æ•°ä¸ºæˆåŠŸ
                                        self.stats['exif_success'] += 1
                                        self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] éƒ¨åˆ†æˆåŠŸ: {error_msg}")
                                    else:
                                        self.stats['exif_failed'] += 1
                                else:
                                    self.stats['exif_failed'] += 1
                            else:
                                self.stats['exif_failed'] += 1
                    except Exception as e:
                        self._log(f"EXIFå†™å…¥ä»»åŠ¡å¼‚å¸¸: {e}", "error")
                        self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] ä»»åŠ¡å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
                        with self.stats_lock:
                            self.stats['exif_failed'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ä»»åŠ¡
                try:
                    with self.futures_lock:
                        if len(self.active_exif_futures) >= self.max_exif_in_flight:
                            time.sleep(0.01)
                            continue
                    rating_info = self.rating_info_queue._queue.get_nowait()
                    self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] è·å–ä»»åŠ¡: {rating_info.job_file_info.file_prefix}")
                    
                    # åˆ›å»ºEXIFå†™å…¥ä»»åŠ¡
                    exif_job = JobBaseCPU_WriteEXIF(
                        job_file_info=rating_info.job_file_info,
                        exif_data=rating_info.exif_data,
                        raw_dict=raw_dict,
                        dir_path=self.dir_path,
                    )
                    
                    worker = self._get_idle_cpu_io_worker()
                    if worker is None:
                        worker = CPUJobWorker(log_callback=self.log_callback, device="cpu")
                    future = self.cpu_io_executor.submit(worker._run_job, exif_job)
                    self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] ä»»åŠ¡å·²æäº¤: {rating_info.job_file_info.file_prefix}")
                    
                    with self.futures_lock:
                        self.active_exif_futures.append(future)
                        self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] æ´»è·ƒä»»åŠ¡æ•°: {len(self.active_exif_futures)}")
                except queue.Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºï¼ˆéœ€è¦åœ¨é”å†…æ£€æŸ¥active_exif_futuresï¼‰
                    if self.rate_complete.is_set() and self.rating_info_queue.empty():
                        with self.futures_lock:
                            # å¦‚æœè¯„åˆ†å®Œæˆä¸”é˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                            if not self.active_exif_futures:
                                self._debug_log("[EXIFå†™å…¥çº¿ç¨‹] é˜Ÿåˆ—ä¸ºç©ºä¸”æ— æ´»è·ƒä»»åŠ¡ï¼Œå‡†å¤‡é€€å‡º")
                                break
                    time.sleep(0.01)  # é¿å…CPUç©ºè½¬
            
            # ç­‰å¾…æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®Œæˆ
            while True:
                # åœ¨é”å†…æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                with self.futures_lock:
                    if not self.active_exif_futures:
                        break
                    completed_futures = []
                    for future in list(self.active_exif_futures):
                        if future.done():
                            completed_futures.append(future)
                
                for future in completed_futures:
                    with self.futures_lock:
                        self.active_exif_futures.remove(future)
                    try:
                        result = future.result()
                        with self.stats_lock:
                            if result:
                                # æ£€æŸ¥ç»“æœï¼Œå³ä½¿éƒ¨åˆ†å¤±è´¥ä¹Ÿç®—éƒ¨åˆ†æˆåŠŸ
                                if result.get('success'):
                                    self.stats['exif_success'] += 1
                                elif result.get('error'):
                                    # æœ‰é”™è¯¯ä¿¡æ¯ï¼Œä½†å¯èƒ½éƒ¨åˆ†æˆåŠŸ
                                    error_msg = result.get('error', '')
                                    if 'éƒ¨åˆ†' in error_msg or 'éƒ¨åˆ†EXIFå†™å…¥å¤±è´¥' in error_msg:
                                        # éƒ¨åˆ†æˆåŠŸï¼Œä»ç„¶è®¡æ•°ä¸ºæˆåŠŸ
                                        self.stats['exif_success'] += 1
                                        self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] éƒ¨åˆ†æˆåŠŸ: {error_msg}")
                                    else:
                                        self.stats['exif_failed'] += 1
                                else:
                                    self.stats['exif_failed'] += 1
                            else:
                                self.stats['exif_failed'] += 1
                    except Exception as e:
                        self._log(f"EXIFå†™å…¥ä»»åŠ¡å¼‚å¸¸: {e}", "error")
                        self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] ä»»åŠ¡å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
                        with self.stats_lock:
                            self.stats['exif_failed'] += 1
                
                if not completed_futures:
                    time.sleep(0.01)
            
            self._log(f"âœ… EXIFå†™å…¥å®Œæˆ: æˆåŠŸ {self.stats['exif_success']}, å¤±è´¥ {self.stats['exif_failed']}")
            self.exif_complete.set()
            self._debug_log("[EXIFå†™å…¥çº¿ç¨‹] æ­£å¸¸ç»“æŸ")
            self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] æœ€ç»ˆç»Ÿè®¡ - æˆåŠŸ: {self.stats['exif_success']}, å¤±è´¥: {self.stats['exif_failed']}")
        except Exception as e:
            import traceback
            self._log(f"EXIFå†™å…¥çº¿ç¨‹å¼‚å¸¸: {e}", "error")
            self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            self._debug_log(f"[EXIFå†™å…¥çº¿ç¨‹] å †æ ˆ:\n{traceback.format_exc()}")
            self.exif_complete.set()
    
    def run(self):
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹ï¼ˆé˜»å¡å¼ï¼‰ï¼š
        1. å¯åŠ¨æ–‡ä»¶æ‰«æçº¿ç¨‹ï¼Œå°†JobFileInfoé€åˆ°è¯„åˆ†Jobé˜Ÿåˆ—
        2. å¯åŠ¨è¯„åˆ†Jobçº¿ç¨‹ï¼Œç­‰æœ‰æ–°çš„è¯„åˆ†JobåŠæœ‰ç©ºé—²çš„è®¡ç®—èµ„æºå°±å¯åŠ¨æ–°çš„è¯„åˆ†Job
        3. å¯åŠ¨EXIFå†™å…¥çº¿ç¨‹ï¼Œè¯„åˆ†Jobå®Œæˆåå°†ç»“æœé€å…¥å†™å…¥exifçº¿ç¨‹
        4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡éƒ½ç»“æŸï¼Œè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()
        self._debug_log("=== JobManager.run() å¼€å§‹ ===")
        
        try:
            self._debug_log("æ­¥éª¤1: é‡ç½®çº¿ç¨‹æ§åˆ¶æ ‡å¿—")
            # é‡ç½®çº¿ç¨‹æ§åˆ¶æ ‡å¿—
            self.scan_complete.clear()
            self.rate_complete.clear()
            self.exif_complete.clear()

            self._reset_stats()
            self._reset_rating_results()
            with self.stats_lock:
                self.stats['start_time'] = start_time
            
            self._debug_log("æ­¥éª¤2: æ¸…ç©ºé˜Ÿåˆ—å’Œä»»åŠ¡è·Ÿè¸ª")
            # æ¸…ç©ºé˜Ÿåˆ—å’Œä»»åŠ¡è·Ÿè¸ª
            queue_count = 0
            while not self.rate_job_queue.empty():
                try:
                    self.rate_job_queue.get_nowait()
                    queue_count += 1
                except queue.Empty:
                    break
            if queue_count > 0:
                self._debug_log(f"æ¸…ç©ºäº† {queue_count} ä¸ªé˜Ÿåˆ—é¡¹")

            rating_queue_count = self._clear_rating_queue()
            if rating_queue_count > 0:
                self._debug_log(f"Cleared {rating_queue_count} rating queue items")
            
            with self.futures_lock:
                futures_count = len(self.active_rate_futures) + len(self.active_convert_futures) + len(self.active_exif_futures)
                self.active_rate_futures.clear()
                self.active_convert_futures.clear()
                self.active_exif_futures.clear()
                if futures_count > 0:
                    self._debug_log(f"æ¸…ç©ºäº† {futures_count} ä¸ªæœªæ¥ä»»åŠ¡")
            with self.worker_index_lock:
                self.busy_gpu_workers.clear()
            
            self._debug_log("æ­¥éª¤3: åˆ›å»ºä¸´æ—¶ç›®å½•")
            # ä¸´æ—¶ç›®å½•
            temp_dir = os.path.join(self.dir_path, '.superpicky', 'temp_jpg')
            os.makedirs(temp_dir, exist_ok=True)
            self._debug_log(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
            
            self._debug_log("æ­¥éª¤4: æ‰«ææ–‡ä»¶")
            # æ‰«ææ–‡ä»¶è·å–raw_dictå’Œjob_file_info_listï¼ˆéœ€è¦åœ¨æ‰€æœ‰çº¿ç¨‹ä¸­ä½¿ç”¨ï¼‰
            raw_dict, job_file_info_list = self._scan_files()
            self._debug_log(f"æ‰«æå®Œæˆ: {len(job_file_info_list)} ä¸ªæ–‡ä»¶, {len(raw_dict)} ä¸ªRAWæ–‡ä»¶")
            
            if not job_file_info_list:
                self._log("æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†")
                self._debug_log("=== JobManager.run() ç»“æŸï¼ˆæ— æ–‡ä»¶ï¼‰ ===")
                end_time = time.time()
                with self.stats_lock:
                    self.stats['end_time'] = end_time
                    self.stats['total_time'] = end_time - start_time
                    self.stats['avg_time'] = 0
                return {
                    'stats': self.stats.copy(),
                    'total_time': self.stats['total_time'],
                    'file_ratings': {},
                    'star_3_photos': [],
                }
            
            self._debug_log("æ­¥éª¤5: å¯åŠ¨å·¥ä½œçº¿ç¨‹")
            # å¯åŠ¨æ–‡ä»¶æ‰«æçº¿ç¨‹
            scan_thread = threading.Thread(
                target=self._file_scan_thread,
                args=(job_file_info_list, temp_dir),
                daemon=False
            )
            scan_thread.start()
            self._debug_log(f"æ–‡ä»¶æ‰«æçº¿ç¨‹å·²å¯åŠ¨ (ID: {scan_thread.ident})")
            
            # å¯åŠ¨è¯„åˆ†å·¥ä½œçº¿ç¨‹
            rate_thread = threading.Thread(
                target=self._rate_worker_thread,
                args=(raw_dict,),
                daemon=False
            )
            rate_thread.start()
            self._debug_log(f"è¯„åˆ†å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨ (ID: {rate_thread.ident})")
            
            # å¯åŠ¨EXIFå†™å…¥çº¿ç¨‹
            exif_thread = threading.Thread(
                target=self._exif_write_thread,
                args=(raw_dict,),
                daemon=False
            )
            exif_thread.start()
            self._debug_log(f"EXIFå†™å…¥çº¿ç¨‹å·²å¯åŠ¨ (ID: {exif_thread.ident})")
            
            self._debug_log("æ­¥éª¤6: ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ")
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            self._debug_log("ç­‰å¾…æ–‡ä»¶æ‰«æçº¿ç¨‹...")
            scan_thread.join()
            self._debug_log("æ–‡ä»¶æ‰«æçº¿ç¨‹å·²å®Œæˆ")
            
            self._debug_log("ç­‰å¾…è¯„åˆ†å·¥ä½œçº¿ç¨‹...")
            rate_thread.join()
            self._debug_log("è¯„åˆ†å·¥ä½œçº¿ç¨‹å·²å®Œæˆ")
            
            self._debug_log("ç­‰å¾…EXIFå†™å…¥çº¿ç¨‹...")
            exif_thread.join()
            self._debug_log("EXIFå†™å…¥çº¿ç¨‹å·²å®Œæˆ")
            
            self._debug_log("æ­¥éª¤7: æ”¶é›†file_ratingså’Œstar_3_photos")
            with self.rating_results_lock:
                file_ratings = dict(self.file_ratings)
                star_3_photos = list(self.star_3_photos)
            self._debug_log(f"æ”¶é›†å®Œæˆ: {len(file_ratings)} ä¸ªfile_ratings, {len(star_3_photos)} ä¸ªstar_3_photos")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            total_time = end_time - start_time
            with self.stats_lock:
                self.stats['end_time'] = end_time
                self.stats['total_time'] = total_time
                total_count = self.stats.get('total', 0)
                self.stats['avg_time'] = total_time / total_count if total_count > 0 else 0
            self._log(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self._log(f"ğŸ“Š ç»Ÿè®¡: è½¬æ¢({self.stats['convert_success']}/{self.stats['convert_failed']}), "
                      f"è¯„åˆ†({self.stats['rate_success']}/{self.stats['rate_failed']}), "
                      f"EXIF({self.stats['exif_success']}/{self.stats['exif_failed']})")
            
            self._debug_log("æ­¥éª¤9: é‡Šæ”¾workers")
            # é‡Šæ”¾workers
            self._debug_log("å¼€å§‹å…³é—­CPUè¯„åˆ†çº¿ç¨‹æ± ...")
            try:
                if self.cpu_rate_executor is not None:
                    self.cpu_rate_executor.shutdown(wait=True)
                    self._debug_log("CPUè¯„åˆ†çº¿ç¨‹æ± å·²å…³é—­")
                else:
                    self._debug_log("CPUè¯„åˆ†çº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            except Exception as e:
                self._debug_log(f"å…³é—­CPUè¯„åˆ†çº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")

            self._debug_log("å¼€å§‹å…³é—­CPU IOçº¿ç¨‹æ± ...")
            try:
                if self.cpu_io_executor is not None:
                    self.cpu_io_executor.shutdown(wait=True)
                    self._debug_log("CPU IOçº¿ç¨‹æ± å·²å…³é—­")
                else:
                    self._debug_log("CPU IOçº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            except Exception as e:
                self._debug_log(f"å…³é—­CPU IOçº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")
            
            self._debug_log("å¼€å§‹å…³é—­GPUçº¿ç¨‹æ± ...")
            try:
                if self.gpu_executor is not None:
                    self.gpu_executor.shutdown(wait=True)
                    self._debug_log("GPUçº¿ç¨‹æ± å·²å…³é—­")
                else:
                    self._debug_log("GPUçº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            except Exception as e:
                self._debug_log(f"å…³é—­GPUçº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")
            
            self._debug_log("Workerså·²é‡Šæ”¾")
            self._debug_log(f"æœ€ç»ˆç»Ÿè®¡: {self.stats}")
            self._debug_log(f"è¿”å›ç»“æœ: file_ratings={len(file_ratings)}, star_3_photos={len(star_3_photos)}")
            self._debug_log("=== JobManager.run() æ­£å¸¸ç»“æŸ ===")
            return {
                'stats': self.stats.copy(),
                'total_time': total_time,
                'file_ratings': file_ratings,
                'star_3_photos': star_3_photos,
            }
        except Exception as e:
            # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œè®°å½•æ—¥å¿—å¹¶ç¡®ä¿èµ„æºæ¸…ç†
            import traceback
            error_msg = f"JobManagerè¿è¡Œå¼‚å¸¸: {str(e)}\n{traceback.format_exc()}"
            self._log(error_msg, "error")
            self._debug_log(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            self._debug_log(f"å¼‚å¸¸æ¶ˆæ¯: {str(e)}")
            self._debug_log(f"å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            # ç¡®ä¿è®¾ç½®å®Œæˆæ ‡å¿—ï¼Œé¿å…çº¿ç¨‹æ— é™ç­‰å¾…
            self._debug_log("è®¾ç½®å®Œæˆæ ‡å¿—ä»¥é¿å…çº¿ç¨‹æ— é™ç­‰å¾…")
            self.scan_complete.set()
            self.rate_complete.set()
            self.exif_complete.set()
            end_time = time.time()
            with self.stats_lock:
                self.stats['end_time'] = end_time
                self.stats['total_time'] = end_time - start_time
                total_count = self.stats.get('total', 0)
                self.stats['avg_time'] = self.stats['total_time'] / total_count if total_count > 0 else 0
            # é‡Šæ”¾workers
            self._debug_log("å°è¯•é‡Šæ”¾workers")
            try:
                self.shutdown(wait=True)
                self._debug_log("Workersé‡Šæ”¾æˆåŠŸ")
            except Exception as shutdown_error:
                self._debug_log(f"Workersé‡Šæ”¾å¤±è´¥: {shutdown_error}", "error")
            # è¿”å›é”™è¯¯ç»“æœ
            self._debug_log("=== JobManager.run() å¼‚å¸¸ç»“æŸ ===")
            return {
                'stats': self.stats.copy(),
                'total_time': self.stats['total_time'],
                'file_ratings': {},
                'star_3_photos': [],
                'error': str(e),
            }

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats_lock:
            return self.stats.copy()

    def shutdown(self, wait: bool = True):
        """å…³é—­çº¿ç¨‹æ± ï¼ˆå¯é€‰è°ƒç”¨ï¼‰"""
        self._debug_log(f"shutdown() è¢«è°ƒç”¨ï¼Œwait={wait}")
        try:
            self._debug_log("å…³é—­CPUè¯„åˆ†çº¿ç¨‹æ± ...")
            if self.cpu_rate_executor is not None:
                self.cpu_rate_executor.shutdown(wait=wait)
                self._debug_log("CPUè¯„åˆ†çº¿ç¨‹æ± å·²å…³é—­")
            else:
                self._debug_log("CPUè¯„åˆ†çº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        except Exception as e:
            self._debug_log(f"å…³é—­CPUè¯„åˆ†çº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")
        try:
            self._debug_log("å…³é—­CPU IOçº¿ç¨‹æ± ...")
            if self.cpu_io_executor is not None:
                self.cpu_io_executor.shutdown(wait=wait)
                self._debug_log("CPU IOçº¿ç¨‹æ± å·²å…³é—­")
            else:
                self._debug_log("CPU IOçº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        except Exception as e:
            self._debug_log(f"å…³é—­CPU IOçº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")
        try:
            if self.gpu_executor is not None:
                self._debug_log("å…³é—­GPUçº¿ç¨‹æ± ...")
                self.gpu_executor.shutdown(wait=wait)
                self._debug_log("GPUçº¿ç¨‹æ± å·²å…³é—­")
            else:
                self._debug_log("GPUçº¿ç¨‹æ± ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        except Exception as e:
            self._debug_log(f"å…³é—­GPUçº¿ç¨‹æ± æ—¶å‡ºé”™: {e}", "error")
        with self.worker_index_lock:
            self.busy_gpu_workers.clear()
        self._debug_log("shutdown() å®Œæˆ")
