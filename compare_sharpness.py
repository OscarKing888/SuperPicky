#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Laplacian vs Tenengrad é”åº¦ç®—æ³•å¯¹æ¯”æµ‹è¯•

ä½¿ç”¨ YOLO + Keypoint Detector åœ¨çœŸå®é¸Ÿå¤´éƒ¨åŒºåŸŸä¸Šå¯¹æ¯”
"""

import os
import sys
import glob
import time
import cv2
import numpy as np
from typing import List, Dict, Tuple
import statistics

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ultralytics import YOLO
from core.keypoint_detector import KeypointDetector


def calculate_laplacian(gray: np.ndarray, mask: np.ndarray) -> float:
    """å½“å‰æ–¹æ³•: Laplacian æ–¹å·®"""
    if mask.sum() == 0:
        return 0.0
    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)
    laplacian = cv2.Laplacian(masked_gray, cv2.CV_64F)
    mask_pixels = mask > 0
    if mask_pixels.sum() == 0:
        return 0.0
    return float(laplacian[mask_pixels].var())


def calculate_laplacian_denoised(gray: np.ndarray, mask: np.ndarray) -> float:
    """æ–¹æ¡ˆA: Laplacian + é«˜æ–¯é™å™ª"""
    if mask.sum() == 0:
        return 0.0
    # å…ˆé™å™ª
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)
    masked_gray = cv2.bitwise_and(blurred, blurred, mask=mask)
    laplacian = cv2.Laplacian(masked_gray, cv2.CV_64F)
    mask_pixels = mask > 0
    if mask_pixels.sum() == 0:
        return 0.0
    return float(laplacian[mask_pixels].var())


def calculate_tenengrad(gray: np.ndarray, mask: np.ndarray) -> float:
    """æ–¹æ¡ˆB: Tenengrad (Sobel æ¢¯åº¦)"""
    if mask.sum() == 0:
        return 0.0
    
    # Sobel æ¢¯åº¦
    gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    
    # æ¢¯åº¦å¹…å€¼å¹³æ–¹
    gradient_magnitude = gx ** 2 + gy ** 2
    
    # åªå–æ©ç åŒºåŸŸ
    mask_pixels = mask > 0
    if mask_pixels.sum() == 0:
        return 0.0
    
    return float(gradient_magnitude[mask_pixels].mean())


def calculate_tenengrad_threshold(gray: np.ndarray, mask: np.ndarray, threshold: float = 0) -> float:
    """æ–¹æ¡ˆBå˜ä½“: Tenengrad å¸¦é˜ˆå€¼ (æ›´æŠ—å™ª)"""
    if mask.sum() == 0:
        return 0.0
    
    gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    
    gradient_magnitude = gx ** 2 + gy ** 2
    
    # åº”ç”¨é˜ˆå€¼å¿½ç•¥å°æ¢¯åº¦ï¼ˆå™ªå£°ï¼‰
    if threshold > 0:
        gradient_magnitude[gradient_magnitude < threshold] = 0
    
    mask_pixels = mask > 0
    if mask_pixels.sum() == 0:
        return 0.0
    
    return float(gradient_magnitude[mask_pixels].mean())


def run_comparison(image_paths: List[str]):
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("ğŸ”¬ Laplacian vs Tenengrad é”åº¦ç®—æ³•å¯¹æ¯”")
    print("=" * 80)
    print(f"\nğŸ“ æµ‹è¯•å›¾ç‰‡: {len(image_paths)} å¼ \n")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    yolo_model = YOLO('yolo11m-seg.pt')
    kp_detector = KeypointDetector()
    print("âœ… æ¨¡å‹å°±ç»ª\n")
    
    # æ”¶é›†ç»“æœ
    results = []
    no_bird_count = 0
    no_eye_count = 0
    
    laplacian_times = []
    laplacian_dn_times = []
    tenengrad_times = []
    
    print("ğŸ”„ æµ‹è¯•ä¸­...")
    print("-" * 80)
    
    for i, img_path in enumerate(image_paths):
        filename = os.path.basename(img_path)
        
        # YOLO æ£€æµ‹
        yolo_results = yolo_model(img_path, verbose=False)
        if not yolo_results or len(yolo_results) == 0:
            no_bird_count += 1
            continue
        
        result = yolo_results[0]
        
        # æ‰¾é¸Ÿ
        bird_class = 14
        bird_idx = None
        best_conf = 0
        
        if result.boxes is not None:
            for idx, cls in enumerate(result.boxes.cls):
                if int(cls) == bird_class:
                    conf = float(result.boxes.conf[idx])
                    if conf > best_conf:
                        best_conf = conf
                        bird_idx = idx
        
        if bird_idx is None:
            no_bird_count += 1
            continue
        
        # è·å–æ£€æµ‹æ¡†å’Œè£å‰ªå›¾
        box = result.boxes.xyxy[bird_idx].cpu().numpy()
        x1, y1, x2, y2 = map(int, box)
        
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        bird_crop = img_rgb[y1:y2, x1:x2]
        
        if bird_crop.size == 0:
            continue
        
        # Keypoint æ£€æµ‹
        kp_result = kp_detector.detect(bird_crop)
        
        if not kp_result.visible_eye:
            no_eye_count += 1
            continue
        
        # è·å–å¤´éƒ¨æ©ç 
        h, w = bird_crop.shape[:2]
        gray = cv2.cvtColor(bird_crop, cv2.COLOR_RGB2GRAY)
        
        # æ„å»ºå¤´éƒ¨æ©ç  (ä½¿ç”¨çœ¼ç›ä½ç½®)
        VIS_THRESH = 0.5
        left_vis = kp_result.left_eye_vis >= VIS_THRESH
        right_vis = kp_result.right_eye_vis >= VIS_THRESH
        
        if left_vis:
            eye = kp_result.left_eye
        elif right_vis:
            eye = kp_result.right_eye
        else:
            no_eye_count += 1
            continue
        
        eye_px = (int(eye[0] * w), int(eye[1] * h))
        
        beak_visible = kp_result.beak_vis >= VIS_THRESH
        if beak_visible:
            beak = kp_result.beak
            beak_px = (int(beak[0] * w), int(beak[1] * h))
            radius = int(np.sqrt((eye_px[0] - beak_px[0])**2 + (eye_px[1] - beak_px[1])**2) * 1.2)
        else:
            radius = int(max(w, h) * 0.15)
        
        radius = max(10, min(radius, min(w, h) // 2))
        
        head_mask = np.zeros((h, w), dtype=np.uint8)
        cv2.circle(head_mask, eye_px, radius, 255, -1)
        
        # è®¡ç®—ä¸‰ç§é”åº¦
        # 1. Laplacian (å½“å‰)
        t0 = time.time()
        lap = calculate_laplacian(gray, head_mask)
        laplacian_times.append((time.time() - t0) * 1000)
        
        # 2. Laplacian + é™å™ª
        t0 = time.time()
        lap_dn = calculate_laplacian_denoised(gray, head_mask)
        laplacian_dn_times.append((time.time() - t0) * 1000)
        
        # 3. Tenengrad
        t0 = time.time()
        tene = calculate_tenengrad(gray, head_mask)
        tenengrad_times.append((time.time() - t0) * 1000)
        
        results.append({
            'file': filename,
            'laplacian': lap,
            'laplacian_dn': lap_dn,
            'tenengrad': tene,
        })
        
        if (i + 1) % 10 == 0:
            print(f"[{i+1:3d}/{len(image_paths)}] å·²å¤„ç†...")
    
    print("-" * 80)
    print(f"âœ… å®Œæˆ: {len(results)} æœ‰æ•ˆ, {no_bird_count} æ— é¸Ÿ, {no_eye_count} æ— çœ¼\n")
    
    if not results:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆç»“æœ")
        return
    
    # åˆ†æç»“æœ
    print_analysis(results, laplacian_times, laplacian_dn_times, tenengrad_times)


def print_analysis(results: List[Dict], lap_times, lap_dn_times, tene_times):
    """æ‰“å°åˆ†æç»“æœ"""
    print("=" * 80)
    print("ğŸ“Š åˆ†æç»“æœ")
    print("=" * 80)
    
    lap_scores = [r['laplacian'] for r in results]
    lap_dn_scores = [r['laplacian_dn'] for r in results]
    tene_scores = [r['tenengrad'] for r in results]
    
    # é€Ÿåº¦å¯¹æ¯”
    print("\nâ±ï¸  é€Ÿåº¦å¯¹æ¯” (å¹³å‡):")
    print(f"   Laplacian:        {statistics.mean(lap_times):.3f} ms")
    print(f"   Laplacian+é™å™ª:   {statistics.mean(lap_dn_times):.3f} ms")
    print(f"   Tenengrad:        {statistics.mean(tene_times):.3f} ms")
    
    # æ•°å€¼èŒƒå›´
    print("\nğŸ“ˆ æ•°å€¼èŒƒå›´:")
    print(f"   Laplacian:        [{min(lap_scores):.0f}, {max(lap_scores):.0f}], å‡å€¼={statistics.mean(lap_scores):.0f}")
    print(f"   Laplacian+é™å™ª:   [{min(lap_dn_scores):.0f}, {max(lap_dn_scores):.0f}], å‡å€¼={statistics.mean(lap_dn_scores):.0f}")
    print(f"   Tenengrad:        [{min(tene_scores):.0f}, {max(tene_scores):.0f}], å‡å€¼={statistics.mean(tene_scores):.0f}")
    
    # ç›¸å…³æ€§åˆ†æ
    def pearson(x, y):
        n = len(x)
        if n < 2:
            return 0
        mx, my = sum(x)/n, sum(y)/n
        num = sum((xi-mx)*(yi-my) for xi, yi in zip(x, y))
        dx = sum((xi-mx)**2 for xi in x) ** 0.5
        dy = sum((yi-my)**2 for yi in y) ** 0.5
        if dx == 0 or dy == 0:
            return 0
        return num / (dx * dy)
    
    corr_lap_tene = pearson(lap_scores, tene_scores)
    corr_lap_lapdn = pearson(lap_scores, lap_dn_scores)
    
    print("\nğŸ”— ç›¸å…³æ€§:")
    print(f"   Laplacian vs Tenengrad:    r = {corr_lap_tene:.4f}")
    print(f"   Laplacian vs Laplacian+é™å™ª: r = {corr_lap_lapdn:.4f}")
    
    # æ ·æœ¬å±•ç¤º
    print("\nğŸ“ æ ·æœ¬å¯¹æ¯” (å‰10å¼ ):")
    print(f"{'æ–‡ä»¶':<25} {'Laplacian':>12} {'Lap+é™å™ª':>12} {'Tenengrad':>12}")
    print("-" * 65)
    for r in results[:10]:
        print(f"{r['file'][:24]:<25} {r['laplacian']:>12.0f} {r['laplacian_dn']:>12.0f} {r['tenengrad']:>12.0f}")
    
    # ç»“è®º
    print("\n" + "=" * 80)
    print("ğŸ’¡ ç»“è®º")
    print("=" * 80)
    
    if corr_lap_tene > 0.9:
        print("   ä¸¤ç§ç®—æ³•é«˜åº¦ç›¸å…³ï¼Œå¯ä»¥äº’ç›¸æ›¿ä»£")
    elif corr_lap_tene > 0.7:
        print("   ä¸¤ç§ç®—æ³•æœ‰è‰¯å¥½ç›¸å…³æ€§ï¼Œä½†æ’åºå¯èƒ½ç•¥æœ‰ä¸åŒ")
    else:
        print("   ä¸¤ç§ç®—æ³•ç›¸å…³æ€§è¾ƒä½ï¼Œä¼šäº§ç”Ÿä¸åŒçš„æ’åºç»“æœ")
    
    if statistics.mean(tene_times) <= statistics.mean(lap_times) * 1.2:
        print("   Tenengrad é€Ÿåº¦å¯æ¥å—")
    else:
        print("   Tenengrad æ˜æ˜¾æ›´æ…¢")
    
    print("=" * 80)


if __name__ == "__main__":
    # ä½¿ç”¨ä¹‹å‰çš„æµ‹è¯•å›¾ç‰‡
    test_dir = "/tmp/topiq_test"
    
    images = glob.glob(os.path.join(test_dir, "*.jpg"))
    if not images:
        print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡: {test_dir}")
        print("   è¯·å…ˆè¿è¡Œ compare_iqa_crop.py ç”Ÿæˆæµ‹è¯•å›¾ç‰‡")
        sys.exit(1)
    
    images = sorted(images)[:50]  # å–50å¼ 
    run_comparison(images)
