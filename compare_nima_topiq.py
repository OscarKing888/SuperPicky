#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NIMA vs TOPIQ åˆ†æ•°å¯¹æ¯”æµ‹è¯•

å¯¹æ¯”åŒæ ·çš„ç…§ç‰‡åœ¨ä¸¤ä¸ªæ¨¡å‹ä¸‹çš„åˆ†æ•°å·®å¼‚
"""

import os
import sys
import glob
import subprocess
import time

import torch
import torch.nn as nn
import torchvision.transforms as T
from PIL import Image

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ultralytics import YOLO
from topiq_model import TOPIQScorer
from nima_model import NIMA, load_nima_weights


class NIMAScorer:
    """ç‹¬ç«‹çš„ NIMA è¯„åˆ†å™¨"""
    
    def __init__(self, device='mps'):
        self.device = self._get_device(device)
        self._model = None
        
    def _get_device(self, preferred='mps'):
        if preferred == 'mps':
            try:
                if torch.backends.mps.is_available():
                    return torch.device('mps')
            except:
                pass
        if preferred == 'cuda' or torch.cuda.is_available():
            return torch.device('cuda')
        return torch.device('cpu')
    
    def _load_model(self):
        if self._model is None:
            print(f"ğŸ¨ åˆå§‹åŒ– NIMA è¯„åˆ†å™¨ (è®¾å¤‡: {self.device})...")
            
            # æŸ¥æ‰¾æƒé‡
            weight_paths = [
                'models/NIMA_InceptionV2_ava-b0c77c00.pth',
                os.path.join(os.path.dirname(__file__), 'models/NIMA_InceptionV2_ava-b0c77c00.pth')
            ]
            
            weight_path = None
            for p in weight_paths:
                if os.path.exists(p):
                    weight_path = p
                    break
            
            if not weight_path:
                raise FileNotFoundError("NIMA æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°")
            
            self._model = NIMA()
            load_nima_weights(self._model, weight_path, self.device)
            self._model.to(self.device)
            self._model.eval()
            
        return self._model
    
    def calculate_score(self, image_path: str) -> float:
        """è®¡ç®— NIMA è¯„åˆ†"""
        if not os.path.exists(image_path):
            return None
            
        try:
            model = self._load_model()
            
            img = Image.open(image_path).convert('RGB')
            # NIMA ä½¿ç”¨ 224x224 æˆ– 299x299
            img = img.resize((299, 299), Image.LANCZOS)
            
            transform = T.ToTensor()
            img_tensor = transform(img).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                score = model.predict_score(img_tensor)
            
            if isinstance(score, torch.Tensor):
                score = score.item()
            
            return float(max(1.0, min(10.0, score)))
            
        except Exception as e:
            print(f"âŒ NIMA è®¡ç®—å¤±è´¥: {e}")
            return None


def extract_preview(nef_path: str, output_dir: str) -> str:
    """ä» NEF æå–é¢„è§ˆ JPG"""
    basename = os.path.basename(nef_path).replace('.NEF', '.jpg')
    output_path = os.path.join(output_dir, basename)
    
    if os.path.exists(output_path):
        return output_path
    
    try:
        exiftool = os.path.join(os.path.dirname(__file__), 'exiftool')
        subprocess.run([exiftool, '-b', '-PreviewImage', '-w', output_dir + '/%f.jpg', nef_path],
                       capture_output=True, timeout=30)
        if os.path.exists(output_path):
            return output_path
    except:
        pass
    
    return None


def main():
    print("=" * 70)
    print("ğŸ”¬ NIMA vs TOPIQ åˆ†æ•°å¯¹æ¯”æµ‹è¯•")
    print("=" * 70)
    
    directory = "/Users/jameszhenyu/Desktop/2025-08-14"
    tmp_dir = "/tmp/nima_topiq_test"
    os.makedirs(tmp_dir, exist_ok=True)
    
    # æ‰¾ NEF æ–‡ä»¶
    nef_files = []
    for root, dirs, files in os.walk(directory):
        for f in files:
            if f.upper().endswith('.NEF'):
                nef_files.append(os.path.join(root, f))
    
    # æµ‹è¯•å…¨éƒ¨
    nef_files = sorted(nef_files)
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {directory}")
    print(f"ğŸ“Š æµ‹è¯•æ–‡ä»¶: {len(nef_files)} å¼ \n")
    
    # æå–é¢„è§ˆ
    print("ğŸ“¥ æå–é¢„è§ˆå›¾...")
    jpg_files = []
    for nef in nef_files:
        jpg = extract_preview(nef, tmp_dir)
        if jpg:
            jpg_files.append((nef, jpg))
    print(f"   âœ… æå–å®Œæˆ: {len(jpg_files)} å¼ \n")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    yolo = YOLO('yolo11m-seg.pt')
    nima_scorer = NIMAScorer(device='mps')
    topiq_scorer = TOPIQScorer(device='mps')
    print("âœ… æ¨¡å‹å°±ç»ª\n")
    
    # å¤„ç†
    results = []
    print("-" * 80)
    print(f"{'æ–‡ä»¶å':<22} {'TOPIQ-Crop':>11} {'TOPIQ-Full':>11} {'å·®å€¼':>8}")
    print("-" * 80)
    
    for nef_path, jpg_path in jpg_files:
        filename = os.path.basename(nef_path)
        
        # YOLO æ£€æµ‹
        yolo_results = yolo(jpg_path, verbose=False)
        if not yolo_results:
            continue
        
        result = yolo_results[0]
        bird_class = 14
        bird_idx = None
        best_conf = 0
        
        if result.boxes is not None:
            for idx, cls in enumerate(result.boxes.cls):
                if int(cls) == bird_class:
                    conf = float(result.boxes.conf[idx])
                    if conf > best_conf:
                        best_conf = conf
                        bird_idx = idx
        
        if bird_idx is None:
            continue
        
        # è£å‰ªé¸ŸåŒºåŸŸ
        box = result.boxes.xyxy[bird_idx].cpu().numpy()
        x1, y1, x2, y2 = map(int, box)
        
        from PIL import Image as PILImage
        import cv2
        img = cv2.imread(jpg_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        bird_crop = img_rgb[y1:y2, x1:x2]
        
        if bird_crop.size == 0:
            continue
        
        # ä¿å­˜è£å‰ªå›¾
        crop_path = os.path.join(tmp_dir, f"crop_{os.path.basename(jpg_path)}")
        PILImage.fromarray(bird_crop).save(crop_path, quality=95)
        
        # è®¡ç®—åˆ†æ•°: Crop vs Full
        topiq_crop = topiq_scorer.calculate_score(crop_path)
        topiq_full = topiq_scorer.calculate_score(jpg_path)
        
        if topiq_crop and topiq_full:
            diff = topiq_full - topiq_crop
            results.append((filename, topiq_crop, topiq_full, diff))
            print(f"{filename[:21]:<22} {topiq_crop:>11.2f} {topiq_full:>11.2f} {diff:>+8.2f}")
    
    print("-" * 80)
    
    if results:
        crop_scores = [r[1] for r in results]
        full_scores = [r[2] for r in results]
        diffs = [r[3] for r in results]
        
        print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ ({len(results)} å¼ æœ‰æ•ˆç…§ç‰‡):")
        print(f"   TOPIQ-Crop èŒƒå›´: [{min(crop_scores):.2f}, {max(crop_scores):.2f}], å‡å€¼: {sum(crop_scores)/len(crop_scores):.2f}")
        print(f"   TOPIQ-Full èŒƒå›´: [{min(full_scores):.2f}, {max(full_scores):.2f}], å‡å€¼: {sum(full_scores)/len(full_scores):.2f}")
        print(f"   å·®å€¼ (Full-Crop): [{min(diffs):.2f}, {max(diffs):.2f}], å‡å€¼: {sum(diffs)/len(diffs):+.2f}")
        
        # æŒ‰ Crop åˆ†æ•°æ’åº
        by_crop = sorted(results, key=lambda x: x[1], reverse=True)
        # æŒ‰ Full åˆ†æ•°æ’åº
        by_full = sorted(results, key=lambda x: x[2], reverse=True)
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ æŒ‰ Crop æ’å Top 10")
        print("=" * 80)
        print(f"{'æ’å':<4} {'æ–‡ä»¶å':<20} {'Crop':>8} {'Full':>8} {'å·®å€¼':>8}")
        print("-" * 60)
        for i, r in enumerate(by_crop[:10], 1):
            print(f"{i:<4} {r[0][:19]:<20} {r[1]:>8.2f} {r[2]:>8.2f} {r[3]:>+8.2f}")
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ æŒ‰ Full æ’å Top 10")
        print("=" * 80)
        print(f"{'æ’å':<4} {'æ–‡ä»¶å':<20} {'Crop':>8} {'Full':>8} {'å·®å€¼':>8}")
        print("-" * 60)
        for i, r in enumerate(by_full[:10], 1):
            print(f"{i:<4} {r[0][:19]:<20} {r[1]:>8.2f} {r[2]:>8.2f} {r[3]:>+8.2f}")
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ æŒ‰ Crop æ’å Bottom 10")
        print("=" * 80)
        print(f"{'æ’å':<4} {'æ–‡ä»¶å':<20} {'Crop':>8} {'Full':>8} {'å·®å€¼':>8}")
        print("-" * 60)
        for i, r in enumerate(by_crop[-10:], len(by_crop)-9):
            print(f"{i:<4} {r[0][:19]:<20} {r[1]:>8.2f} {r[2]:>8.2f} {r[3]:>+8.2f}")
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ æŒ‰ Full æ’å Bottom 10")
        print("=" * 80)
        print(f"{'æ’å':<4} {'æ–‡ä»¶å':<20} {'Crop':>8} {'Full':>8} {'å·®å€¼':>8}")
        print("-" * 60)
        for i, r in enumerate(by_full[-10:], len(by_full)-9):
            print(f"{i:<4} {r[0][:19]:<20} {r[1]:>8.2f} {r[2]:>8.2f} {r[3]:>+8.2f}")
        
        # æ’åå·®å¼‚åˆ†æ - Top 10%
        top_n = max(1, len(results) // 10)  # 10%
        crop_top_set = set(r[0] for r in by_crop[:top_n])
        full_top_set = set(r[0] for r in by_full[:top_n])
        overlap = crop_top_set & full_top_set
        
        print("\n" + "=" * 80)
        print(f"ğŸ”— Top 10% ({top_n}å¼ ) æ’åé‡å åˆ†æ")
        print("=" * 80)
        print(f"   é‡å : {len(overlap)}/{top_n} ({len(overlap)*100//top_n}%)")
        print(f"   åªåœ¨ Crop Top 10%: {len(crop_top_set - full_top_set)} å¼ ")
        print(f"   åªåœ¨ Full Top 10%: {len(full_top_set - crop_top_set)} å¼ ")
        
        if crop_top_set - full_top_set:
            print(f"\n   åªåœ¨ Crop é å‰çš„ç…§ç‰‡:")
            for f in sorted(crop_top_set - full_top_set):
                r = next(x for x in results if x[0] == f)
                print(f"      {f}: Crop={r[1]:.2f}, Full={r[2]:.2f}")
        
        if full_top_set - crop_top_set:
            print(f"\n   åªåœ¨ Full é å‰çš„ç…§ç‰‡:")
            for f in sorted(full_top_set - crop_top_set):
                r = next(x for x in results if x[0] == f)
                print(f"      {f}: Crop={r[1]:.2f}, Full={r[2]:.2f}")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    main()
